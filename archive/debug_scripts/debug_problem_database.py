#!/usr/bin/env python3
"""
å•é¡Œãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å†…è¨³åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å¹´åº¦åˆ¥ã€ç§‘ç›®åˆ¥ã€é›£æ˜“åº¦åˆ¥ã®å•é¡Œæ•°ã‚’ç¢ºèª
"""

import sys
import os
from collections import Counter, defaultdict
import re

# Firebase Admin SDK ã‚’ç›´æ¥ä½¿ç”¨
import firebase_admin
from firebase_admin import credentials, firestore

class ProblemAnalyzer:
    """å•é¡Œãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.db = None
        self._initialize_firebase()
    
    def _initialize_firebase(self):
        """Firebase Admin SDKã‚’åˆæœŸåŒ–"""
        try:
            if firebase_admin._apps:
                self.db = firestore.client()
                return
            
            cred = credentials.ApplicationDefault()
            firebase_admin.initialize_app(cred, {
                'projectId': 'dent-ai-4d8d8'
            })
            
            self.db = firestore.client()
            print("âœ… Firebaseæ¥ç¶šå®Œäº†")
            
        except Exception as e:
            print(f"âŒ FirebaseåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise e
    
    def analyze_all_problems(self):
        """å…¨å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ"""
        try:
            print("ğŸ“Š å…¨å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æä¸­...")
            
            # study_cardsã‹ã‚‰å…¨ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå•é¡Œã‚’å–å¾—
            cards_ref = self.db.collection('study_cards')
            cards_docs = cards_ref.get()
            
            # å•é¡ŒIDã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆ
            unique_problems = {}
            user_problem_pairs = []
            
            for doc in cards_docs:
                card_data = doc.to_dict()
                question_id = card_data.get('question_id')
                uid = card_data.get('uid')
                metadata = card_data.get('metadata', {})
                
                if question_id:
                    user_problem_pairs.append((uid, question_id))
                    
                    # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå•é¡Œã¨ã—ã¦è¨˜éŒ²
                    if question_id not in unique_problems:
                        unique_problems[question_id] = {
                            'question_id': question_id,
                            'subject': metadata.get('subject', 'ä¸æ˜'),
                            'difficulty': metadata.get('difficulty', 'normal'),
                            'original_level': metadata.get('original_level', 0),
                            'user_count': 0,
                            'year': self._extract_year_from_id(question_id),
                            'exam_type': self._determine_exam_type(question_id)
                        }
                    
                    unique_problems[question_id]['user_count'] += 1
            
            print(f"âœ… åˆ†æå®Œäº†: ãƒ¦ãƒ‹ãƒ¼ã‚¯å•é¡Œæ•° {len(unique_problems)}, ç·ã‚«ãƒ¼ãƒ‰ã‚¨ãƒ³ãƒˆãƒªæ•° {len(user_problem_pairs)}")
            
            return {
                'unique_problems': unique_problems,
                'total_card_entries': len(user_problem_pairs),
                'user_problem_pairs': user_problem_pairs
            }
            
        except Exception as e:
            print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _extract_year_from_id(self, question_id):
        """å•é¡ŒIDã‹ã‚‰å¹´åº¦ã‚’æŠ½å‡º"""
        # å•é¡ŒIDã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æï¼ˆä¾‹: 100A1, 95B10, 118A1ãªã©ï¼‰
        match = re.match(r'(\d+)', question_id)
        if match:
            year_part = int(match.group(1))
            
            # å¹´åº¦ã®æ¨å®šãƒ­ã‚¸ãƒƒã‚¯
            if year_part >= 95 and year_part <= 99:
                return f"19{year_part}"  # 1995-1999
            elif year_part >= 100 and year_part <= 125:
                return f"20{year_part - 100:02d}"  # 2000-2025
            elif year_part >= 1995:
                return str(year_part)  # ç›´æ¥å¹´å·
            else:
                return "ä¸æ˜"
        return "ä¸æ˜"
    
    def _determine_exam_type(self, question_id):
        """å•é¡ŒIDã‹ã‚‰è©¦é¨“ç¨®åˆ¥ã‚’åˆ¤å®š"""
        # æ­¯ç§‘å›½è©¦ã®ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³
        if re.match(r'\d+[A-D]\d+', question_id):
            return "æ­¯ç§‘å›½è©¦"
        elif re.match(r'[A-Z]+\d+', question_id):
            return "å­¦å£«è©¦é¨“"
        else:
            return "ãã®ä»–"
    
    def generate_statistics(self, analysis_data):
        """çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆ"""
        unique_problems = analysis_data['unique_problems']
        
        # ç§‘ç›®åˆ¥çµ±è¨ˆ
        subject_stats = Counter()
        year_stats = Counter()
        exam_type_stats = Counter()
        difficulty_stats = Counter()
        user_distribution = Counter()
        
        for problem_data in unique_problems.values():
            subject_stats[problem_data['subject']] += 1
            year_stats[problem_data['year']] += 1
            exam_type_stats[problem_data['exam_type']] += 1
            difficulty_stats[problem_data['difficulty']] += 1
            user_distribution[problem_data['user_count']] += 1
        
        return {
            'unique_problem_count': len(unique_problems),
            'total_card_entries': analysis_data['total_card_entries'],
            'subject_distribution': dict(subject_stats),
            'year_distribution': dict(year_stats),
            'exam_type_distribution': dict(exam_type_stats),
            'difficulty_distribution': dict(difficulty_stats),
            'user_distribution': dict(user_distribution),
            'most_common_subjects': subject_stats.most_common(10),
            'recent_years': {year: count for year, count in year_stats.items() if year.startswith('20')},
            'replication_factor': analysis_data['total_card_entries'] / len(unique_problems) if unique_problems else 0
        }
    
    def suggest_problem_set_definition(self, stats):
        """é©åˆ‡ãªå•é¡Œã‚»ãƒƒãƒˆå®šç¾©ã‚’ææ¡ˆ"""
        print("\nğŸ’¡ å•é¡Œã‚»ãƒƒãƒˆå®šç¾©ã®ææ¡ˆ:")
        
        total_unique = stats['unique_problem_count']
        replication = stats['replication_factor']
        
        print(f"ğŸ“Š ç¾çŠ¶åˆ†æ:")
        print(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯å•é¡Œæ•°: {total_unique}")
        print(f"  ç·ã‚«ãƒ¼ãƒ‰ã‚¨ãƒ³ãƒˆãƒªæ•°: {stats['total_card_entries']}")
        print(f"  å¹³å‡è¤‡è£½ç‡: {replication:.1f}å€")
        
        # å¹´åº¦åˆ¥æ¨å¥¨ã‚»ãƒƒãƒˆ
        recent_years = stats['recent_years']
        sorted_years = sorted(recent_years.items(), key=lambda x: x[0], reverse=True)
        
        print(f"\nğŸ“… å¹´åº¦åˆ¥å•é¡Œæ•°:")
        for year, count in sorted_years[:10]:
            print(f"  {year}å¹´: {count}å•")
        
        # æ¨å¥¨å•é¡Œã‚»ãƒƒãƒˆ
        print(f"\nğŸ¯ æ¨å¥¨å•é¡Œã‚»ãƒƒãƒˆå®šç¾©:")
        
        # æœ€æ–°5å¹´é–“
        latest_5_years = sum(count for year, count in sorted_years[:5])
        print(f"  æœ€æ–°5å¹´é–“ã‚»ãƒƒãƒˆ: {latest_5_years}å•")
        
        # æœ€æ–°10å¹´é–“
        latest_10_years = sum(count for year, count in sorted_years[:10])
        print(f"  æœ€æ–°10å¹´é–“ã‚»ãƒƒãƒˆ: {latest_10_years}å•")
        
        # æ­¯ç§‘å›½è©¦ã®ã¿
        dental_exam_count = stats['exam_type_distribution'].get('æ­¯ç§‘å›½è©¦', 0)
        print(f"  æ­¯ç§‘å›½è©¦ã®ã¿: {dental_exam_count}å•")
        
        # ç§‘ç›®åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ææ¡ˆ
        print(f"\nğŸ“š ä¸»è¦ç§‘ç›®:")
        for subject, count in stats['most_common_subjects'][:5]:
            print(f"  {subject}: {count}å•")
        
        return {
            'latest_5_years': latest_5_years,
            'latest_10_years': latest_10_years,
            'dental_exam_only': dental_exam_count,
            'recommended_filters': {
                'years': [year for year, _ in sorted_years[:5]],
                'exam_types': ['æ­¯ç§‘å›½è©¦'],
                'exclude_subjects': ['ãã®ä»–', 'ä¸æ˜'] if 'ä¸æ˜' in stats['subject_distribution'] else []
            }
        }

def main():
    analyzer = ProblemAnalyzer()
    
    print("ğŸ” æ­¯ç§‘å›½è©¦å•é¡Œãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æ")
    print("=" * 70)
    
    # å…¨å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ
    analysis_data = analyzer.analyze_all_problems()
    
    if not analysis_data:
        print("âŒ ãƒ‡ãƒ¼ã‚¿åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # çµ±è¨ˆæƒ…å ±ã‚’ç”Ÿæˆ
    stats = analyzer.generate_statistics(analysis_data)
    
    # çµæœè¡¨ç¤º
    print(f"\nğŸ“Š åˆ†æçµæœ:")
    print(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯å•é¡Œæ•°: {stats['unique_problem_count']}")
    print(f"  ç·ã‚«ãƒ¼ãƒ‰ã‚¨ãƒ³ãƒˆãƒªæ•°: {stats['total_card_entries']}")
    print(f"  è¤‡è£½ç‡: {stats['replication_factor']:.1f}å€")
    
    print(f"\nğŸ“š ç§‘ç›®åˆ¥åˆ†å¸ƒ:")
    for subject, count in sorted(stats['subject_distribution'].items(), key=lambda x: x[1], reverse=True)[:10]:
        print(f"  {subject}: {count}å•")
    
    print(f"\nğŸ¥ è©¦é¨“ç¨®åˆ¥åˆ†å¸ƒ:")
    for exam_type, count in stats['exam_type_distribution'].items():
        print(f"  {exam_type}: {count}å•")
    
    print(f"\nğŸ“ˆ é›£æ˜“åº¦åˆ†å¸ƒ:")
    for difficulty, count in stats['difficulty_distribution'].items():
        print(f"  {difficulty}: {count}å•")
    
    # å•é¡Œã‚»ãƒƒãƒˆå®šç¾©ã®ææ¡ˆ
    recommendations = analyzer.suggest_problem_set_definition(stats)

if __name__ == "__main__":
    main()
