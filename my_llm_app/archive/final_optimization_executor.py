#!/usr/bin/env python3
"""
æœ€çµ‚æ®µéšFirestoreæœ€é©åŒ–å®Ÿè¡Œ
æ¤œè¨¼çµæœã«åŸºã¥ã„ãŸå®‰å…¨ã§åŠ¹æœçš„ãªæœ€é©åŒ–ã‚’å®Ÿè¡Œ
"""

from complete_migration_system import CompleteMigrationSystem
from datetime import datetime
import json

class FinalOptimizationExecutor:
    def __init__(self):
        self.migration_system = CompleteMigrationSystem()
        self.db = self.migration_system.db
        
    def execute_final_optimization(self):
        """æœ€çµ‚æœ€é©åŒ–ã®å®Ÿè¡Œ"""
        print("ğŸš€ æœ€çµ‚æ®µéšFirestoreæœ€é©åŒ–é–‹å§‹")
        print("=" * 60)
        
        optimization_results = {
            'deleted_collections': [],
            'documents_deleted': 0,
            'collections_before': 0,
            'collections_after': 0,
            'safety_preserved': []
        }
        
        # æœ€é©åŒ–å‰çŠ¶æ…‹è¨˜éŒ²
        initial_collections = list(self.db.collections())
        optimization_results['collections_before'] = len(initial_collections)
        
        print(f"æœ€é©åŒ–å‰: {len(initial_collections)}ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³")
        
        # ãƒ•ã‚§ãƒ¼ã‚º1: å®Œå…¨å®‰å…¨å‰Šé™¤ï¼ˆç§»è¡Œé–¢é€£ï¼‰
        print("\nğŸ—‘ï¸  ãƒ•ã‚§ãƒ¼ã‚º1: ç§»è¡Œé–¢é€£ãƒ‡ãƒ¼ã‚¿å‰Šé™¤")
        phase1_result = self._execute_phase1_safe_deletion()
        optimization_results['deleted_collections'].extend(phase1_result['deleted'])
        optimization_results['documents_deleted'] += phase1_result['docs_deleted']
        
        # ãƒ•ã‚§ãƒ¼ã‚º2: ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ç³»çµ±åˆåˆ¤å®š
        print("\nğŸ”„ ãƒ•ã‚§ãƒ¼ã‚º2: ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ç³»çµ±åˆå¯èƒ½æ€§ç¢ºèª")
        phase2_result = self._analyze_analytics_usage()
        
        # ãƒ•ã‚§ãƒ¼ã‚º3: ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹å‰Šé™¤
        print("\nğŸ—‘ï¸  ãƒ•ã‚§ãƒ¼ã‚º3: æœªä½¿ç”¨ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹å‰Šé™¤")
        phase3_result = self._execute_phase3_analytics_cleanup(phase2_result)
        optimization_results['deleted_collections'].extend(phase3_result['deleted'])
        optimization_results['documents_deleted'] += phase3_result['docs_deleted']
        
        # ãƒ•ã‚§ãƒ¼ã‚º4: ãƒ©ãƒ³ã‚­ãƒ³ã‚°æœ€é©åŒ–
        print("\nâš¡ ãƒ•ã‚§ãƒ¼ã‚º4: ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿æœ€é©åŒ–")
        phase4_result = self._execute_phase4_ranking_optimization()
        optimization_results['deleted_collections'].extend(phase4_result['deleted'])
        optimization_results['documents_deleted'] += phase4_result['docs_deleted']
        
        # æœ€é©åŒ–å¾ŒçŠ¶æ…‹ç¢ºèª
        final_collections = list(self.db.collections())
        optimization_results['collections_after'] = len(final_collections)
        
        # çµæœè¡¨ç¤º
        self._print_optimization_results(optimization_results)
        
        return optimization_results
    
    def _execute_phase1_safe_deletion(self):
        """ãƒ•ã‚§ãƒ¼ã‚º1: ç§»è¡Œé–¢é€£ã®å®‰å…¨å‰Šé™¤"""
        result = {'deleted': [], 'docs_deleted': 0}
        
        migration_collections = ['migration_backups', 'migration_summaries']
        
        for collection_name in migration_collections:
            try:
                collection = self.db.collection(collection_name)
                docs = list(collection.stream())
                
                if docs:
                    print(f"   å‰Šé™¤ä¸­: {collection_name} ({len(docs)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ)")
                    
                    # ãƒãƒƒãƒå‰Šé™¤
                    batch = self.db.batch()
                    for doc in docs:
                        batch.delete(doc.reference)
                    
                    batch.commit()
                    
                    result['deleted'].append(collection_name)
                    result['docs_deleted'] += len(docs)
                    print(f"   âœ… {collection_name}å‰Šé™¤å®Œäº†")
                else:
                    print(f"   â„¹ï¸  {collection_name}ã¯ã™ã§ã«ç©º")
                    
            except Exception as e:
                print(f"   âŒ {collection_name}å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    def _analyze_analytics_usage(self):
        """ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ç³»ã®ä½¿ç”¨çŠ¶æ³åˆ†æ"""
        print("   ğŸ“Š ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ä½¿ç”¨çŠ¶æ³ãƒã‚§ãƒƒã‚¯")
        
        analytics_collections = {
            'analytics_summary': {'in_app': False, 'recent_data': False},
            'daily_active_users': {'in_app': True, 'recent_data': False}, 
            'daily_engagement_summary': {'in_app': True, 'recent_data': False}
        }
        
        # æœ€è¿‘ã®ãƒ‡ãƒ¼ã‚¿ç¢ºèªï¼ˆéå»7æ—¥ï¼‰
        cutoff_date = (datetime.now().strftime('%Y-%m-%d'))
        
        for collection_name in analytics_collections.keys():
            try:
                docs = list(self.db.collection(collection_name).stream())
                recent_docs = [doc for doc in docs 
                             if doc.to_dict().get('date', '1900-01-01') >= cutoff_date]
                
                if recent_docs:
                    analytics_collections[collection_name]['recent_data'] = True
                    
                print(f"     {collection_name}: ã‚¢ãƒ—ãƒªä½¿ç”¨={analytics_collections[collection_name]['in_app']}, æœ€æ–°ãƒ‡ãƒ¼ã‚¿={len(recent_docs)}ä»¶")
                
            except Exception as e:
                print(f"     {collection_name}åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        
        return analytics_collections
    
    def _execute_phase3_analytics_cleanup(self, analytics_analysis):
        """ãƒ•ã‚§ãƒ¼ã‚º3: ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹å‰Šé™¤"""
        result = {'deleted': [], 'docs_deleted': 0}
        
        # analytics_summaryã¯ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã®ã§å‰Šé™¤
        unused_collections = ['analytics_summary']
        
        for collection_name in unused_collections:
            if not analytics_analysis.get(collection_name, {}).get('in_app', True):
                try:
                    collection = self.db.collection(collection_name)
                    docs = list(collection.stream())
                    
                    if docs:
                        print(f"   å‰Šé™¤ä¸­: {collection_name} ({len(docs)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ)")
                        
                        batch = self.db.batch()
                        for doc in docs:
                            batch.delete(doc.reference)
                        
                        batch.commit()
                        
                        result['deleted'].append(collection_name)
                        result['docs_deleted'] += len(docs)
                        print(f"   âœ… {collection_name}å‰Šé™¤å®Œäº†")
                        
                except Exception as e:
                    print(f"   âŒ {collection_name}å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        
        # dailyç³»ã¯ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãŒã€å¤ã„ãƒ‡ãƒ¼ã‚¿ã¯å‰Šé™¤
        daily_collections = ['daily_active_users', 'daily_engagement_summary']
        for collection_name in daily_collections:
            if analytics_analysis.get(collection_name, {}).get('in_app', False):
                try:
                    collection = self.db.collection(collection_name)
                    docs = list(collection.stream())
                    
                    # 7æ—¥ä»¥ä¸Šå‰ã®ãƒ‡ãƒ¼ã‚¿å‰Šé™¤
                    cutoff_date = (datetime.now()).strftime('%Y-%m-%d')
                    old_docs = [doc for doc in docs 
                               if doc.to_dict().get('date', '9999-12-31') < cutoff_date]
                    
                    if old_docs:
                        print(f"   å¤ã„ãƒ‡ãƒ¼ã‚¿å‰Šé™¤: {collection_name} ({len(old_docs)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ)")
                        
                        batch = self.db.batch()
                        for doc in old_docs:
                            batch.delete(doc.reference)
                        
                        batch.commit()
                        result['docs_deleted'] += len(old_docs)
                        print(f"   âœ… {collection_name}å¤ã„ãƒ‡ãƒ¼ã‚¿å‰Šé™¤å®Œäº†")
                        
                except Exception as e:
                    print(f"   âŒ {collection_name}å¤ã„ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    def _execute_phase4_ranking_optimization(self):
        """ãƒ•ã‚§ãƒ¼ã‚º4: ãƒ©ãƒ³ã‚­ãƒ³ã‚°æœ€é©åŒ–"""
        result = {'deleted': [], 'docs_deleted': 0}
        
        # weekly_ranking_snapshotsã¯å†—é•·ãªã®ã§å‰Šé™¤
        try:
            collection = self.db.collection('weekly_ranking_snapshots')
            docs = list(collection.stream())
            
            if docs:
                print(f"   å‰Šé™¤ä¸­: weekly_ranking_snapshots ({len(docs)}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ)")
                
                batch = self.db.batch()
                for doc in docs:
                    batch.delete(doc.reference)
                
                batch.commit()
                
                result['deleted'].append('weekly_ranking_snapshots')
                result['docs_deleted'] += len(docs)
                print(f"   âœ… weekly_ranking_snapshotså‰Šé™¤å®Œäº†")
                
        except Exception as e:
            print(f"   âŒ weekly_ranking_snapshotså‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    def _print_optimization_results(self, results):
        """æœ€é©åŒ–çµæœã®è¡¨ç¤º"""
        print("\nğŸ¯ æœ€çµ‚æœ€é©åŒ–çµæœ")
        print("=" * 60)
        
        print(f"å‰Šé™¤ã•ã‚ŒãŸã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {len(results['deleted_collections'])}å€‹")
        for collection in results['deleted_collections']:
            print(f"   ğŸ—‘ï¸  {collection}")
        
        print(f"\nå‰Šé™¤ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {results['documents_deleted']}å€‹")
        print(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ•°: {results['collections_before']} â†’ {results['collections_after']}")
        
        reduction_rate = ((results['collections_before'] - results['collections_after']) / 
                         results['collections_before'] * 100) if results['collections_before'] > 0 else 0
        
        print(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å‰Šæ¸›ç‡: {reduction_rate:.1f}%")
        
        print("\nğŸ›¡ï¸  ä¿æŒã•ã‚ŒãŸã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³:")
        try:
            final_collections = list(self.db.collections())
            total_docs = 0
            
            for collection in final_collections:
                docs = list(collection.limit(100).stream())
                doc_count = len(docs)
                total_docs += doc_count
                print(f"   âœ… {collection.id}: {doc_count}ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
            
            print(f"\nğŸ“Š æœ€çµ‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç·æ•°: {total_docs}")
            
        except Exception as e:
            print(f"âŒ æœ€çµ‚çŠ¶æ…‹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        
        print("\nğŸ‰ æœ€çµ‚æœ€é©åŒ–å®Œäº†ï¼")
        print("   ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒæœ€å¤§é™æœ€é©åŒ–ã•ã‚Œã¾ã—ãŸ")

if __name__ == "__main__":
    executor = FinalOptimizationExecutor()
    results = executor.execute_final_optimization()
    
    print("\nâœ¨ Firestoreæœ€çµ‚æœ€é©åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print("   ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚³ã‚¹ãƒˆåŠ¹ç‡ãŒæœ€å¤§åŒ–ã•ã‚Œã¦ã„ã¾ã™")
