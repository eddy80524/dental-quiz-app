#!/usr/bin/env python3
"""
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
è‡ªå·±è©•ä¾¡ãƒ­ã‚°ã€æ¼”ç¿’ãƒ­ã‚°ã€ã‚«ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã‚’åŠ¹ç‡çš„ã«æŠ½å‡º
"""

import sys
import os
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import json

# Firebase Admin SDK ã‚’ç›´æ¥ä½¿ç”¨
import firebase_admin
from firebase_admin import credentials, firestore

class UserDataExtractor:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼å­¦ç¿’ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.db = None
        self._initialize_firebase()
    
    def _parse_timestamp(self, timestamp):
        """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å®‰å…¨ã«ãƒ‘ãƒ¼ã‚¹"""
        if timestamp is None:
            return None
        
        try:
            # datetime.datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
            if hasattr(timestamp, 'year') and hasattr(timestamp, 'month'):
                # timezone-awareãªdatetimeã®å ´åˆã¯UTCã«å¤‰æ›ã—ã¦ã‹ã‚‰naiveã«
                if hasattr(timestamp, 'tzinfo') and timestamp.tzinfo is not None:
                    timestamp = timestamp.replace(tzinfo=None)
                return timestamp
            
            # Firestoreã®DatetimeWithNanosecondsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
            if hasattr(timestamp, 'timestamp'):
                return datetime.fromtimestamp(timestamp.timestamp())  # Unix timestampã‹ã‚‰datetimeã«å¤‰æ›
            
            # æ–‡å­—åˆ—ã®å ´åˆã¯ãƒ‘ãƒ¼ã‚¹
            if isinstance(timestamp, str):
                # ISOå½¢å¼ã®å ´åˆ (TåŒºåˆ‡ã‚Š)
                if 'T' in timestamp:
                    # ãƒã‚¤ã‚¯ãƒ­ç§’éƒ¨åˆ†ã‚’é™¤å»
                    if '.' in timestamp:
                        timestamp = timestamp.split('.')[0]
                    # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ã‚’é™¤å»
                    if '+' in timestamp:
                        timestamp = timestamp.split('+')[0]
                    if 'Z' in timestamp:
                        timestamp = timestamp.replace('Z', '')
                    return datetime.strptime(timestamp, "%Y-%m-%dT%H:%M:%S")
                # é€šå¸¸å½¢å¼ã®å ´åˆ
                elif '.' in timestamp:
                    timestamp = timestamp[:19]  # ç§’ã¾ã§
                    return datetime.strptime(timestamp, "%Y-%m-%d %H:%M:%S")
                else:
                    return datetime.strptime(timestamp, "%Y-%m-%d %H:%M:%S")
            
            return None
        except Exception as e:
            print(f"ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e} (input: {timestamp}, type: {type(timestamp)})")
            return None
    
    def _initialize_firebase(self):
        """Firebase Admin SDKã‚’åˆæœŸåŒ–"""
        try:
            # ã™ã§ã«åˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if firebase_admin._apps:
                self.db = firestore.client()
                return
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®èªè¨¼ã‚’ä½¿ç”¨ï¼ˆADCãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
            cred = credentials.ApplicationDefault()
            firebase_admin.initialize_app(cred, {
                'projectId': 'dent-ai-4d8d8'
            })
            
            self.db = firestore.client()
            print("âœ… Firebaseæ¥ç¶šå®Œäº†")
            
        except Exception as e:
            print(f"âŒ FirebaseåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise e
    
    def get_user_comprehensive_stats(self, uid, analysis_target='å›½è©¦'):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åŒ…æ‹¬çš„ãªå­¦ç¿’çµ±è¨ˆã‚’å–å¾—ï¼ˆpractice_pageç”¨ï¼‰"""
        try:
            print(f"ğŸ¯ {uid} ã®åŒ…æ‹¬çš„çµ±è¨ˆã‚’åˆ†æä¸­...")
            
            # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—
            evaluation_logs = self.extract_self_evaluation_logs(uid)
            practice_logs = self.extract_practice_logs(uid)
            
            # analysis_targetã«å¿œã˜ã¦è©¦é¨“ç¨®åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ã‚’è¨­å®š
            exam_type_filter = None
            if analysis_target == 'å­¦å£«è©¦é¨“' or analysis_target == 'å­¦å£«è©¦é¨“å•é¡Œ':
                exam_type_filter = 'å­¦å£«è©¦é¨“'
            elif analysis_target == 'å›½è©¦' or analysis_target == 'å›½è©¦å•é¡Œ':
                exam_type_filter = 'æ­¯ç§‘å›½è©¦'
            
            card_levels = self.extract_card_levels(uid, exam_type_filter=exam_type_filter)
            
            if not evaluation_logs:
                return None
            
            # å¼±ç‚¹åˆ†é‡ã®ç‰¹å®š
            try:
                weak_categories = self._identify_weak_categories(evaluation_logs)
            except Exception as e:
                print(f"å¼±ç‚¹åˆ†é‡ç‰¹å®šã‚¨ãƒ©ãƒ¼: {e}")
                weak_categories = []
            
            # ç¿’ç†Ÿåº¦åˆ†å¸ƒã®è¨ˆç®—ï¼ˆå…¨å•é¡Œæ•°ã‚’è€ƒæ…®ã€analysis_targetã‚’æ¸¡ã™ï¼‰
            try:
                level_distribution = self._calculate_comprehensive_level_distribution(uid, card_levels.get('cards', []), analysis_target)
            except Exception as e:
                print(f"ç¿’ç†Ÿåº¦åˆ†å¸ƒè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                level_distribution = {'æœªå­¦ç¿’': 0, 'ãƒ¬ãƒ™ãƒ«0': 0, 'ãƒ¬ãƒ™ãƒ«1': 0, 'ãƒ¬ãƒ™ãƒ«2': 0, 'ãƒ¬ãƒ™ãƒ«3': 0, 'ãƒ¬ãƒ™ãƒ«4': 0, 'ãƒ¬ãƒ™ãƒ«5': 0, 'ç¿’å¾—æ¸ˆã¿': 0}
            
            # å­¦ç¿’åŠ¹ç‡ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
            try:
                learning_efficiency = self._calculate_learning_efficiency(evaluation_logs, practice_logs)
            except Exception as e:
                print(f"å­¦ç¿’åŠ¹ç‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                learning_efficiency = 0.0
            
            # æœ€è¿‘ã®å­¦ç¿’å‚¾å‘
            try:
                recent_trends = self._analyze_recent_trends(evaluation_logs)
            except Exception as e:
                print(f"å­¦ç¿’å‚¾å‘åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                recent_trends = {'trend': 'unknown', 'daily_average': 0}
            
            # æœ€çµ‚å­¦ç¿’æ—¥ã‚’å–å¾—
            try:
                last_study_date = self._get_last_study_date(evaluation_logs)
            except Exception as e:
                print(f"æœ€çµ‚å­¦ç¿’æ—¥å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                last_study_date = None
            
            # ä»Šæ—¥ã®å­¦ç¿’æ•°ã‚’è¨ˆç®—
            try:
                today_study_count = self._calculate_today_study_count(evaluation_logs)
            except Exception as e:
                print(f"ä»Šæ—¥ã®å­¦ç¿’æ•°è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                today_study_count = 0
            
            return {
                'weak_categories': weak_categories,
                'level_distribution': level_distribution,
                'learning_efficiency': learning_efficiency,
                'recent_trends': recent_trends,
                'total_studied_cards': len(card_levels.get('cards', [])),
                'last_study_date': last_study_date,
                'ä»Šæ—¥ã®å­¦ç¿’æ•°': today_study_count
            }
            
        except Exception as e:
            print(f"âŒ åŒ…æ‹¬çš„çµ±è¨ˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _identify_weak_categories(self, evaluation_logs):
        """å¼±ç‚¹åˆ†é‡ã‚’ç‰¹å®š"""
        try:
            category_performance = defaultdict(list)
            
            for log in evaluation_logs:
                category = log.get('category', 'ä¸æ˜')
                quality = log.get('quality', 3)
                category_performance[category].append(quality)
            
            # å¹³å‡è©•ä¾¡ãŒ3æœªæº€ã®åˆ†é‡ã‚’å¼±ç‚¹ã¨ã™ã‚‹
            weak_categories = []
            for category, qualities in category_performance.items():
                if qualities:
                    avg_quality = sum(qualities) / len(qualities)
                    if avg_quality < 3.0:
                        weak_categories.append(category)
            
            return weak_categories[:5]  # ä¸Šä½5åˆ†é‡
            
        except Exception as e:
            print(f"å¼±ç‚¹åˆ†é‡ç‰¹å®šã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _calculate_level_distribution(self, cards):
        """ã‚«ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã®åˆ†å¸ƒã‚’è¨ˆç®—ï¼ˆsearch_page.pyå½¢å¼ã«å¯¾å¿œï¼‰"""
        try:
            # search_page.pyã§æœŸå¾…ã•ã‚Œã‚‹è©³ç´°ãªãƒ¬ãƒ™ãƒ«åˆ†å¸ƒå½¢å¼
            distribution = {
                'æœªå­¦ç¿’': 0,
                'ãƒ¬ãƒ™ãƒ«0': 0,
                'ãƒ¬ãƒ™ãƒ«1': 0,
                'ãƒ¬ãƒ™ãƒ«2': 0,
                'ãƒ¬ãƒ™ãƒ«3': 0,
                'ãƒ¬ãƒ™ãƒ«4': 0,
                'ãƒ¬ãƒ™ãƒ«5': 0,
                'ç¿’å¾—æ¸ˆã¿': 0
            }
            
            if not cards:
                return distribution
            
            for i, card in enumerate(cards):
                try:
                    # è©³ç´°ãƒ­ã‚°
                    if i < 3:  # æœ€åˆã®3ä»¶ã ã‘ãƒ­ã‚°å‡ºåŠ›
                        print(f"[DEBUG] card[{i}] type: {type(card)}, content: {card}")
                    
                    level = None
                    mastery_status = None
                    
                    # è¾æ›¸å½¢å¼ã®å ´åˆ
                    if isinstance(card, dict):
                        level = card.get('level')
                        mastery_status = card.get('mastery_status')
                    # ãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆï¼ˆã‚¨ãƒ©ãƒ¼ã®åŸå› ï¼‰
                    elif isinstance(card, list):
                        print(f"[ERROR] Unexpected list card: {card}")
                        continue
                    # æ–‡å­—åˆ—å½¢å¼ã®å ´åˆ
                    elif isinstance(card, str):
                        print(f"[ERROR] Unexpected string card: {card}")
                        continue
                    else:
                        print(f"[ERROR] Unknown card type: {type(card)}")
                        continue
                    
                    # levelã®å‹ãƒã‚§ãƒƒã‚¯
                    if level is None:
                        distribution['æœªå­¦ç¿’'] += 1
                        continue
                    
                    if isinstance(level, (list, dict)):
                        print(f"[ERROR] Level is {type(level)}: {level}")
                        continue
                    
                    if not isinstance(level, (int, float)):
                        print(f"[ERROR] Level is not numeric: {level} (type: {type(level)})")
                        continue
                    
                    # è©³ç´°ãªãƒ¬ãƒ™ãƒ«åˆ†é¡ï¼ˆUserDataExtractorã®level 6ã¯ç¿’å¾—æ¸ˆã¿æ‰±ã„ï¼‰
                    if mastery_status == 'ç¿’å¾—æ¸ˆã¿' or level >= 6:
                        distribution['ç¿’å¾—æ¸ˆã¿'] += 1
                    elif level == 5:
                        distribution['ãƒ¬ãƒ™ãƒ«5'] += 1
                    elif level == 4:
                        distribution['ãƒ¬ãƒ™ãƒ«4'] += 1
                    elif level == 3:
                        distribution['ãƒ¬ãƒ™ãƒ«3'] += 1
                    elif level == 2:
                        distribution['ãƒ¬ãƒ™ãƒ«2'] += 1
                    elif level == 1:
                        distribution['ãƒ¬ãƒ™ãƒ«1'] += 1
                    elif level == 0:
                        distribution['ãƒ¬ãƒ™ãƒ«0'] += 1
                    else:
                        # ä¸æ˜ãªãƒ¬ãƒ™ãƒ«ã¯æœªå­¦ç¿’ã¨ã—ã¦æ‰±ã†
                        distribution['æœªå­¦ç¿’'] += 1
                        
                except Exception as e:
                    print(f"[ERROR] ã‚«ãƒ¼ãƒ‰å‡¦ç†ã‚¨ãƒ©ãƒ¼ (index {i}): {e}")
                    continue
            
            print(f"[DEBUG] è©³ç´°ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ: {distribution}")
            return distribution
            
        except Exception as e:
            print(f"[ERROR] ç¿’ç†Ÿåº¦åˆ†å¸ƒè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return {'æœªå­¦ç¿’': 0, 'ãƒ¬ãƒ™ãƒ«0': 0, 'ãƒ¬ãƒ™ãƒ«1': 0, 'ãƒ¬ãƒ™ãƒ«2': 0, 'ãƒ¬ãƒ™ãƒ«3': 0, 'ãƒ¬ãƒ™ãƒ«4': 0, 'ãƒ¬ãƒ™ãƒ«5': 0, 'ç¿’å¾—æ¸ˆã¿': 0}

    def _calculate_comprehensive_level_distribution(self, uid, studied_cards, analysis_target='å›½è©¦'):
        """å…¨å•é¡Œæ•°ã‚’è€ƒæ…®ã—ãŸåŒ…æ‹¬çš„ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒã‚’è¨ˆç®—"""
        try:
            # å­¦ç¿’æ¸ˆã¿ã‚«ãƒ¼ãƒ‰ã®åˆ†å¸ƒã‚’è¨ˆç®—
            studied_distribution = self._calculate_level_distribution(studied_cards)
            
            # analysis_targetã«å¿œã˜ã¦é©åˆ‡ãªå•é¡Œæ•°ã‚’è¨­å®š
            if analysis_target == 'å­¦å£«è©¦é¨“' or analysis_target == 'å­¦å£«è©¦é¨“å•é¡Œ':
                total_questions_count = 4941  # å­¦å£«è©¦é¨“å•é¡Œæ•°
            else:
                total_questions_count = 8576  # å›½è©¦å•é¡Œæ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
            
            studied_count = len(studied_cards)
            unstudied_count = total_questions_count - studied_count
            
            # æœªå­¦ç¿’å•é¡Œæ•°ã‚’è¿½åŠ 
            comprehensive_distribution = studied_distribution.copy()
            comprehensive_distribution['æœªå­¦ç¿’'] = unstudied_count
            
            print(f"[DEBUG] åŒ…æ‹¬çš„ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ({analysis_target}): å…¨å•é¡Œ{total_questions_count}å•, å­¦ç¿’æ¸ˆã¿{studied_count}å•, æœªå­¦ç¿’{unstudied_count}å•")
            print(f"[DEBUG] åˆ†å¸ƒè©³ç´°: {comprehensive_distribution}")
            
            return comprehensive_distribution
            
        except Exception as e:
            print(f"[ERROR] åŒ…æ‹¬çš„ç¿’ç†Ÿåº¦åˆ†å¸ƒè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚analysis_targetã«å¿œã˜ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
            default_total = 4941 if (analysis_target == 'å­¦å£«è©¦é¨“' or analysis_target == 'å­¦å£«è©¦é¨“å•é¡Œ') else 8576
            return {'æœªå­¦ç¿’': default_total, 'ãƒ¬ãƒ™ãƒ«0': 0, 'ãƒ¬ãƒ™ãƒ«1': 0, 'ãƒ¬ãƒ™ãƒ«2': 0, 'ãƒ¬ãƒ™ãƒ«3': 0, 'ãƒ¬ãƒ™ãƒ«4': 0, 'ãƒ¬ãƒ™ãƒ«5': 0, 'ç¿’å¾—æ¸ˆã¿': 0}
    
    def _calculate_learning_efficiency(self, evaluation_logs, practice_logs):
        """å­¦ç¿’åŠ¹ç‡ã‚’è¨ˆç®—"""
        try:
            if not evaluation_logs:
                return 0.0
            
            # æœ€è¿‘30æ—¥é–“ã®æ”¹å–„ç‡ã‚’è¨ˆç®—
            recent_date = datetime.now() - timedelta(days=30)
            recent_evaluations = []
            
            for log in evaluation_logs:
                log_datetime = self._parse_timestamp(log.get('timestamp'))
                if log_datetime and log_datetime > recent_date:
                    recent_evaluations.append(log)
            
            if len(recent_evaluations) < 5:
                return 0.0
            
            # è©•ä¾¡ã®æ”¹å–„å‚¾å‘ã‚’åˆ†æ
            quality_scores = [log.get('quality', 3) for log in recent_evaluations[-10:]]
            if len(quality_scores) >= 2:
                improvement = (quality_scores[-1] - quality_scores[0]) / len(quality_scores)
                return max(0.0, min(1.0, 0.5 + improvement * 0.1))
            
            return 0.5  # ä¸­ç«‹å€¤
            
        except Exception as e:
            print(f"å­¦ç¿’åŠ¹ç‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def _analyze_recent_trends(self, evaluation_logs):
        """æœ€è¿‘ã®å­¦ç¿’å‚¾å‘ã‚’åˆ†æ"""
        try:
            recent_date = datetime.now() - timedelta(days=7)
            recent_logs = []
            
            for log in evaluation_logs:
                log_datetime = self._parse_timestamp(log.get('timestamp'))
                if log_datetime and log_datetime > recent_date:
                    recent_logs.append(log)
            
            if not recent_logs:
                return {'trend': 'no_data', 'daily_average': 0}
            
            # æ—¥åˆ¥å­¦ç¿’é‡
            daily_counts = defaultdict(int)
            for log in recent_logs:
                log_datetime = self._parse_timestamp(log.get('timestamp'))
                if log_datetime:
                    date_key = log_datetime.strftime('%Y-%m-%d')
                    daily_counts[date_key] += 1
            
            avg_daily = sum(daily_counts.values()) / 7 if daily_counts else 0
            
            return {
                'trend': 'active' if avg_daily > 5 else 'moderate' if avg_daily > 2 else 'low',
                'daily_average': avg_daily,
                'total_recent': len(recent_logs)
            }
            
        except Exception as e:
            print(f"å­¦ç¿’å‚¾å‘åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {'trend': 'unknown', 'daily_average': 0}
    
    def _get_last_study_date(self, evaluation_logs):
        """æœ€å¾Œã®å­¦ç¿’æ—¥ã‚’å–å¾—"""
        try:
            if not evaluation_logs:
                return None
            
            latest_timestamp = None
            
            for log in evaluation_logs:
                log_datetime = self._parse_timestamp(log.get('timestamp'))
                if log_datetime and (latest_timestamp is None or log_datetime > latest_timestamp):
                    latest_timestamp = log_datetime
            
            if latest_timestamp:
                return latest_timestamp.strftime('%Y-%m-%d')
            
            return None
            
        except Exception as e:
            print(f"æœ€çµ‚å­¦ç¿’æ—¥å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def _calculate_today_study_count(self, evaluation_logs):
        """ä»Šæ—¥ã®å­¦ç¿’æ•°ã‚’è¨ˆç®—"""
        try:
            if not evaluation_logs:
                return 0
            
            from datetime import datetime, date
            today = date.today()
            today_count = 0
            
            for log in evaluation_logs:
                log_datetime = self._parse_timestamp(log.get('timestamp'))
                if log_datetime and log_datetime.date() == today:
                    today_count += 1
            
            return today_count
            
        except Exception as e:
            print(f"ä»Šæ—¥ã®å­¦ç¿’æ•°è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0

    def extract_self_evaluation_logs(self, uid, start_date=None, end_date=None):
        """è‡ªå·±è©•ä¾¡ãƒ­ã‚°ã‚’æŠ½å‡º"""
        try:
            print(f"ğŸ“Š {uid} ã®è‡ªå·±è©•ä¾¡ãƒ­ã‚°ã‚’æŠ½å‡ºä¸­...")
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            cards_ref = self.db.collection('study_cards')
            query = cards_ref.where('uid', '==', uid)
            cards_docs = query.get()
            
            evaluation_logs = []
            
            for doc in cards_docs:
                card_data = doc.to_dict()
                question_id = card_data.get('question_id')
                history = card_data.get('history', [])
                
                for entry in history:
                    timestamp = entry.get('timestamp')
                    quality = entry.get('quality')
                    
                    if quality is not None:
                        dt = self._parse_timestamp(timestamp)
                        if not dt:
                            continue
                        
                        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                        if start_date and dt < start_date:
                            continue
                        if end_date and dt > end_date:
                            continue
                        
                        evaluation_logs.append({
                            'question_id': question_id,
                            'timestamp': dt,
                            'quality': quality,
                            'quality_text': self._quality_to_text(quality),
                            'is_correct': quality >= 3,  # 3ä»¥ä¸Šã‚’æ­£è§£ã¨ã¿ãªã™
                            'subject': card_data.get('metadata', {}).get('subject', 'ä¸æ˜'),
                            'difficulty': card_data.get('metadata', {}).get('difficulty', 'normal')
                        })
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆ
            evaluation_logs.sort(key=lambda x: x['timestamp'])
            
            print(f"âœ… {len(evaluation_logs)}ä»¶ã®è‡ªå·±è©•ä¾¡ãƒ­ã‚°ã‚’æŠ½å‡º")
            return evaluation_logs
            
        except Exception as e:
            print(f"âŒ è‡ªå·±è©•ä¾¡ãƒ­ã‚°æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def extract_practice_logs(self, uid, start_date=None, end_date=None):
        """æ¼”ç¿’ãƒ­ã‚°ã‚’æŠ½å‡ºï¼ˆæ—¥åˆ¥é›†è¨ˆå«ã‚€ï¼‰"""
        try:
            print(f"ğŸ“ˆ {uid} ã®æ¼”ç¿’ãƒ­ã‚°ã‚’æŠ½å‡ºä¸­...")
            
            evaluation_logs = self.extract_self_evaluation_logs(uid, start_date, end_date)
            
            if not evaluation_logs:
                return {
                    'daily_stats': {},
                    'total_sessions': 0,
                    'total_problems': 0,
                    'accuracy_rate': 0.0,
                    'quality_distribution': {},
                    'subject_stats': {}
                }
            
            # æ—¥åˆ¥çµ±è¨ˆ
            daily_stats = defaultdict(lambda: {
                'problems_solved': 0,
                'correct_answers': 0,
                'quality_sum': 0,
                'sessions': 0,
                'subjects': set(),
                'first_session': None,
                'last_session': None
            })
            
            # ç§‘ç›®åˆ¥çµ±è¨ˆ
            subject_stats = defaultdict(lambda: {
                'total': 0,
                'correct': 0,
                'quality_sum': 0,
                'avg_quality': 0.0
            })
            
            # å“è³ªåˆ†å¸ƒ
            quality_distribution = Counter()
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¤œå‡ºï¼ˆ30åˆ†ä»¥å†…ã®é€£ç¶šå­¦ç¿’ã‚’1ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¨ã¿ãªã™ï¼‰
            sessions = []
            current_session = []
            last_timestamp = None
            
            for log in evaluation_logs:
                date_key = log['timestamp'].strftime('%Y-%m-%d')
                
                # æ—¥åˆ¥çµ±è¨ˆæ›´æ–°
                daily_stats[date_key]['problems_solved'] += 1
                if log['is_correct']:
                    daily_stats[date_key]['correct_answers'] += 1
                daily_stats[date_key]['quality_sum'] += log['quality']
                daily_stats[date_key]['subjects'].add(log['subject'])
                
                if daily_stats[date_key]['first_session'] is None:
                    daily_stats[date_key]['first_session'] = log['timestamp']
                daily_stats[date_key]['last_session'] = log['timestamp']
                
                # ç§‘ç›®åˆ¥çµ±è¨ˆæ›´æ–°
                subject = log['subject']
                subject_stats[subject]['total'] += 1
                if log['is_correct']:
                    subject_stats[subject]['correct'] += 1
                subject_stats[subject]['quality_sum'] += log['quality']
                
                # å“è³ªåˆ†å¸ƒæ›´æ–°
                quality_distribution[log['quality']] += 1
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¤œå‡º
                if last_timestamp is None or (log['timestamp'] - last_timestamp).total_seconds() <= 1800:  # 30åˆ†
                    current_session.append(log)
                else:
                    if current_session:
                        sessions.append(current_session)
                    current_session = [log]
                
                last_timestamp = log['timestamp']
            
            # æœ€å¾Œã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
            if current_session:
                sessions.append(current_session)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°ã‚’æ—¥åˆ¥çµ±è¨ˆã«è¿½åŠ 
            for session in sessions:
                if session:
                    date_key = session[0]['timestamp'].strftime('%Y-%m-%d')
                    daily_stats[date_key]['sessions'] += 1
            
            # ç§‘ç›®åˆ¥å¹³å‡å“è³ªã‚’è¨ˆç®—
            for subject in subject_stats:
                if subject_stats[subject]['total'] > 0:
                    subject_stats[subject]['avg_quality'] = subject_stats[subject]['quality_sum'] / subject_stats[subject]['total']
                    subject_stats[subject]['accuracy_rate'] = subject_stats[subject]['correct'] / subject_stats[subject]['total']
            
            # æ—¥åˆ¥çµ±è¨ˆã®å¾Œå‡¦ç†
            for date_key in daily_stats:
                daily_stats[date_key]['subjects'] = list(daily_stats[date_key]['subjects'])
                if daily_stats[date_key]['problems_solved'] > 0:
                    daily_stats[date_key]['accuracy_rate'] = daily_stats[date_key]['correct_answers'] / daily_stats[date_key]['problems_solved']
                    daily_stats[date_key]['avg_quality'] = daily_stats[date_key]['quality_sum'] / daily_stats[date_key]['problems_solved']
            
            total_problems = len(evaluation_logs)
            total_correct = sum(1 for log in evaluation_logs if log['is_correct'])
            accuracy_rate = total_correct / total_problems if total_problems > 0 else 0.0
            
            practice_data = {
                'daily_stats': dict(daily_stats),
                'sessions': sessions,
                'total_sessions': len(sessions),
                'total_problems': total_problems,
                'total_correct': total_correct,
                'accuracy_rate': accuracy_rate,
                'quality_distribution': dict(quality_distribution),
                'subject_stats': dict(subject_stats),
                'study_period': {
                    'start': evaluation_logs[0]['timestamp'] if evaluation_logs else None,
                    'end': evaluation_logs[-1]['timestamp'] if evaluation_logs else None,
                    'days': len(daily_stats)
                }
            }
            
            print(f"âœ… æ¼”ç¿’ãƒ­ã‚°æŠ½å‡ºå®Œäº†: {total_problems}å•ã€{len(sessions)}ã‚»ãƒƒã‚·ãƒ§ãƒ³ã€{len(daily_stats)}æ—¥é–“")
            return practice_data
            
        except Exception as e:
            print(f"âŒ æ¼”ç¿’ãƒ­ã‚°æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def extract_card_levels(self, uid, level_filter=None, studied_only=True, exam_type_filter=None):
        """ã‚«ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆè©¦é¨“ç¨®åˆ¥åˆ†æä»˜ãï¼‰"""
        try:
            print(f"ğŸ¯ {uid} ã®ã‚«ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã‚’æŠ½å‡ºä¸­...")
            
            cards_ref = self.db.collection('study_cards')
            query = cards_ref.where('uid', '==', uid)
            cards_docs = query.get()
            
            card_levels = []
            level_distribution = Counter()
            unstudied_count = 0
            exam_type_distribution = Counter()
            subject_distribution = Counter()
            
            for doc in cards_docs:
                card_data = doc.to_dict()
                question_id = card_data.get('question_id')
                sm2_data = card_data.get('sm2_data', {})
                performance = card_data.get('performance', {})
                metadata = card_data.get('metadata', {})
                history = card_data.get('history', [])
                
                # è©¦é¨“ç¨®åˆ¥ã‚’åˆ¤å®š
                exam_type = self._determine_exam_type_from_question_id(question_id)
                exam_type_distribution[exam_type] += 1
                
                # ç§‘ç›®åˆ†å¸ƒ
                subject = metadata.get('subject', 'ä¸æ˜')
                subject_distribution[subject] += 1
                
                # è©¦é¨“ç¨®åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if exam_type_filter and exam_type != exam_type_filter:
                    continue
                
                # å®Ÿéš›ã«å­¦ç¿’ã—ãŸã‹ã©ã†ã‹ã®åˆ¤å®š
                has_history = len(history) > 0
                has_attempts = performance.get('total_attempts', 0) > 0
                is_studied = has_history or has_attempts
                
                # studied_onlyãŒTrueã®å ´åˆã¯ã€å­¦ç¿’æ¸ˆã¿ã‚«ãƒ¼ãƒ‰ã®ã¿ã‚’å¯¾è±¡ã«ã™ã‚‹
                if studied_only and not is_studied:
                    unstudied_count += 1
                    continue
                
                level = sm2_data.get('n', 0)  # SM2ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å¾©ç¿’å›æ•°
                interval = sm2_data.get('interval', 0)
                ef = sm2_data.get('ef', 2.5)
                due_date = sm2_data.get('due_date')
                
                # ãƒ¬ãƒ™ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                if level_filter is not None and level != level_filter:
                    continue
                
                # ç¿’å¾—åº¦åˆ¤å®šï¼ˆå­¦ç¿’æ¸ˆã¿ã‚«ãƒ¼ãƒ‰ã®ã¿ï¼‰
                mastery_status = self._determine_mastery_status(level, performance, sm2_data, is_studied)
                
                card_info = {
                    'question_id': question_id,
                    'exam_type': exam_type,
                    'level': level,
                    'interval': interval,
                    'easiness_factor': ef,
                    'due_date': due_date,
                    'total_attempts': performance.get('total_attempts', 0),
                    'correct_attempts': performance.get('correct_attempts', 0),
                    'avg_quality': performance.get('avg_quality', 0.0),
                    'last_quality': performance.get('last_quality', 0),
                    'subject': subject,
                    'difficulty': metadata.get('difficulty', 'normal'),
                    'mastery_status': mastery_status,
                    'is_due': self._is_card_due(due_date) if is_studied else False,
                    'accuracy_rate': performance.get('correct_attempts', 0) / max(performance.get('total_attempts', 1), 1),
                    'is_studied': is_studied,
                    'history_count': len(history)
                }
                
                card_levels.append(card_info)
                level_distribution[level] += 1
            
            # ãƒ¬ãƒ™ãƒ«é †ã§ã‚½ãƒ¼ãƒˆ
            card_levels.sort(key=lambda x: (-x['level'], x['question_id']))
            
            # è©¦é¨“ç¨®åˆ¥åˆ†æ
            kokushi_cards = [card for card in card_levels if card['exam_type'] == 'æ­¯ç§‘å›½è©¦']
            gakushi_cards = [card for card in card_levels if card['exam_type'] == 'å­¦å£«è©¦é¨“']
            
            # çµ±è¨ˆæƒ…å ±
            stats = {
                'total_cards_in_db': len(cards_docs),
                'studied_cards': len(card_levels),
                'unstudied_cards': unstudied_count,
                'exam_type_distribution': dict(exam_type_distribution),
                'subject_distribution': dict(subject_distribution),
                'level_distribution': dict(level_distribution),
                'mastery_breakdown': Counter(card['mastery_status'] for card in card_levels),
                'due_cards': sum(1 for card in card_levels if card['is_due']),
                'avg_level': sum(card['level'] for card in card_levels) / len(card_levels) if card_levels else 0,
                'high_level_cards': sum(1 for card in card_levels if card['level'] >= 4),
                'struggling_cards': sum(1 for card in card_levels if card['accuracy_rate'] < 0.5 and card['total_attempts'] >= 2),
                'perfect_cards': sum(1 for card in card_levels if card['accuracy_rate'] == 1.0 and card['total_attempts'] >= 2),
                
                # è©¦é¨“ç¨®åˆ¥çµ±è¨ˆ
                'kokushi_stats': {
                    'total_cards': len(kokushi_cards),
                    'total_problems_available': 8576,  # æ—¢çŸ¥ã®å›½è©¦å•é¡Œæ•°
                    'coverage_rate': len([card for card in kokushi_cards if card['exam_type'] == 'æ­¯ç§‘å›½è©¦']) / 8576 if 8576 > 0 else 0,
                    'studied_cards': len([card for card in kokushi_cards if card['is_studied']]),
                    'mastery_breakdown': Counter(card['mastery_status'] for card in kokushi_cards)
                },
                'gakushi_stats': {
                    'total_cards': len(gakushi_cards),
                    'total_problems_available': 4941,  # æ—¢çŸ¥ã®å­¦å£«å•é¡Œæ•°
                    'coverage_rate': len([card for card in gakushi_cards if card['exam_type'] == 'å­¦å£«è©¦é¨“']) / 4941 if 4941 > 0 else 0,
                    'studied_cards': len([card for card in gakushi_cards if card['is_studied']]),
                    'mastery_breakdown': Counter(card['mastery_status'] for card in gakushi_cards)
                }
            }
            
            print(f"âœ… ã‚«ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«æŠ½å‡ºå®Œäº†: å­¦ç¿’æ¸ˆã¿{len(card_levels)}æšã€æœªå­¦ç¿’{unstudied_count}æš")
            print(f"   å›½è©¦: {len(kokushi_cards)}æšã€å­¦å£«: {len(gakushi_cards)}æš")
            return {
                'cards': card_levels,
                'stats': stats
            }
            
        except Exception as e:
            print(f"âŒ ã‚«ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return {'cards': [], 'stats': {}}
    
    def _determine_exam_type_from_question_id(self, question_id):
        """å•é¡ŒIDã‹ã‚‰è©¦é¨“ç¨®åˆ¥ã‚’åˆ¤å®š"""
        if not question_id:
            return "ä¸æ˜"
        
        import re
        
        # æ­¯ç§‘å›½è©¦ã®ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ (ä¾‹: 100A1, 95B10, 118A1)
        if re.match(r'\d+[A-D]\d+', question_id):
            return "æ­¯ç§‘å›½è©¦"
        
        # å­¦å£«è©¦é¨“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ (ä¾‹: GAKUSHI_001, G2023_A01)
        if re.match(r'[A-Z]+\d+', question_id) or 'GAKUSHI' in question_id.upper() or question_id.startswith('G'):
            return "å­¦å£«è©¦é¨“"
        
        # ãã®ä»–ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚‚å«ã‚ã¦è©³ç´°åˆ¤å®š
        if any(char.isalpha() for char in question_id) and any(char.isdigit() for char in question_id):
            # æ•°å­—+ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆ+æ•°å­—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯å›½è©¦ã®å¯èƒ½æ€§ãŒé«˜ã„
            if re.match(r'\d+[A-Z]\d*', question_id):
                return "æ­¯ç§‘å›½è©¦"
        
        return "ãã®ä»–"
    
    def _quality_to_text(self, quality):
        """å“è³ªå€¤ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
        quality_map = {
            1: "Ã— ã‚‚ã†ä¸€åº¦",
            2: "â–³ é›£ã—ã„", 
            3: "â—‹ æ™®é€š",
            4: "â— ç°¡å˜",
            5: "â—â— å®Œç’§"
        }
        return quality_map.get(quality, f"ä¸æ˜({quality})")
    
    def _determine_mastery_status(self, level, performance, sm2_data, is_studied):
        """ç¿’å¾—åº¦ã‚’åˆ¤å®šï¼ˆå­¦ç¿’æ¸ˆã¿ã‚«ãƒ¼ãƒ‰ã®ã¿ï¼‰"""
        if not is_studied:
            return "æœªå­¦ç¿’"
        
        total_attempts = performance.get('total_attempts', 0)
        avg_quality = performance.get('avg_quality', 0)
        
        if level == 0:
            return "æ–°è¦å­¦ç¿’"
        elif level >= 4 and avg_quality >= 3.5:
            return "ç¿’å¾—æ¸ˆã¿"
        elif level >= 2 and avg_quality >= 3.0:
            return "ç·´ç¿’ä¸­"
        elif total_attempts >= 2 and avg_quality < 2.5:
            return "è¦å¾©ç¿’"
        else:
            return "å­¦ç¿’ä¸­"
    
    def _is_card_due(self, due_date):
        """ã‚«ãƒ¼ãƒ‰ãŒå¾©ç¿’æœŸé™ã«é”ã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        if not due_date:
            return True
        
        try:
            if hasattr(due_date, 'seconds'):
                due_dt = datetime.fromtimestamp(due_date.seconds)
            elif isinstance(due_date, str):
                due_dt = datetime.fromisoformat(due_date.replace('Z', '+00:00'))
                due_dt = due_dt.replace(tzinfo=None)
            else:
                due_dt = due_date
                if hasattr(due_dt, 'tzinfo') and due_dt.tzinfo is not None:
                    due_dt = due_dt.replace(tzinfo=None)
            
            return due_dt <= datetime.now()
        except:
            return True
    
    def _display_exam_specific_stats(self, card_data, exam_type, total_problems):
        """è©¦é¨“ç¨®åˆ¥å°‚ç”¨ã®è©³ç´°çµ±è¨ˆè¡¨ç¤º"""
        cards = card_data['cards']
        stats = card_data['stats']
        
        print(f"\nğŸ“ {exam_type} è©³ç´°çµ±è¨ˆ")
        print("=" * 60)
        
        # åŸºæœ¬çµ±è¨ˆ
        studied_cards = len([card for card in cards if card['is_studied']])
        unstudied_cards = stats.get('unstudied_cards', 0)
        
        print(f"ğŸ“Š åŸºæœ¬æƒ…å ±:")
        print(f"  ç·å•é¡Œæ•°ï¼ˆå…¨ä½“ï¼‰: {total_problems:,}å•")
        print(f"  ä¿æœ‰ã‚«ãƒ¼ãƒ‰æ•°: {len(cards) + unstudied_cards:,}æš")
        print(f"  å­¦ç¿’æ¸ˆã¿ã‚«ãƒ¼ãƒ‰: {studied_cards}æš")
        print(f"  æœªå­¦ç¿’ã‚«ãƒ¼ãƒ‰: {unstudied_cards}æš")
        print(f"  ã‚«ãƒãƒ¼ç‡: {((len(cards) + unstudied_cards) / total_problems * 100):.1f}%")
        print(f"  å­¦ç¿’é€²æ—ç‡: {(studied_cards / (len(cards) + unstudied_cards) * 100):.1f}%")
        
        if not cards:
            print(f"\nâŒ {exam_type}ã®å­¦ç¿’æ¸ˆã¿ã‚«ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ
        level_dist = Counter(card['level'] for card in cards)
        print(f"\nğŸ“ˆ ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ:")
        for level in sorted(level_dist.keys(), reverse=True):
            count = level_dist[level]
            percentage = (count / len(cards)) * 100
            print(f"  ãƒ¬ãƒ™ãƒ« {level}: {count}æš ({percentage:.1f}%)")
        
        # ç¿’å¾—åº¦åˆ†å¸ƒ
        mastery_dist = Counter(card['mastery_status'] for card in cards)
        print(f"\nğŸ¯ ç¿’å¾—åº¦åˆ†å¸ƒ:")
        for status, count in mastery_dist.most_common():
            percentage = (count / len(cards)) * 100
            print(f"  {status}: {count}æš ({percentage:.1f}%)")
        
        # ç§‘ç›®åˆ†å¸ƒ
        subject_dist = Counter(card['subject'] for card in cards)
        print(f"\nğŸ“š ç§‘ç›®åˆ†å¸ƒ:")
        for subject, count in subject_dist.most_common():
            percentage = (count / len(cards)) * 100
            print(f"  {subject}: {count}æš ({percentage:.1f}%)")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        accuracy_rates = [card['accuracy_rate'] for card in cards if card['total_attempts'] > 0]
        if accuracy_rates:
            avg_accuracy = sum(accuracy_rates) / len(accuracy_rates)
            print(f"\nğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ:")
            print(f"  å¹³å‡æ­£è§£ç‡: {avg_accuracy:.1%}")
            print(f"  å®Œç’§ã‚«ãƒ¼ãƒ‰: {sum(1 for rate in accuracy_rates if rate == 1.0)}æš")
            print(f"  è‹¦æ‰‹ã‚«ãƒ¼ãƒ‰: {sum(1 for rate in accuracy_rates if rate < 0.5)}æš")
        
        # å¾©ç¿’æœŸé™åˆ†æ
        due_cards = [card for card in cards if card['is_due']]
        print(f"\nâ° å¾©ç¿’æœŸé™åˆ†æ:")
        print(f"  å¾©ç¿’æœŸé™ã‚«ãƒ¼ãƒ‰: {len(due_cards)}æš")
        if due_cards:
            urgent_cards = [card for card in due_cards if card['level'] >= 2]  # ãƒ¬ãƒ™ãƒ«2ä»¥ä¸Šã§æœŸé™åˆ‡ã‚Œ
            print(f"  ç·Šæ€¥å¾©ç¿’ã‚«ãƒ¼ãƒ‰: {len(urgent_cards)}æš")
        
        # é«˜ãƒ¬ãƒ™ãƒ«ã‚«ãƒ¼ãƒ‰è©³ç´°
        high_level_cards = [card for card in cards if card['level'] >= 4]
        if high_level_cards:
            print(f"\nğŸ† ç¿’å¾—æ¸ˆã¿ã‚«ãƒ¼ãƒ‰è©³ç´°:")
            print(f"  ãƒ¬ãƒ™ãƒ«4ä»¥ä¸Š: {len(high_level_cards)}æš")
            for card in high_level_cards[:5]:  # æœ€åˆã®5æšã‚’è¡¨ç¤º
                print(f"    {card['question_id']}: ãƒ¬ãƒ™ãƒ«{card['level']}, æ­£è§£ç‡{card['accuracy_rate']:.1%}")
        
        # è¦å¾©ç¿’ã‚«ãƒ¼ãƒ‰è©³ç´°
        struggling_cards = [card for card in cards if card['mastery_status'] == 'è¦å¾©ç¿’']
        if struggling_cards:
            print(f"\nâš ï¸ è¦å¾©ç¿’ã‚«ãƒ¼ãƒ‰è©³ç´°:")
            print(f"  è¦å¾©ç¿’ã‚«ãƒ¼ãƒ‰: {len(struggling_cards)}æš")
            for card in struggling_cards[:5]:  # æœ€åˆã®5æšã‚’è¡¨ç¤º
                print(f"    {card['question_id']}: ãƒ¬ãƒ™ãƒ«{card['level']}, æ­£è§£ç‡{card['accuracy_rate']:.1%}, ç§‘ç›®:{card['subject']}")
    
    def generate_learning_report(self, uid, days=30):
        """ç·åˆå­¦ç¿’ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        try:
            print(f"ğŸ“‹ {uid} ã®å­¦ç¿’ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­ï¼ˆéå»{days}æ—¥é–“ï¼‰...")
            
            # æœŸé–“è¨­å®š
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            
            # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            evaluation_logs = self.extract_self_evaluation_logs(uid, start_date, end_date)
            practice_data = self.extract_practice_logs(uid, start_date, end_date)
            card_data = self.extract_card_levels(uid)
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = {
                'user_id': uid,
                'report_period': {
                    'start': start_date.strftime('%Y-%m-%d'),
                    'end': end_date.strftime('%Y-%m-%d'),
                    'days': days
                },
                'summary': {
                    'total_problems_solved': practice_data.get('total_problems', 0),
                    'total_sessions': practice_data.get('total_sessions', 0),
                    'accuracy_rate': practice_data.get('accuracy_rate', 0.0),
                    'total_cards_in_db': card_data['stats'].get('total_cards_in_db', 0),
                    'studied_cards': card_data['stats'].get('studied_cards', 0),
                    'unstudied_cards': card_data['stats'].get('unstudied_cards', 0),
                    'mastered_cards': card_data['stats'].get('high_level_cards', 0),
                    'due_cards': card_data['stats'].get('due_cards', 0)
                },
                'evaluation_logs': evaluation_logs,
                'practice_analytics': practice_data,
                'card_levels': card_data,
                'generated_at': datetime.now().isoformat()
            }
            
            print(f"âœ… å­¦ç¿’ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")
            return report
            
        except Exception as e:
            print(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return {}

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python user_data_extractor.py <user_id> [action]")
        print("action: evaluation_logs, practice_logs, card_levels, kokushi_levels, gakushi_levels, report")
        return
    
    uid = sys.argv[1]
    action = sys.argv[2] if len(sys.argv) > 2 else "report"
    
    extractor = UserDataExtractor()
    
    print(f"ğŸ¯ ãƒ¦ãƒ¼ã‚¶ãƒ¼: {uid}")
    print(f"ğŸ“Š ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {action}")
    print("=" * 70)
    
    if action == "evaluation_logs":
        logs = extractor.extract_self_evaluation_logs(uid)
        print(f"\nğŸ“Š è‡ªå·±è©•ä¾¡ãƒ­ã‚°ï¼ˆæœ€æ–°10ä»¶ï¼‰:")
        for log in logs[-10:]:
            print(f"  {log['timestamp'].strftime('%m/%d %H:%M')} - {log['question_id'][:8]}... - {log['quality_text']}")
    
    elif action == "practice_logs":
        practice = extractor.extract_practice_logs(uid)
        print(f"\nğŸ“ˆ æ¼”ç¿’çµ±è¨ˆ:")
        print(f"  ç·å•é¡Œæ•°: {practice.get('total_problems', 0)}")
        print(f"  ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {practice.get('total_sessions', 0)}")
        print(f"  æ­£è§£ç‡: {practice.get('accuracy_rate', 0):.1%}")
        print(f"  å­¦ç¿’æ—¥æ•°: {practice.get('study_period', {}).get('days', 0)}")
    
    elif action == "card_levels":
        card_data = extractor.extract_card_levels(uid)
        print(f"\nğŸ¯ ã‚«ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«çµ±è¨ˆ:")
        stats = card_data['stats']
        print(f"  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç·ã‚«ãƒ¼ãƒ‰æ•°: {stats.get('total_cards_in_db', 0)}")
        print(f"  å­¦ç¿’æ¸ˆã¿ã‚«ãƒ¼ãƒ‰æ•°: {stats.get('studied_cards', 0)}")
        print(f"  æœªå­¦ç¿’ã‚«ãƒ¼ãƒ‰æ•°: {stats.get('unstudied_cards', 0)}")
        print(f"  å¹³å‡ãƒ¬ãƒ™ãƒ«: {stats.get('avg_level', 0):.1f}")
        print(f"  ç¿’å¾—æ¸ˆã¿ã‚«ãƒ¼ãƒ‰: {stats.get('high_level_cards', 0)}")
        print(f"  å¾©ç¿’æœŸé™ã‚«ãƒ¼ãƒ‰: {stats.get('due_cards', 0)}")
        print(f"  å®Œç’§ã‚«ãƒ¼ãƒ‰: {stats.get('perfect_cards', 0)}")
        
        print(f"\nğŸ“Š è©¦é¨“ç¨®åˆ¥åˆ†å¸ƒ:")
        exam_dist = stats.get('exam_type_distribution', {})
        for exam_type, count in exam_dist.items():
            print(f"  {exam_type}: {count}æš")
        
        print(f"\nğŸ“ æ­¯ç§‘å›½è©¦é€²æ—:")
        kokushi_stats = stats.get('kokushi_stats', {})
        print(f"  ä¿æœ‰ã‚«ãƒ¼ãƒ‰: {kokushi_stats.get('total_cards', 0)}æš / 8,576å•")
        print(f"  ã‚«ãƒãƒ¼ç‡: {kokushi_stats.get('coverage_rate', 0):.1%}")
        print(f"  å­¦ç¿’æ¸ˆã¿: {kokushi_stats.get('studied_cards', 0)}æš")
        
        print(f"\nğŸ“ å­¦å£«è©¦é¨“é€²æ—:")
        gakushi_stats = stats.get('gakushi_stats', {})
        print(f"  ä¿æœ‰ã‚«ãƒ¼ãƒ‰: {gakushi_stats.get('total_cards', 0)}æš / 4,941å•")
        print(f"  ã‚«ãƒãƒ¼ç‡: {gakushi_stats.get('coverage_rate', 0):.1%}")
        print(f"  å­¦ç¿’æ¸ˆã¿: {gakushi_stats.get('studied_cards', 0)}æš")
        
        print(f"\nğŸ“ˆ ç¿’å¾—åº¦åˆ†å¸ƒ: {dict(stats.get('mastery_breakdown', {}))}")
    
    elif action == "kokushi_levels":
        card_data = extractor.extract_card_levels(uid, exam_type_filter="æ­¯ç§‘å›½è©¦")
        extractor._display_exam_specific_stats(card_data, "æ­¯ç§‘å›½è©¦", 8576)
    
    elif action == "gakushi_levels":
        card_data = extractor.extract_card_levels(uid, exam_type_filter="å­¦å£«è©¦é¨“")
        extractor._display_exam_specific_stats(card_data, "å­¦å£«è©¦é¨“", 4941)
    
    elif action == "report":
        report = extractor.generate_learning_report(uid)
        print(f"\nğŸ“‹ å­¦ç¿’ãƒ¬ãƒãƒ¼ãƒˆè¦ç´„:")
        summary = report.get('summary', {})
        print(f"  å•é¡Œè§£ç­”æ•°: {summary.get('total_problems_solved', 0)}")
        print(f"  å­¦ç¿’ã‚»ãƒƒã‚·ãƒ§ãƒ³: {summary.get('total_sessions', 0)}")
        print(f"  æ­£è§£ç‡: {summary.get('accuracy_rate', 0):.1%}")
        print(f"  å­¦ç¿’æ¸ˆã¿ã‚«ãƒ¼ãƒ‰: {summary.get('studied_cards', 0)} / {summary.get('total_cards_in_db', 0)}")
        print(f"  ç¿’å¾—ã‚«ãƒ¼ãƒ‰: {summary.get('mastered_cards', 0)}")
        print(f"  å¾©ç¿’æœŸé™ã‚«ãƒ¼ãƒ‰: {summary.get('due_cards', 0)}")
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        filename = f"learning_report_{uid}_{datetime.now().strftime('%Y%m%d')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        print(f"  ğŸ’¾ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()
