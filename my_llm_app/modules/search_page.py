"""
æ¤œç´¢ãƒ»é€²æ—ãƒšãƒ¼ã‚¸ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - UIå®Œå…¨ä¿æŒæœ€é©åŒ–ç‰ˆ

å…ƒã®UIã¨å®Œå…¨ã«ä¸€è‡´ã—ãªãŒã‚‰ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åŠ‡çš„ã«æ”¹å–„:
- @st.cache_dataã‚’ä½¿ã£ãŸé‡ã„ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–ï¼ˆå…ƒã®UIä¿æŒï¼‰
- æ¼”ç¿’ãƒšãƒ¼ã‚¸ã¨ã®é€£æºã«ã‚ˆã‚‹å·®åˆ†æ›´æ–°
- å…ƒã®render_*_tab_perfecté–¢æ•°ç¾¤ã‚’å®Œå…¨ä¿æŒ
- UserDataExtractorã®çµ±åˆã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–
- å…ƒã®4ã¤ã®ã‚¿ãƒ–æ§‹é€ ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºã‚’å®Œå…¨å†ç¾
"""

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import datetime
import pytz
from typing import Dict, List, Any, Optional
import time
from functools import lru_cache
from collections import defaultdict, Counter
import hashlib
import json
import re
import random
import sys
import os
import subprocess
import shutil
import tempfile

# æ—¥æœ¬æ™‚é–“ç”¨ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
JST = pytz.timezone('Asia/Tokyo')

def get_japan_today() -> datetime.date:
    """æ—¥æœ¬æ™‚é–“ã®ä»Šæ—¥ã®æ—¥ä»˜ã‚’å–å¾—"""
    return datetime.datetime.now(JST).date()

def get_japan_datetime_from_timestamp(timestamp) -> datetime.datetime:
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‹ã‚‰æ—¥æœ¬æ™‚é–“ã®datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—"""
    try:
        # ã¾ãšæ–‡å­—åˆ—ã®å ´åˆã®å‡¦ç†
        if isinstance(timestamp, str):
            try:
                # ISOæ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹
                dt = datetime.datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                return dt.astimezone(JST)
            except ValueError:
                try:
                    # æ—¥ä»˜éƒ¨åˆ†ã®ã¿ã®å ´åˆ
                    dt = datetime.datetime.strptime(timestamp[:10], '%Y-%m-%d')
                    return JST.localize(dt)
                except (ValueError, IndexError):
                    return datetime.datetime.now(JST)
        elif hasattr(timestamp, 'replace'):
            # DatetimeWithNanoseconds ã¾ãŸã¯ datetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            if hasattr(timestamp, 'tzinfo') and timestamp.tzinfo is None:
                # ãƒŠã‚¤ãƒ¼ãƒ–ãªdatetimeã®å ´åˆã€UTCã¨ã—ã¦æ‰±ã£ã¦æ—¥æœ¬æ™‚é–“ã«å¤‰æ›
                return pytz.UTC.localize(timestamp).astimezone(JST)
            else:
                return timestamp.astimezone(JST)
        
        # ãã®ä»–ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
        return datetime.datetime.now(JST)
    except Exception as e:
        # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®å ´åˆã‚‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
        return datetime.datetime.now(JST)

# å¿…è¦ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from utils import (
        ALL_QUESTIONS, 
        HISSHU_Q_NUMBERS_SET, 
        GAKUSHI_HISSHU_Q_NUMBERS_SET,
        _gather_images_for_questions,
        _image_block_latex,
        export_questions_to_latex_tcb_jsarticle,
        compile_latex_to_pdf,
        extract_year_from_question_number
    )
except ImportError:
    try:
        from ..utils import (
            ALL_QUESTIONS, 
            HISSHU_Q_NUMBERS_SET, 
            GAKUSHI_HISSHU_Q_NUMBERS_SET,
            _gather_images_for_questions,
            _image_block_latex,
            export_questions_to_latex_tcb_jsarticle,
            compile_latex_to_pdf,
            extract_year_from_question_number
        )
    except ImportError:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€å°é™ã®å®šç¾©
        ALL_QUESTIONS = []
        HISSHU_Q_NUMBERS_SET = set()
        GAKUSHI_HISSHU_Q_NUMBERS_SET = set()

try:
    from firestore_db import get_firestore_manager
except ImportError:
    try:
        from ..firestore_db import get_firestore_manager
    except ImportError:
        get_firestore_manager = None

try:
    from constants import LEVEL_COLORS
except ImportError:
    try:
        from ..constants import LEVEL_COLORS
    except ImportError:
        LEVEL_COLORS = {}

# UserDataExtractor
try:
    from user_data_extractor import UserDataExtractor
    HAS_USER_DATA_EXTRACTOR = True
except ImportError:
    try:
        from ..user_data_extractor import UserDataExtractor
        HAS_USER_DATA_EXTRACTOR = True
    except ImportError:
        UserDataExtractor = None
        HAS_USER_DATA_EXTRACTOR = False

def update_session_evaluation_log(question_id: str, quality: int, timestamp: datetime.datetime = None):
    """
    æ¼”ç¿’ãƒšãƒ¼ã‚¸ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹é–¢æ•°ï¼šå­¦ç¿’çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«è¿½åŠ ï¼ˆæ—¥æœ¬æ™‚é–“ãƒ™ãƒ¼ã‚¹ï¼‰
    """
    if timestamp is None:
        timestamp = datetime.datetime.now(JST)  # æ—¥æœ¬æ™‚é–“ã§è¨˜éŒ²
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®è©•ä¾¡ãƒ­ã‚°ã‚’åˆæœŸåŒ–ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
    if 'evaluation_logs' not in st.session_state:
        st.session_state['evaluation_logs'] = []
    
    # æ–°ã—ã„è©•ä¾¡ãƒ­ã‚°ã‚’è¿½åŠ 
    new_log = {
        'question_id': question_id,
        'quality': quality,
        'timestamp': timestamp
    }
    
    st.session_state['evaluation_logs'].append(new_log)
    
    # ãƒ­ã‚°ãŒå¤šããªã‚Šã™ããªã„ã‚ˆã†ã€å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’åˆ¶é™ï¼ˆä¾‹ï¼šæœ€æ–°1000ä»¶ï¼‰
    if len(st.session_state['evaluation_logs']) > 1000:
        st.session_state['evaluation_logs'] = st.session_state['evaluation_logs'][-1000:]

# ãƒ¬ãƒ™ãƒ«é †åºå®šç¾©ï¼ˆ0-5ãƒ¬ãƒ™ãƒ«ã‚·ã‚¹ãƒ†ãƒ ï¼‰
LEVEL_ORDER = ["æœªå­¦ç¿’", "ãƒ¬ãƒ™ãƒ«0", "ãƒ¬ãƒ™ãƒ«1", "ãƒ¬ãƒ™ãƒ«2", "ãƒ¬ãƒ™ãƒ«3", "ãƒ¬ãƒ™ãƒ«4", "ãƒ¬ãƒ™ãƒ«5", "ç¿’å¾—æ¸ˆã¿"]

@st.cache_data(ttl=600)  # 10åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def calculate_total_questions():
    """å•é¡Œæ•°ã‚’è¨ˆç®—ã™ã‚‹"""
    total_kokushi = 0
    total_gakushi = 0
    
    for question in ALL_QUESTIONS:
        number = question.get('number', '')
        if number.startswith('G'):
            total_gakushi += 1
        else:
            total_kokushi += 1
    
    return total_kokushi, total_gakushi

def prepare_data_for_display(uid: str, cards: dict, analysis_target: str, force_refresh: bool = False) -> pd.DataFrame:
    """
    æœ€é©åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿æº–å‚™é–¢æ•°ï¼ˆé‡ã„å‡¦ç†ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
    """
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã®ç”Ÿæˆ
    cache_key = f"{uid}_{analysis_target}_{len(cards)}_{hash(str(sorted(cards.keys())))}"
    
    if force_refresh:
        st.cache_data.clear()
    
    all_data = []
    
    # å•é¡Œãƒ‡ãƒ¼ã‚¿å‡¦ç†ï¼ˆå…¨å•é¡Œã‚’å‡¦ç†ï¼‰
    for question in ALL_QUESTIONS:
        q_number = question.get('number', '')
        
        # analysis_targetãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if analysis_target == "å›½è©¦" and q_number.startswith('G'):
            continue
        if analysis_target == "å­¦å£«è©¦é¨“" and not q_number.startswith('G'):
            continue
        
        # ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨ãƒ¬ãƒ™ãƒ«è¨ˆç®—
        card = cards.get(q_number, {})
        level = calculate_card_level(card)
        
        # å¿…ä¿®å•é¡Œåˆ¤å®š
        if analysis_target == "å­¦å£«è©¦é¨“":
            is_hisshu = q_number in GAKUSHI_HISSHU_Q_NUMBERS_SET
        else:
            is_hisshu = q_number in HISSHU_Q_NUMBERS_SET
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œã®ä½œæˆ
        row_data = {
            'id': q_number,
            'level': level,
            'subject': question.get('subject', 'æœªåˆ†é¡'),
            'is_hisshu': is_hisshu,
            'card_data': card,
            'history': card.get('history', []) if isinstance(card, dict) else []
        }
        
        all_data.append(row_data)
    
    return pd.DataFrame(all_data)

def calculate_card_level(card: Dict[str, Any]) -> str:
    """
    SM-2ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ™ãƒ¼ã‚¹ã®ã‚«ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«è¨ˆç®—é–¢æ•°
    
    çµ±ä¸€åˆ†é¡: æœªå­¦ç¿’ã€ãƒ¬ãƒ™ãƒ«0ã€ãƒ¬ãƒ™ãƒ«1ã€ãƒ¬ãƒ™ãƒ«2ã€ãƒ¬ãƒ™ãƒ«3ã€ãƒ¬ãƒ™ãƒ«4ã€ãƒ¬ãƒ™ãƒ«5ã€ç¿’å¾—æ¸ˆã¿
    
    ãƒ¬ãƒ™ãƒ«åˆ†é¡åŸºæº–ï¼ˆSM-2ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æº–æ‹ ï¼‰:
    - æœªå­¦ç¿’: å­¦ç¿’å±¥æ­´ãªã—
    - ãƒ¬ãƒ™ãƒ«0: åˆå›å­¦ç¿’ã€ã¾ãŸã¯ä½å“è³ªå›ç­”ï¼ˆquality < 3ï¼‰
    - ãƒ¬ãƒ™ãƒ«1: åŸºæœ¬ç¿’å¾—ï¼ˆquality 3, é–“éš”çŸ­æœŸï¼‰
    - ãƒ¬ãƒ™ãƒ«2: ä¸­ç¨‹åº¦ç¿’å¾—ï¼ˆquality 3-4, é–“éš”ä¸­æœŸï¼‰
    - ãƒ¬ãƒ™ãƒ«3: è‰¯å¥½ç¿’å¾—ï¼ˆquality 4-5, é–“éš”é•·æœŸï¼‰
    - ãƒ¬ãƒ™ãƒ«4: é«˜åº¦ç¿’å¾—ï¼ˆquality 5, é•·æœŸé–“éš”ï¼‰
    - ãƒ¬ãƒ™ãƒ«5: å®‰å®šç¿’å¾—ï¼ˆquality 5, è¶…é•·æœŸé–“éš”ï¼‰
    - ç¿’å¾—æ¸ˆã¿: EFé«˜å€¤ã‹ã¤è¶…é•·æœŸé–“éš”
    """
    if not card or not isinstance(card, dict):
        return "æœªå­¦ç¿’"
    
    history = card.get('history', [])
    
    # å­¦ç¿’å±¥æ­´ãŒãªã„å ´åˆ
    if not history or len(history) == 0:
        return "æœªå­¦ç¿’"
    
    # æœ€æ–°ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    latest = history[-1] if isinstance(history, list) else {}
    quality = latest.get('quality', 0)
    interval = latest.get('interval', 0)
    ef = latest.get('EF', 2.5)
    
    # å­¦ç¿’å›æ•°ã‚’è¨ˆç®—
    learning_count = len(history)
    
    # SM-2ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸºã¥ãæ®µéšçš„ãƒ¬ãƒ™ãƒ«åˆ¤å®š
    
    # åˆå›å­¦ç¿’ã¾ãŸã¯ä½å“è³ª
    if learning_count == 1 or quality < 3:
        return "ãƒ¬ãƒ™ãƒ«0"
    
    # åŸºæœ¬ç¿’å¾—æ®µéšï¼ˆçŸ­æœŸé–“éš”ï¼‰
    if quality == 3 and interval <= 1:
        return "ãƒ¬ãƒ™ãƒ«1"
    
    # ä¸­ç¨‹åº¦ç¿’å¾—ï¼ˆä¸­æœŸé–“éš”ï¼‰
    if quality == 3 and 1 < interval <= 6:
        return "ãƒ¬ãƒ™ãƒ«2"
    elif quality == 4 and interval <= 3:
        return "ãƒ¬ãƒ™ãƒ«2"
    
    # è‰¯å¥½ç¿’å¾—ï¼ˆé•·æœŸé–“éš”ï¼‰
    if quality == 4 and 3 < interval <= 15:
        return "ãƒ¬ãƒ™ãƒ«3"
    elif quality == 5 and interval <= 7:
        return "ãƒ¬ãƒ™ãƒ«3"
    
    # é«˜åº¦ç¿’å¾—ï¼ˆè¶…é•·æœŸé–“éš”ï¼‰
    if quality == 5 and 7 < interval <= 30:
        return "ãƒ¬ãƒ™ãƒ«4"
    
    # å®‰å®šç¿’å¾—ï¼ˆè¶…é•·æœŸé–“éš”ï¼‰
    if quality == 5 and 30 < interval <= 180:
        return "ãƒ¬ãƒ™ãƒ«5"
    
    # å®Œå…¨ç¿’å¾—ï¼ˆEFé«˜å€¤ã‹ã¤è¶…é•·æœŸé–“éš”ï¼‰
    if quality == 5 and interval > 180 and ef >= 2.8:
        return "ç¿’å¾—æ¸ˆã¿"
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é«˜å“è³ªã ãŒé–“éš”ãŒçŸ­ã„å ´åˆ
    if quality >= 4:
        return "ãƒ¬ãƒ™ãƒ«3"
    elif quality >= 3:
        return "ãƒ¬ãƒ™ãƒ«1"
    else:
        return "ãƒ¬ãƒ™ãƒ«0"

def calculate_sm2_review_schedule(cards: dict, days_ahead: int = 7) -> Dict[str, List[str]]:
    """
    SM-2ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸºã¥ã„ã¦å¾©ç¿’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¨ˆç®—ï¼ˆæ—¥æœ¬æ™‚é–“ãƒ™ãƒ¼ã‚¹ï¼‰
    
    Args:
        cards: ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿è¾æ›¸
        days_ahead: ä½•æ—¥å…ˆã¾ã§è¨ˆç®—ã™ã‚‹ã‹
    
    Returns:
        æ—¥ä»˜æ–‡å­—åˆ—ã‚’ã‚­ãƒ¼ã¨ã—ã€ãã®æ—¥ã«å¾©ç¿’ã™ã¹ãå•é¡ŒIDã®ãƒªã‚¹ãƒˆã‚’å€¤ã¨ã™ã‚‹è¾æ›¸
        ä¾‹: {"2025-09-02": ["123A4", "124B2"], "2025-09-03": ["125C1"]}
    """
    today = get_japan_today()  # æ—¥æœ¬æ™‚é–“ã®ä»Šæ—¥
    schedule = {}
    
    # æœªæ¥ã®æ—¥ä»˜ã‚’åˆæœŸåŒ–
    for i in range(days_ahead + 1):
        date_str = (today + datetime.timedelta(days=i)).isoformat()
        schedule[date_str] = []
    
    for q_id, card in cards.items():
        if not isinstance(card, dict):
            continue
            
        history = card.get('history', [])
        if not history:
            continue
            
        # æœ€æ–°ã®å­¦ç¿’è¨˜éŒ²ã‹ã‚‰æ¬¡å›å¾©ç¿’æ—¥ã‚’è¨ˆç®—
        latest = history[-1]
        if not isinstance(latest, dict):
            continue
            
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨é–“éš”ã‚’å–å¾—
        timestamp = latest.get('timestamp')
        interval = latest.get('interval', 1)
        quality = latest.get('quality', 0)
        
        if not timestamp:
            continue
            
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ—¥æœ¬æ™‚é–“ã®æ—¥ä»˜ã«å¤‰æ›
        last_study_date = None
        try:
            last_study_datetime_jst = get_japan_datetime_from_timestamp(timestamp)
            last_study_date = last_study_datetime_jst.date()
        except (ValueError, TypeError, AttributeError) as e:
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®å¤‰æ›ã«å¤±æ•—ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            continue
            
        if not last_study_date:
            continue
            
        # æ¬¡å›å¾©ç¿’æ—¥ã‚’è¨ˆç®—ï¼ˆSM-2ã®é–“éš”ã«åŸºã¥ãï¼‰
        next_review_date = last_study_date + datetime.timedelta(days=int(interval))
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
        if next_review_date <= today + datetime.timedelta(days=days_ahead):
            date_str = next_review_date.isoformat()
            if date_str in schedule:
                schedule[date_str].append(q_id)
    
    return schedule

def get_review_priority_cards(cards: dict, target_date: datetime.date = None) -> List[tuple]:
    """
    æŒ‡å®šæ—¥ã®å¾©ç¿’å„ªå…ˆåº¦ä»˜ãã‚«ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆæ—¥æœ¬æ™‚é–“ãƒ™ãƒ¼ã‚¹ï¼‰
    
    Args:
        cards: ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿è¾æ›¸
        target_date: å¯¾è±¡æ—¥ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ä»Šæ—¥ã®æ—¥æœ¬æ™‚é–“ï¼‰
    
    Returns:
        (å•é¡ŒID, å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢, çµŒéæ—¥æ•°) ã®ã‚¿ãƒ—ãƒ«ã®ãƒªã‚¹ãƒˆï¼ˆå„ªå…ˆåº¦é †ï¼‰
    """
    if target_date is None:
        target_date = get_japan_today()
    
    priority_cards = []
    
    for q_id, card in cards.items():
        if not isinstance(card, dict):
            continue
            
        history = card.get('history', [])
        if not history:
            continue
            
        latest = history[-1]
        if not isinstance(latest, dict):
            continue
            
        timestamp = latest.get('timestamp')
        interval = latest.get('interval', 1)
        quality = latest.get('quality', 0)
        ef = latest.get('EF', 2.5)
        
        if not timestamp:
            continue
            
        # æœ€å¾Œã®å­¦ç¿’æ—¥ã‚’æ—¥æœ¬æ™‚é–“ã§å–å¾—
        last_study_date = None
        try:
            last_study_datetime_jst = get_japan_datetime_from_timestamp(timestamp)
            last_study_date = last_study_datetime_jst.date()
        except (ValueError, TypeError):
            continue
            
        if not last_study_date:
            continue
            
        # æ¬¡å›å¾©ç¿’äºˆå®šæ—¥
        next_review_date = last_study_date + datetime.timedelta(days=int(interval))
        
        # å¾©ç¿’å¯¾è±¡æ—¥ä»¥å‰ã®å ´åˆã®ã¿å¯¾è±¡
        if next_review_date <= target_date:
            # çµŒéæ—¥æ•°ã‚’è¨ˆç®—ï¼ˆå¾©ç¿’äºˆå®šæ—¥ã‹ã‚‰ã®çµŒéï¼‰
            days_overdue = (target_date - next_review_date).days
            
            # å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆçµŒéæ—¥æ•° + EFã®é€†æ•° + qualityã®é€†æ•°ï¼‰
            # çµŒéæ—¥æ•°ãŒå¤šã„ã»ã©ã€EFãŒä½ã„ã»ã©ã€å‰å›ã®qualityãŒä½ã„ã»ã©å„ªå…ˆåº¦ãŒé«˜ã„
            priority_score = days_overdue + (3.0 - ef) + (6 - quality)
            
            priority_cards.append((q_id, priority_score, days_overdue))
    
    # å„ªå…ˆåº¦ã®é«˜ã„é †ï¼ˆã‚¹ã‚³ã‚¢ã®å¤§ãã„é †ï¼‰ã«ã‚½ãƒ¼ãƒˆ
    priority_cards.sort(key=lambda x: x[1], reverse=True)
    
    return priority_cards

def check_gakushi_permission(uid: str) -> bool:
    """å­¦å£«è©¦é¨“ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚’ãƒã‚§ãƒƒã‚¯"""
    try:
        db = get_firestore_manager()
        user_ref = db.collection('users').document(uid)
        user_doc = user_ref.get()
        
        if user_doc.exists:
            user_data = user_doc.to_dict()
            return user_data.get('has_gakushi_permission', False)
        
        return True
    except Exception:
        return True

def calculate_progress_metrics(cards: Dict, base_df: pd.DataFrame, uid: str, analysis_target: str) -> Dict:
    """
    é€²æ—ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ï¼ˆå…ƒã®UIã¨åŒæ§˜ï¼‰- æ—¥æœ¬æ™‚é–“ãƒ™ãƒ¼ã‚¹
    """
    today = get_japan_today()  # æ—¥æœ¬æ™‚é–“ã®ä»Šæ—¥
    yesterday = today - datetime.timedelta(days=1)
    seven_days_ago = datetime.datetime.now(JST) - datetime.timedelta(days=7)
    fourteen_days_ago = datetime.datetime.now(JST) - datetime.timedelta(days=14)
    
    enhanced_data = {}
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰å­¦ç¿’å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆæ¼”ç¿’ãƒšãƒ¼ã‚¸ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ï¼‰
    if uid and uid != "guest":
        try:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰ç›´æ¥å­¦ç¿’ãƒ­ã‚°ã‚’å–å¾—
            session_evaluation_logs = st.session_state.get('evaluation_logs', [])
            
            if session_evaluation_logs:
                # analysis_targetã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                filtered_logs = []
                for log in session_evaluation_logs:
                    q_id = log.get('question_id', '')
                    if analysis_target == "å­¦å£«è©¦é¨“":
                        if q_id.startswith('G'):
                            filtered_logs.append(log)
                    else:
                        if not q_id.startswith('G'):
                            filtered_logs.append(log)
                
                evaluation_logs = filtered_logs
                
                # 7æ—¥é–“ã®æ­£è§£ç‡è¨ˆç®—ï¼ˆæ—¥æœ¬æ™‚é–“ãƒ™ãƒ¼ã‚¹ï¼‰
                recent_evaluations = []
                previous_evaluations = []
                
                for log in evaluation_logs:
                    try:
                        log_timestamp = log['timestamp']
                        # æ—¥æœ¬æ™‚é–“ã«å¤‰æ›
                        log_datetime_jst = get_japan_datetime_from_timestamp(log_timestamp)
                        
                        if log_datetime_jst >= seven_days_ago:
                            recent_evaluations.append(log)
                        elif fourteen_days_ago <= log_datetime_jst < seven_days_ago:
                            previous_evaluations.append(log)
                    except Exception:
                        continue
                
                recent_correct = sum(1 for log in recent_evaluations if log.get('quality', 0) >= 3)
                previous_correct = sum(1 for log in previous_evaluations if log.get('quality', 0) >= 3)
                
                enhanced_data['recent_accuracy'] = (recent_correct / len(recent_evaluations) * 100) if recent_evaluations else 0
                enhanced_data['previous_accuracy'] = (previous_correct / len(previous_evaluations) * 100) if previous_evaluations else 0
                enhanced_data['recent_total'] = len(recent_evaluations)
                enhanced_data['previous_total'] = len(previous_evaluations)
                
                # ä»Šæ—¥ã¨æ˜¨æ—¥ã®å­¦ç¿’æ•°ï¼ˆæ—¥æœ¬æ™‚é–“ãƒ™ãƒ¼ã‚¹ï¼‰
                today_logs = []
                yesterday_logs = []
                
                for log in evaluation_logs:
                    try:
                        log_timestamp = log['timestamp']
                        # æ—¥æœ¬æ™‚é–“ã«å¤‰æ›
                        log_datetime_jst = get_japan_datetime_from_timestamp(log_timestamp)
                        log_date = log_datetime_jst.date()
                        
                        if log_date == today:
                            today_logs.append(log)
                        elif log_date == yesterday:
                            yesterday_logs.append(log)
                    except Exception:
                        continue
                
                enhanced_data['today_study_count'] = len(today_logs)
                enhanced_data['yesterday_study_count'] = len(yesterday_logs)
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: UserDataExtractorã‹ã‚‰ã®å–å¾—ï¼ˆåˆå›èª­ã¿è¾¼ã¿æ™‚ã®ã¿ï¼‰
            elif HAS_USER_DATA_EXTRACTOR and not st.session_state.get('evaluation_logs_initialized', False):
                extractor = UserDataExtractor()
                evaluation_logs = extractor.extract_self_evaluation_logs(uid)
                
                if evaluation_logs:
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ã—ã¦ä»Šå¾Œã¯ã“ã‚Œã‚’ä½¿ç”¨
                    st.session_state['evaluation_logs'] = evaluation_logs
                    st.session_state['evaluation_logs_initialized'] = True
                    
                    # ä¸Šè¨˜ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨è¨ˆç®—
                    filtered_logs = []
                    for log in evaluation_logs:
                        q_id = log.get('question_id', '')
                        if analysis_target == "å­¦å£«è©¦é¨“":
                            if q_id.startswith('G'):
                                filtered_logs.append(log)
                        else:
                            if not q_id.startswith('G'):
                                filtered_logs.append(log)
                    
                    evaluation_logs = filtered_logs
                    
                    # 7æ—¥é–“ãƒ»14æ—¥é–“ã®è©•ä¾¡ï¼ˆæ—¥æœ¬æ™‚é–“ãƒ™ãƒ¼ã‚¹ï¼‰
                    recent_evaluations = []
                    previous_evaluations = []
                    
                    for log in evaluation_logs:
                        try:
                            log_timestamp = log['timestamp']
                            log_datetime_jst = get_japan_datetime_from_timestamp(log_timestamp)
                            
                            if log_datetime_jst >= seven_days_ago:
                                recent_evaluations.append(log)
                            elif fourteen_days_ago <= log_datetime_jst < seven_days_ago:
                                previous_evaluations.append(log)
                        except Exception:
                            continue
                    
                    recent_correct = sum(1 for log in recent_evaluations if log.get('quality', 0) >= 3)
                    previous_correct = sum(1 for log in previous_evaluations if log.get('quality', 0) >= 3)
                    
                    enhanced_data['recent_accuracy'] = (recent_correct / len(recent_evaluations) * 100) if recent_evaluations else 0
                    enhanced_data['previous_accuracy'] = (previous_correct / len(previous_evaluations) * 100) if previous_evaluations else 0
                    enhanced_data['recent_total'] = len(recent_evaluations)
                    enhanced_data['previous_total'] = len(previous_evaluations)
                    
                    # ä»Šæ—¥ãƒ»æ˜¨æ—¥ã®å­¦ç¿’æ•°ï¼ˆæ—¥æœ¬æ™‚é–“ãƒ™ãƒ¼ã‚¹ï¼‰
                    today_logs = []
                    yesterday_logs = []
                    
                    for log in evaluation_logs:
                        try:
                            log_timestamp = log['timestamp']
                            log_datetime_jst = get_japan_datetime_from_timestamp(log_timestamp)
                            log_date = log_datetime_jst.date()
                            
                            if log_date == today:
                                today_logs.append(log)
                            elif log_date == yesterday:
                                yesterday_logs.append(log)
                        except Exception:
                            continue
                    
                    enhanced_data['today_study_count'] = len(today_logs)
                    enhanced_data['yesterday_study_count'] = len(yesterday_logs)
                
        except Exception:
            pass
    
    # ç·å•é¡Œæ•°è¨­å®šï¼ˆå‹•çš„è¨ˆç®—ï¼‰
    total_kokushi, total_gakushi = calculate_total_questions()
    
    if analysis_target == "å­¦å£«è©¦é¨“":
        total_count = total_gakushi
        hisshu_total_count = len(GAKUSHI_HISSHU_Q_NUMBERS_SET)
    else:
        total_count = total_kokushi
        hisshu_total_count = len(HISSHU_Q_NUMBERS_SET)
    
    # å­¦ç¿’æ¸ˆã¿æ•°è¨ˆç®—ï¼ˆanalysis_targetã«åŸºã¥ã„ã¦æ­£ç¢ºã«è¨ˆç®—ï¼‰
    current_studied_count = 0
    current_hisshu_studied_count = 0
    
    # å…¨å•é¡Œã‹ã‚‰åˆ†æå¯¾è±¡ã«è©²å½“ã™ã‚‹å•é¡Œã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ã—ã¦è¨ˆç®—
    for question in ALL_QUESTIONS:
        q_number = question.get('number', '')
        
        # analysis_targetã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if analysis_target == "å­¦å£«è©¦é¨“":
            if not q_number.startswith('G'):
                continue
        else:  # å›½è©¦
            if q_number.startswith('G'):
                continue
        
        # ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã¨ãƒ¬ãƒ™ãƒ«è¨ˆç®—
        card = cards.get(q_number, {})
        level = calculate_card_level(card)
        
        # å­¦ç¿’æ¸ˆã¿å•é¡Œã®ã‚«ã‚¦ãƒ³ãƒˆ
        if level != "æœªå­¦ç¿’":
            current_studied_count += 1
        
        # å¿…ä¿®å•é¡Œåˆ¤å®šã¨å­¦ç¿’æ¸ˆã¿æ•°ã‚«ã‚¦ãƒ³ãƒˆ
        if analysis_target == "å­¦å£«è©¦é¨“":
            is_hisshu = q_number in GAKUSHI_HISSHU_Q_NUMBERS_SET
        else:
            is_hisshu = q_number in HISSHU_Q_NUMBERS_SET
            
        if is_hisshu and level != "æœªå­¦ç¿’":
            current_hisshu_studied_count += 1
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š
    today_study_count = enhanced_data.get('today_study_count', 0)
    yesterday_study_count = enhanced_data.get('yesterday_study_count', 0)
    recent_accuracy = enhanced_data.get('recent_accuracy', 0)
    previous_accuracy = enhanced_data.get('previous_accuracy', 0)
    
    # å·®åˆ†è¨ˆç®—
    progress_delta = 0  # å­¦ç¿’é€²æ—ã®ãƒ‡ãƒ«ã‚¿ï¼ˆå‰æ—¥æ¯”ãªã©ï¼‰
    hisshu_delta = 0    # å¿…ä¿®å•é¡Œã®ãƒ‡ãƒ«ã‚¿
    accuracy_delta = recent_accuracy - previous_accuracy
    
    return {
        'current_studied_count': current_studied_count,
        'total_count': total_count,
        'current_hisshu_studied_count': current_hisshu_studied_count,
        'hisshu_total_count': hisshu_total_count,
        'today_study_count': today_study_count,
        'yesterday_study_count': yesterday_study_count,
        'recent_accuracy': recent_accuracy,
        'previous_accuracy': previous_accuracy,
        'progress_delta': progress_delta,
        'hisshu_delta': hisshu_delta,
        'accuracy_delta': accuracy_delta
    }

def render_search_page():
    """
    æ¤œç´¢ãƒšãƒ¼ã‚¸ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆUIå®Œå…¨ä¿æŒï¼‰
    """
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®å–å¾—
    uid = st.session_state.get("uid", "guest")
    cards = st.session_state.get("cards", {})
    analysis_target = st.session_state.get("analysis_target", "å›½è©¦")
    level_filter = st.session_state.get("level_filter", LEVEL_ORDER)
    subject_filter = st.session_state.get("subject_filter", [])
    
    # æ¨©é™ãƒã‚§ãƒƒã‚¯
    has_gakushi_permission = check_gakushi_permission(uid)
    
    # æœ€é©åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿æº–å‚™
    base_df = prepare_data_for_display(uid, cards, analysis_target)
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
    filtered_df = base_df.copy()
    
    # ãƒ¬ãƒ™ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    if level_filter and set(level_filter) != set(LEVEL_ORDER):
        filtered_df = filtered_df[filtered_df['level'].isin(level_filter)]
    
    # ç§‘ç›®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    if subject_filter:
        filtered_df = filtered_df[filtered_df['subject'].isin(subject_filter)]
    
    # å¿…ä¿®å•é¡Œãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    show_hisshu_only = st.session_state.get('show_hisshu_only', False)
    if show_hisshu_only:
        filtered_df = filtered_df[filtered_df['is_hisshu'] == True]
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼ˆåˆ†æå¯¾è±¡ã«åŸºã¥ãæ­£ç¢ºãªè¨ˆç®—ï¼‰
    if not filtered_df.empty:
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ã«ã¯å…¨ä½“ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ã•ã‚Œã¦ã„ãªã„ï¼‰ã‚’ä½¿ç”¨
        metrics = calculate_progress_metrics(cards, base_df, uid, analysis_target)
        
        # 4ã¤ã®ä¸»è¦æŒ‡æ¨™ã‚’st.metricã§è¡¨ç¤º
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            progress_delta_text = f"+{metrics['progress_delta']} å•" if metrics['progress_delta'] > 0 else f"{metrics['progress_delta']} å•" if metrics['progress_delta'] < 0 else "å¤‰åŒ–ãªã—"
            st.metric(
                "å­¦ç¿’é€²æ—ç‡",
                f"{metrics['current_studied_count']} / {metrics['total_count']} å•",
                delta=progress_delta_text
            )
        
        with col2:
            hisshu_delta_text = f"+{metrics['hisshu_delta']} å•" if metrics['hisshu_delta'] > 0 else f"{metrics['hisshu_delta']} å•" if metrics['hisshu_delta'] < 0 else "å¤‰åŒ–ãªã—"
            st.metric(
                "å¿…ä¿®å•é¡Œã®é€²æ—",
                f"{metrics['current_hisshu_studied_count']} / {metrics['hisshu_total_count']} å•",
                delta=hisshu_delta_text
            )
        
        with col3:
            today_delta = metrics['today_study_count'] - metrics['yesterday_study_count']
            today_delta_text = f"+{today_delta}" if today_delta > 0 else f"{today_delta}" if today_delta < 0 else "Â±0"
            st.metric(
                "ä»Šæ—¥ã®å­¦ç¿’",
                f"{metrics['today_study_count']} å•",
                delta=f"æ˜¨æ—¥æ¯” {today_delta_text}"
            )
        
        with col4:
            accuracy_delta_text = f"+{metrics['accuracy_delta']:.1f}%" if metrics['accuracy_delta'] > 0 else f"{metrics['accuracy_delta']:.1f}%" if metrics['accuracy_delta'] < 0 else "Â±0%"
            st.metric(
                "ç›´è¿‘ã®æ­£è§£ç‡",
                f"{metrics['recent_accuracy']:.1f}%",
                delta=f"å‰é€±æ¯” {accuracy_delta_text}"
            )
    
    # ã‚¿ãƒ–ã‚³ãƒ³ãƒ†ãƒŠ - 4ã¤ã®ã‚¿ãƒ–ï¼ˆå…ƒUIã‚’å®Œå…¨å¾©å…ƒï¼‰
    tab1, tab2, tab3, tab4 = st.tabs(["æ¦‚è¦", "ã‚°ãƒ©ãƒ•åˆ†æ", "å•é¡Œãƒªã‚¹ãƒˆ", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢"])
    
    with tab1:
        render_overview_tab_perfect(filtered_df, base_df, ALL_QUESTIONS, analysis_target)
    
    with tab2:
        render_graph_analysis_tab_perfect(filtered_df)
    
    with tab3:
        render_question_list_tab_perfect(filtered_df, analysis_target)
    
    with tab4:
        render_keyword_search_tab_perfect(analysis_target)

def render_overview_tab_perfect(filtered_df: pd.DataFrame, base_df: pd.DataFrame, all_questions: List, analysis_target: str):
    """
    æ¦‚è¦ã‚¿ãƒ– - å­¦ç¿’çŠ¶æ³ã‚µãƒãƒªãƒ¼
    """
    st.subheader("å­¦ç¿’çŠ¶æ³ã‚µãƒãƒªãƒ¼")
    if filtered_df.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("##### ã‚«ãƒ¼ãƒ‰ç¿’ç†Ÿåº¦åˆ†å¸ƒï¼ˆå…¨ä½“ï¼‰")
            # åˆ†æå¯¾è±¡ã®å…¨ä½“ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç„¡é–¢ä¿‚ï¼‰ã‚’ä½¿ç”¨
            level_counts = base_df["level"].value_counts().reindex(LEVEL_ORDER).fillna(0).astype(int)
            st.dataframe(level_counts)
        with col2:
            st.markdown("##### æ­£è§£ç‡ (True Retention)")
            total_reviews = 0
            correct_reviews = 0
            for history_list in filtered_df["history"]:
                for review in history_list:
                    if isinstance(review, dict) and "quality" in review:
                        total_reviews += 1
                        if review["quality"] >= 4:
                            correct_reviews += 1
            retention_rate = (correct_reviews / total_reviews * 100) if total_reviews > 0 else 0
            st.metric(label="é¸æŠç¯„å›²ã®æ­£è§£ç‡", value=f"{retention_rate:.1f}%", delta=f"{correct_reviews} / {total_reviews} å›")

            # å¿…ä¿®å•é¡Œã®æ­£è§£ç‡è¨ˆç®—
            if analysis_target == "å­¦å£«è©¦é¨“":
                hisshu_df = filtered_df[filtered_df["is_hisshu"] == True]
                hisshu_label = "ã€å­¦å£«è©¦é¨“ãƒ»å¿…ä¿®å•é¡Œã€‘ã®æ­£è§£ç‡ (ç›®æ¨™: 80%ä»¥ä¸Š)"
            else:
                hisshu_df = filtered_df[filtered_df["id"].isin(HISSHU_Q_NUMBERS_SET)]
                hisshu_label = "ã€å¿…ä¿®å•é¡Œã€‘ã®æ­£è§£ç‡ (ç›®æ¨™: 80%ä»¥ä¸Š)"

            hisshu_total_reviews = 0
            hisshu_correct_reviews = 0
            for history_list in hisshu_df["history"]:
                for review in history_list:
                    if isinstance(review, dict) and "quality" in review:
                        hisshu_total_reviews += 1
                        if review["quality"] >= 4:
                            hisshu_correct_reviews += 1
            hisshu_retention_rate = (hisshu_correct_reviews / hisshu_total_reviews * 100) if hisshu_total_reviews > 0 else 0
            st.metric(label=hisshu_label, value=f"{hisshu_retention_rate:.1f}%", delta=f"{hisshu_correct_reviews} / {hisshu_total_reviews} å›")

def render_graph_analysis_tab_perfect(filtered_df: pd.DataFrame):
    """
    ã‚°ãƒ©ãƒ•åˆ†æã‚¿ãƒ– - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–
    """
    st.subheader("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–")
    if filtered_df.empty:
        st.warning("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.markdown("##### å­¦ç¿’ã®è¨˜éŒ²")
        review_history = []
        for history_list in filtered_df["history"]:
            for review in history_list:
                if isinstance(review, dict) and "timestamp" in review:
                    timestamp = review["timestamp"]
                    try:
                        # æ—¥æœ¬æ™‚é–“ã«å¤‰æ›ã—ã¦ã‹ã‚‰æ—¥ä»˜ã‚’å–å¾—
                        review_datetime_jst = get_japan_datetime_from_timestamp(timestamp)
                        review_history.append(review_datetime_jst.date())
                    except (ValueError, TypeError):
                        # ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                        continue

        if review_history:
            from collections import Counter
            import pandas as pd  # ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ã‚³ãƒ¼ãƒ—ã§ç¢ºå®Ÿã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            review_counts = Counter(review_history)
            ninety_days_ago = get_japan_today() - datetime.timedelta(days=90)  # æ—¥æœ¬æ™‚é–“ãƒ™ãƒ¼ã‚¹
            dates = [ninety_days_ago + datetime.timedelta(days=i) for i in range(91)]
            counts = [review_counts.get(d, 0) for d in dates]
            chart_df = pd.DataFrame({"Date": dates, "Reviews": counts})

            # plotlyã‚’ä½¿ã£ã¦yè»¸ã®æœ€å°å€¤ã‚’0ã«å›ºå®š
            try:
                import plotly.express as px
                fig = px.bar(chart_df, x="Date", y="Reviews", 
                            title="æ—¥ã€…ã®å­¦ç¿’é‡ï¼ˆéå»90æ—¥é–“ï¼‰")
                fig.update_layout(
                    yaxis=dict(range=[0, max(counts) * 1.1] if counts else [0, 5]),
                    showlegend=False
                )
                st.plotly_chart(fig, use_container_width=True)
            except ImportError:
                # plotlyãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯å¾“æ¥ã®bar_chart
                st.bar_chart(chart_df.set_index("Date"))
        else:
            st.info("é¸æŠã•ã‚ŒãŸç¯„å›²ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼å±¥æ­´ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")

        st.markdown("##### å­¦ç¿’ãƒ¬ãƒ™ãƒ«åˆ¥åˆ†å¸ƒ")
        if not filtered_df.empty:
            level_counts = filtered_df['level'].value_counts()

            # è‰²åˆ†ã‘å®šç¾©
            level_colors_chart = {
                "æœªå­¦ç¿’": "#757575", "ãƒ¬ãƒ™ãƒ«0": "#FF9800", "ãƒ¬ãƒ™ãƒ«1": "#FFC107",
                "ãƒ¬ãƒ™ãƒ«2": "#8BC34A", "ãƒ¬ãƒ™ãƒ«3": "#9C27B0", "ãƒ¬ãƒ™ãƒ«4": "#03A9F4",
                "ãƒ¬ãƒ™ãƒ«5": "#1E88E5", "ç¿’å¾—æ¸ˆã¿": "#4CAF50"
            }

            try:
                import plotly.express as px
                import pandas as pd

                # ãƒ¬ãƒ™ãƒ«é †ã«ä¸¦ã¹æ›¿ãˆ
                chart_data = []
                colors = []

                for level in LEVEL_ORDER:
                    if level in level_counts.index:
                        chart_data.append({"Level": level, "Count": level_counts[level]})
                        colors.append(level_colors_chart.get(level, "#888888"))

                chart_df = pd.DataFrame(chart_data)

                fig = px.bar(chart_df, x="Level", y="Count", 
                            title="å­¦ç¿’ãƒ¬ãƒ™ãƒ«åˆ¥å•é¡Œæ•°",
                            color="Level",
                            color_discrete_map=level_colors_chart)
                fig.update_layout(
                    yaxis=dict(range=[0, None]),
                    showlegend=False,
                    xaxis_tickangle=-45
                )
                st.plotly_chart(fig, use_container_width=True)

            except ImportError:
                # plotlyãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯åŸºæœ¬çš„ãªbar_chart
                st.bar_chart(level_counts)
        else:
            st.info("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

def render_question_list_tab_perfect(filtered_df: pd.DataFrame, analysis_target: str = "å›½è©¦"):
    """
    å•é¡Œãƒªã‚¹ãƒˆã‚¿ãƒ– - å•é¡Œãƒªã‚¹ãƒˆ
    """
    st.subheader("å•é¡Œãƒªã‚¹ãƒˆ")
    level_colors = {
        "æœªå­¦ç¿’": "#757575", "ãƒ¬ãƒ™ãƒ«0": "#FF9800", "ãƒ¬ãƒ™ãƒ«1": "#FFC107",
        "ãƒ¬ãƒ™ãƒ«2": "#8BC34A", "ãƒ¬ãƒ™ãƒ«3": "#9C27B0", "ãƒ¬ãƒ™ãƒ«4": "#03A9F4",
        "ãƒ¬ãƒ™ãƒ«5": "#1E88E5", "ç¿’å¾—æ¸ˆã¿": "#4CAF50"
    }

    # æ¨©é™ãƒã‚§ãƒƒã‚¯
    has_gakushi_permission = st.session_state.get("has_gakushi_permission", False)

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
    if not filtered_df.empty:
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã® level_filter ã¯æ—¢ã«é©ç”¨æ¸ˆã¿

        st.markdown(f"**{len(filtered_df)}ä»¶ã®å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ**")
        if not filtered_df.empty:
            def sort_key(row_id):
                m_gakushi = re.match(r'^(G)(\d+)[â€“\-]([\dâ€“\-å†]+)[â€“\-]([A-Z])[â€“\-](\d+)$', str(row_id))
                if m_gakushi: return (m_gakushi.group(1), int(m_gakushi.group(2)), m_gakushi.group(3), m_gakushi.group(4), int(m_gakushi.group(5)))
                m_normal = re.match(r"(\d+)([A-D])(\d+)", str(row_id))
                if m_normal: return ('Z', int(m_normal.group(1)), m_normal.group(2), '', int(m_normal.group(3)))
                return ('Z', 0, '', '', 0)

            detail_filtered_sorted = filtered_df.copy()
            detail_filtered_sorted['sort_key'] = detail_filtered_sorted['id'].apply(sort_key)
            detail_filtered_sorted = detail_filtered_sorted.sort_values(by='sort_key').drop(columns=['sort_key'])
            for _, row in detail_filtered_sorted.iterrows():
                # æ¨©é™ãƒã‚§ãƒƒã‚¯ï¼šå­¦å£«è©¦é¨“ã®å•é¡Œã§æ¨©é™ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if str(row.id).startswith("G") and not has_gakushi_permission:
                    continue

                st.markdown(
                    f"<div style='margin-bottom: 5px; padding: 5px; border-left: 5px solid {level_colors.get(row.level, '#888')};'>"
                    f"<span style='display:inline-block;width:80px;font-weight:bold;color:{level_colors.get(row.level, '#888')};'>{row.level}</span>"
                    f"<span style='font-size:1.1em;'>{row.id}</span>"
                    f"</div>",
                    unsafe_allow_html=True
                )
        else:
            st.info("ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.info("è¡¨ç¤ºã™ã‚‹å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

def render_keyword_search_tab_perfect(analysis_target: str):
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚¿ãƒ– - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
    """
    # æ¨©é™ãƒã‚§ãƒƒã‚¯
    has_gakushi_permission = st.session_state.get("has_gakushi_permission", False)
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é€£å‹•ï¼‰
    st.subheader("ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢")
    st.info(f"ğŸ¯ æ¤œç´¢å¯¾è±¡: {analysis_target} ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã®åˆ†æå¯¾è±¡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§å¤‰æ›´å¯èƒ½ï¼‰")

    col1, col2 = st.columns([4, 1])
    with col1:
        search_keyword = st.text_input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", placeholder="æ¤œç´¢ã—ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›", key="search_keyword_input")
    with col2:
        shuffle_results = st.checkbox("çµæœã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«", key="shuffle_checkbox")

    search_btn = st.button("æ¤œç´¢å®Ÿè¡Œ", type="primary", use_container_width=True)

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã®å®Ÿè¡Œã¨çµæœè¡¨ç¤º
    if search_btn and search_keyword.strip():
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚’å®Ÿè¡Œ
        search_words = [word.strip() for word in search_keyword.strip().split() if word.strip()]

        keyword_results = []
        for q in ALL_QUESTIONS:
            # æ¨©é™ãƒã‚§ãƒƒã‚¯ï¼šå­¦å£«è©¦é¨“ã®å•é¡Œã§æ¨©é™ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            question_number = q.get('number', '')
            if question_number.startswith("G") and not has_gakushi_permission:
                continue

            # åˆ†æå¯¾è±¡ãƒ•ã‚£ãƒ«ã‚¿ãƒã‚§ãƒƒã‚¯ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®šã‚’ä½¿ç”¨ï¼‰
            if analysis_target == "å­¦å£«è©¦é¨“" and not question_number.startswith("G"):
                continue
            elif analysis_target == "å›½è©¦" and question_number.startswith("G"):
                continue

            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
            text_to_search = f"{q.get('question', '')} {q.get('subject', '')} {q.get('number', '')}"
            if any(word.lower() in text_to_search.lower() for word in search_words):
                keyword_results.append(q)

        # ã‚·ãƒ£ãƒƒãƒ•ãƒ«å‡¦ç†
        if shuffle_results:
            random.shuffle(keyword_results)

        # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        st.session_state["search_results"] = keyword_results
        st.session_state["search_query"] = search_keyword.strip()
        st.session_state["search_page_analysis_target"] = analysis_target
        st.session_state["search_page_shuffle_setting"] = shuffle_results

    # æ¤œç´¢çµæœã®è¡¨ç¤º
    if "search_results" in st.session_state:
        results = st.session_state["search_results"]
        query = st.session_state.get("search_query", "")
        search_type = st.session_state.get("search_page_analysis_target", "å›½è©¦")
        shuffle_info = "ï¼ˆã‚·ãƒ£ãƒƒãƒ•ãƒ«æ¸ˆã¿ï¼‰" if st.session_state.get("search_page_shuffle_setting", False) else "ï¼ˆé †ç•ªé€šã‚Šï¼‰"

        if results:
            st.success(f"ã€Œ{query}ã€ã§{len(results)}å•è¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼ˆ{search_type}ï¼‰{shuffle_info}")

            # çµæœã®çµ±è¨ˆã‚’è¡¨ç¤º
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ¤œç´¢çµæœ", f"{len(results)}å•")
            with col2:
                subjects = [q.get("subject", "æœªåˆ†é¡") for q in results]
                unique_subjects = len(set(subjects))
                st.metric("é–¢é€£ç§‘ç›®", f"{unique_subjects}ç§‘ç›®")
            with col3:
                years = []
                for q in results:
                    year = extract_year_from_question_number(q.get("number", ""))
                    if year is not None:
                        years.append(int(year))

                year_range = f"{min(years)}-{max(years)}" if years else "ä¸æ˜"
                st.metric("å¹´åº¦ç¯„å›²", year_range)

            # æ¤œç´¢çµæœã®è©³ç´°è¡¨ç¤º
            st.subheader("æ¤œç´¢çµæœ")

            # ãƒ¬ãƒ™ãƒ«åˆ¥è‰²åˆ†ã‘å®šç¾©
            level_colors = {
                "æœªå­¦ç¿’": "#757575", "ãƒ¬ãƒ™ãƒ«0": "#FF9800", "ãƒ¬ãƒ™ãƒ«1": "#FFC107",
                "ãƒ¬ãƒ™ãƒ«2": "#8BC34A", "ãƒ¬ãƒ™ãƒ«3": "#9C27B0", "ãƒ¬ãƒ™ãƒ«4": "#03A9F4",
                "ãƒ¬ãƒ™ãƒ«5": "#1E88E5", "ç¿’å¾—æ¸ˆã¿": "#4CAF50"
            }

            level_icons = {
                "æœªå­¦ç¿’": "#757575",        # ã‚°ãƒ¬ãƒ¼ç³»
                "ãƒ¬ãƒ™ãƒ«0": "#FF9800",      # ã‚ªãƒ¬ãƒ³ã‚¸ #FF9800
                "ãƒ¬ãƒ™ãƒ«1": "#FFC107",      # ã‚¤ã‚¨ãƒ­ãƒ¼ #FFC107
                "ãƒ¬ãƒ™ãƒ«2": "#8BC34A",      # ã‚°ãƒªãƒ¼ãƒ³ #8BC34A
                "ãƒ¬ãƒ™ãƒ«3": "#9C27B0",      # ãƒ‘ãƒ¼ãƒ—ãƒ« #9C27B0
                "ãƒ¬ãƒ™ãƒ«4": "#03A9F4",      # ãƒ–ãƒ«ãƒ¼ #03A9F4
                "ãƒ¬ãƒ™ãƒ«5": "#1E88E5",      # ãƒ€ãƒ¼ã‚¯ãƒ–ãƒ«ãƒ¼ #1E88E5
                "ç¿’å¾—æ¸ˆã¿": "#4CAF50"      # ã‚°ãƒªãƒ¼ãƒ³å®Œäº† #4CAF50
            }

            for i, q in enumerate(results[:20]):  # æœ€åˆã®20ä»¶ã‚’è¡¨ç¤º
                # æ¨©é™ãƒã‚§ãƒƒã‚¯ï¼šå­¦å£«è©¦é¨“ã®å•é¡Œã§æ¨©é™ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                question_number = q.get('number', '')
                if question_number.startswith("G") and not has_gakushi_permission:
                    continue

                # å­¦ç¿’ãƒ¬ãƒ™ãƒ«ã®å–å¾—
                card = st.session_state.cards.get(question_number, {})
                if not card:
                    level = "æœªå­¦ç¿’"
                else:
                    card_level = card.get("level", 0)
                    if card_level >= 6:
                        level = "ç¿’å¾—æ¸ˆã¿"
                    else:
                        level = f"ãƒ¬ãƒ™ãƒ«{card_level}"

                # å¿…ä¿®å•é¡Œãƒã‚§ãƒƒã‚¯
                if search_type == "å­¦å£«è©¦é¨“":
                    is_hisshu = question_number in GAKUSHI_HISSHU_Q_NUMBERS_SET
                else:
                    is_hisshu = question_number in HISSHU_Q_NUMBERS_SET

                level_color = level_colors.get(level, "#888888")
                hisshu_mark = "ğŸ”¥" if is_hisshu else ""

                # è‰²ä»˜ããƒ‰ãƒƒãƒˆã‚¢ã‚¤ã‚³ãƒ³ã‚’HTMLã§ç”Ÿæˆ
                color_dot = f'<span style="color: {level_color}; font-size: 1.2em; font-weight: bold;">â—</span>'

                with st.expander(f"â— {q.get('number', 'N/A')} - {q.get('subject', 'æœªåˆ†é¡')} {hisshu_mark}"):
                    # ãƒ¬ãƒ™ãƒ«ã‚’å¤§ããè‰²ä»˜ãã§è¡¨ç¤º  
                    st.markdown(f"**å­¦ç¿’ãƒ¬ãƒ™ãƒ«:** <span style='color: {level_color}; font-weight: bold; font-size: 1.2em;'>{level}</span>", unsafe_allow_html=True)
                    st.markdown(f"**å•é¡Œ:** {q.get('question', '')[:100]}...")
                    if q.get('choices'):
                        st.markdown("**é¸æŠè‚¢:**")
                        for j, choice in enumerate(q['choices']):  # å…¨ã¦ã®é¸æŠè‚¢ã‚’è¡¨ç¤º
                            choice_text = choice.get('text', str(choice)) if isinstance(choice, dict) else str(choice)
                            st.markdown(f"  {chr(65+j)}. {choice_text[:50]}...")

                    # å­¦ç¿’å±¥æ­´ã®è¡¨ç¤º
                    if card and card.get('history'):
                        st.markdown(f"**å­¦ç¿’å±¥æ­´:** {len(card['history'])}å›")
                        for j, review in enumerate(card['history'][-3:]):  # æœ€æ–°3ä»¶
                            if isinstance(review, dict):
                                timestamp = review.get('timestamp', 'ä¸æ˜')
                                quality = review.get('quality', 0)
                                quality_emoji = "âœ…" if quality >= 4 else "âŒ"
                                st.markdown(f"  {j+1}. {timestamp} - è©•ä¾¡: {quality} {quality_emoji}")
                    else:
                        st.markdown("**å­¦ç¿’å±¥æ­´:** ãªã—")

            if len(results) > 20:
                st.info(f"è¡¨ç¤ºã¯æœ€åˆã®20ä»¶ã§ã™ã€‚å…¨{len(results)}ä»¶ä¸­")

            # PDFç”Ÿæˆã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
            st.markdown("#### ğŸ“„ PDFç”Ÿæˆ")

            colA, colB = st.columns(2)
            with colA:
                if st.button("ğŸ“„ PDFã‚’ç”Ÿæˆ", key="pdf_tcb_js_generate"):
                    with st.spinner("PDFã‚’ç”Ÿæˆä¸­..."):
                        # 1) LaTeXæœ¬æ–‡ï¼ˆå³ä¸Šã¯å›ºå®šã®'â—¯â—¯â—¯â—¯â—¯'ã‚’è¡¨ç¤ºï¼‰
                        latex_tcb = export_questions_to_latex_tcb_jsarticle(results)
                        # 2) ç”»åƒåé›†ï¼ˆURL/Storageå•ã‚ãšï¼‰
                        assets, per_q_files = _gather_images_for_questions(results)
                        # 3) ç”»åƒã‚¹ãƒ­ãƒƒãƒˆã‚’ includegraphics ã«å·®ã—æ›¿ãˆ
                        for i, files in enumerate(per_q_files, start=1):
                            block = _image_block_latex(files)
                            latex_tcb = latex_tcb.replace(rf"%__IMAGES_SLOT__{i}__", block)
                        # 4) ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
                        pdf_bytes, log = compile_latex_to_pdf(latex_tcb, assets=assets)
                        if pdf_bytes:
                            ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                            st.session_state["pdf_bytes_tcb_js"] = pdf_bytes
                            st.session_state["pdf_filename_tcb_js"] = f"dental_questions_tcb_js_{ts}.pdf"
                            st.success("âœ… PDFã®ç”Ÿæˆã«æˆåŠŸã—ã¾ã—ãŸã€‚å³ã®ãƒœã‚¿ãƒ³ã‹ã‚‰DLã§ãã¾ã™ã€‚")
                        else:
                            st.error("âŒ PDFç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                            with st.expander("ãƒ­ã‚°ã‚’è¦‹ã‚‹"):
                                st.code(log or "no log", language="text")

            with colB:
                if "pdf_bytes_tcb_js" in st.session_state:
                    # çµ±ä¸€ã•ã‚ŒãŸPDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæ–°ã‚¿ãƒ–ã§é–‹ãï¼‰
                    pdf_data = st.session_state["pdf_bytes_tcb_js"]
                    filename = st.session_state.get("pdf_filename_tcb_js", "dental_questions_tcb_js.pdf")

                    # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                    import base64
                    b64_pdf = base64.b64encode(pdf_data).decode()

                    # Data URI ã‚’æŒã¤HTMLãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆï¼ˆæ–°ã‚¿ãƒ–ã§é–‹ãï¼‰
                    href = f'<a href="data:application/pdf;base64,{b64_pdf}" download="{filename}" target="_blank" style="display: inline-block; padding: 12px; background-color: #ff6b6b; color: white; text-decoration: none; border-radius: 6px; text-align: center; width: 100%; font-size: 16px; font-weight: bold; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">ğŸ“¥ PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'

                    st.markdown(href, unsafe_allow_html=True)
                else:
                    st.button("â¬‡ï¸ PDFã‚’DL", disabled=True, use_container_width=True)

        else:
            st.warning(f"ã€Œ{query}ã€ã«è©²å½“ã™ã‚‹å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    else:
        st.info("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦æ¤œç´¢ã—ã¦ãã ã•ã„")

    # æ¤œç´¢çµæœè¡¨ç¤º
    if "search_results" in st.session_state:
        results = st.session_state["search_results"]
        query = st.session_state.get("search_query", "")
        search_type = st.session_state.get("search_analysis_target", "å›½è©¦")
        is_shuffled = st.session_state.get("search_shuffled", False)

        if results:
            shuffle_info = "ï¼ˆã‚·ãƒ£ãƒƒãƒ•ãƒ«æ¸ˆã¿ï¼‰" if is_shuffled else "ï¼ˆé †ç•ªé€šã‚Šï¼‰"
            st.success(f"ã€Œ{query}ã€ã§{len(results)}å•è¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼ˆ{search_type}ï¼‰{shuffle_info}")

            subjects = set(q.get('subject', '') for q in results)
            
            years = [extract_year_from_question_number(q.get("number", "")) for q in results]
            valid_years = [y for y in years if y is not None]
            year_range = f"{min(valid_years)}-{max(valid_years)}" if valid_years else "ä¸æ˜"
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ãƒ’ãƒƒãƒˆæ•°", len(results))
            with col2:
                st.metric("é–¢é€£ç§‘ç›®æ•°", len(subjects))
            with col3:
                st.metric("å¹´åº¦ç¯„å›²", year_range)

            # æ¤œç´¢çµæœãƒªã‚¹ãƒˆ
            st.subheader("æ¤œç´¢çµæœ")
            for i, q in enumerate(results[:20]):
                q_number = q.get('number', 'N/A')
                subject = q.get('subject', 'æœªåˆ†é¡')
                
                cards = st.session_state.get('cards', {})
                card = cards.get(q_number, {})
                level = calculate_card_level(card)
                
                with st.expander(f"â— {q_number} - {subject}"):
                    st.markdown(f"**å­¦ç¿’ãƒ¬ãƒ™ãƒ«:** {level}")
                    
                    question_text = q.get('question', '')
                    if len(question_text) > 100:
                        st.markdown(f"**å•é¡Œ:** {question_text[:100]}...")
                    else:
                        st.markdown(f"**å•é¡Œ:** {question_text}")
                    
                    choices = q.get('choices', [])
                    if choices:
                        st.markdown("**é¸æŠè‚¢:**")
                        for j, choice in enumerate(choices):
                            if isinstance(choice, dict):
                                choice_text = choice.get('text', str(choice))
                            else:
                                choice_text = str(choice)
                            
                            if len(choice_text) > 50:
                                st.markdown(f"  {chr(65 + j)}. {choice_text[:50]}...")
                            else:
                                st.markdown(f"  {chr(65 + j)}. {choice_text}")
                    
                    answer = q.get('answer', '')
                    if answer:
                        st.markdown(f"**æ­£è§£:** {answer}")
                    
                    history = card.get('history', [])
                    n = card.get('n', 0)
                    if not history:
                        st.markdown("**å­¦ç¿’å±¥æ­´:** ãªã—")
                    else:
                        st.markdown(f"**å­¦ç¿’å±¥æ­´:** {len(history)}å›")
                        st.markdown(f"**æ¼”ç¿’å›æ•°:** {n}å›")
                        if len(history) > 0:
                            latest = history[-1]
                            timestamp = latest.get('timestamp', '')
                            quality = latest.get('quality', 0)
                            if timestamp:
                                try:
                                    if hasattr(timestamp, 'strftime'):
                                        time_str = timestamp.strftime('%Y-%m-%d %H:%M')
                                    else:
                                        try:
                                            if 'T' in str(timestamp):
                                                timestamp_str = str(timestamp).split('.')[0] if '.' in str(timestamp) else str(timestamp)
                                                parsed_time = datetime.datetime.fromisoformat(timestamp_str)
                                                time_str = parsed_time.strftime('%Y-%m-%d %H:%M')
                                            else:
                                                time_str = str(timestamp)[:16]
                                        except:
                                            time_str = "ä¸æ˜"
                                    st.markdown(f"ã€€æœ€æ–°: {time_str} (è©•ä¾¡: {quality})")
                                except:
                                    st.markdown(f"ã€€æœ€æ–°: (è©•ä¾¡: {quality})")

            # PDFç”Ÿæˆæ©Ÿèƒ½
            st.markdown("#### ğŸ“„ PDFç”Ÿæˆ")
            colA, colB = st.columns(2)
            
            with colA:
                if st.button("ğŸ“„ PDFã‚’ç”Ÿæˆ", key="pdf_generate_button"):
                    with st.spinner("PDFã‚’ç”Ÿæˆä¸­... é«˜å“è³ªãªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®ãŸã‚æ•°åˆ†ã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚"):
                        assets, per_q_files = _gather_images_for_questions(results)
                        latex_source = export_questions_to_latex_tcb_jsarticle(results, right_label_fn=lambda q: q.get('subject', ''))
                        
                        for i, files in enumerate(per_q_files, start=1):
                            block = _image_block_latex(files)
                            latex_source = latex_source.replace(rf"%__IMAGES_SLOT__{i}__", block)

                        pdf_bytes, log = compile_latex_to_pdf(latex_source, assets=assets)

                        if pdf_bytes:
                            ts = datetime.datetime.now().strftime("%Y%m%d_%H%M")
                            st.session_state["pdf_bytes_for_download"] = pdf_bytes
                            st.session_state["pdf_filename_for_download"] = f"search_results_{ts}.pdf"
                            st.success("âœ… PDFç”Ÿæˆå®Œäº†ï¼å³ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                        else:
                            st.error("âŒ PDFç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                            if "pdf_bytes_for_download" in st.session_state:
                                del st.session_state["pdf_bytes_for_download"]
                            with st.expander("ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°"):
                                st.code(log or "ãƒ­ã‚°ã¯ã‚ã‚Šã¾ã›ã‚“", language="text")
            
            with colB:
                if "pdf_bytes_for_download" in st.session_state and st.session_state["pdf_bytes_for_download"]:
                    file_size_kb = len(st.session_state["pdf_bytes_for_download"]) / 1024
                    st.download_button(
                        label="ğŸ“¥ PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=st.session_state["pdf_bytes_for_download"],
                        file_name=st.session_state["pdf_filename_for_download"],
                        mime="application/pdf",
                        use_container_width=True,
                        type="primary",
                        help=f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_kb:.1f} KB"
                    )
                else:
                    st.button("ğŸ“¥ PDFã‚’DL", disabled=True, use_container_width=True)
        else:
            if query:
                st.warning(f"ã€Œ{query}ã€ã«è©²å½“ã™ã‚‹å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            else:
                st.info("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦æ¤œç´¢ã—ã¦ãã ã•ã„")

# ãƒ¡ã‚¤ãƒ³é–¢æ•°
def main():
    """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    render_search_page()

if __name__ == "__main__":
    main()
