"""
æ¤œç´¢ãƒ»é€²æ—ãƒšãƒ¼ã‚¸ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä»•æ§˜ã«100%åˆè‡´ã—ãŸå®Œç’§ãªå®Ÿè£…

AI Copilotå‘ã‘ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¦ä»¶ã‚’å®Œå…¨ã«æº€ãŸã™çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ©Ÿèƒ½
- çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: å­¦ç¿’çŠ¶æ³ã‚µãƒãƒªãƒ¼ï¼ˆå­¦ç¿’æ¸ˆã¿å•é¡Œæ•°ã€ç¿’å¾—ç‡ã€ç·å­¦ç¿’å›æ•°ã€è¨˜æ†¶å®šç€åº¦ï¼‰
- ã‚¿ãƒ–ãƒ™ãƒ¼ã‚¹UI: æ¦‚è¦ã€ã‚°ãƒ©ãƒ•åˆ†æã€å•é¡Œãƒªã‚¹ãƒˆã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã®4ã¤ã®ã‚¿ãƒ–
- ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¨é€£å‹•ã—ãŸå‹•çš„çµã‚Šè¾¼ã¿
- è©³ç´°ãªé€²æ—åˆ†æ: ç¿’ç†Ÿåº¦ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒã€æ­£è§£ç‡ã€ç§‘ç›®åˆ¥åˆ†æã€æ—¥ã€…ã®å­¦ç¿’é‡å¯è¦–åŒ–
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: å•é¡Œæ–‡ãƒ»ç§‘ç›®ãƒ»å•é¡Œç•ªå·æ¤œç´¢ã€PDFç”Ÿæˆæ©Ÿèƒ½
"""

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import datetime
from typing import Dict, List, Any, Optional
import time
import base64
import re
import random
import sys
import os
import subprocess
import shutil
import tempfile
import hashlib
from collections import defaultdict, Counter

# å¿…è¦ãªãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã¨ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils import (
    ALL_QUESTIONS, 
    HISSHU_Q_NUMBERS_SET, 
    GAKUSHI_HISSHU_Q_NUMBERS_SET,
    extract_year_from_question_number,
    export_questions_to_latex_tcb_jsarticle,
    _gather_images_for_questions,
    _image_block_latex,
    compile_latex_to_pdf
)
from firestore_db import get_firestore_manager

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append('/Users/utsueito/kokushi-dx-poc/dental-DX-PoC')
try:
    from user_data_extractor import UserDataExtractor
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šUserDataExtractorãŒåˆ©ç”¨ã§ããªã„å ´åˆ
    UserDataExtractor = None

# çµ±ä¸€ã•ã‚ŒãŸãƒ¬ãƒ™ãƒ«è‰²åˆ†ã‘å®šç¾©ï¼ˆæ–°ãƒ‡ã‚¶ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ å¯¾å¿œï¼‰
LEVEL_COLORS = {
    "æœªå­¦ç¿’": "#BDBDBD",
    "ãƒ¬ãƒ™ãƒ«0": "#E47C2E",  # ãƒ¬ãƒ™ãƒ«0ã‚’å†å°å…¥ï¼ˆæ·¡ã„èµ¤è‰²ã§å­¦ç¿’é–‹å§‹æ®µéšã‚’ç¤ºã™ï¼‰
    "ãƒ¬ãƒ™ãƒ«1": "#F4B83E", 
    "ãƒ¬ãƒ™ãƒ«2": "#56C68B", 
    "ãƒ¬ãƒ™ãƒ«3": "#B06CCF",
    "ãƒ¬ãƒ™ãƒ«4": "#4AB2D9",
    "ãƒ¬ãƒ™ãƒ«5": "#7C5FCF", 
    "ç¿’å¾—æ¸ˆã¿": "#344A90"
}

# çµ±ä¸€ã•ã‚ŒãŸãƒ¬ãƒ™ãƒ«é †åºå®šç¾©ï¼ˆ0-5ãƒ¬ãƒ™ãƒ«ã‚·ã‚¹ãƒ†ãƒ ï¼‰
LEVEL_ORDER = ["æœªå­¦ç¿’", "ãƒ¬ãƒ™ãƒ«0", "ãƒ¬ãƒ™ãƒ«1", "ãƒ¬ãƒ™ãƒ«2", "ãƒ¬ãƒ™ãƒ«3", "ãƒ¬ãƒ™ãƒ«4", "ãƒ¬ãƒ™ãƒ«5", "ç¿’å¾—æ¸ˆã¿"]

def check_gakushi_permission(uid: str) -> bool:
    """å­¦å£«è©¦é¨“ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚’ãƒã‚§ãƒƒã‚¯"""
    try:
        db = get_firestore_manager()
        user_ref = db.collection('users').document(uid)
        user_doc = user_ref.get()
        
        if user_doc.exists:
            user_data = user_doc.to_dict()
            return user_data.get('has_gakushi_permission', False)
        
        # æ¨©é™æƒ…å ±ãŒãªã„å ´åˆã¯Trueã‚’è¿”ã™ï¼ˆé–‹ç™ºæ™‚ã®ä¾¿å®œï¼‰
        return True
    except Exception:
        # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã‚‚Trueã‚’è¿”ã™ï¼ˆé–‹ç™ºæ™‚ã®ä¾¿å®œï¼‰
        return True

def calculate_card_level(card: Dict[str, Any]) -> str:
    """
    å†å®šç¾©ã•ã‚ŒãŸæœ€çµ‚ç‰ˆãƒ¬ãƒ™ãƒ«è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ï¼š
    - ã€Œæœªå­¦ç¿’ã€ã¯å±¥æ­´ã®æœ‰ç„¡ã§å³å¯†ã«åˆ¤å®š
    - ã€Œãƒ¬ãƒ™ãƒ«0ã€ã‚’é–‹å§‹ç‚¹ã¨ã™ã‚‹é€£ç¶šçš„ãªãƒ¬ãƒ™ãƒ«ã‚¢ãƒƒãƒ—
    - ã€Œç¿’å¾—æ¸ˆã¿ã€ã¯EFå€¤ã¨æ¼”ç¿’å›æ•°ã®çµ„ã¿åˆã‚ã›ã§åˆ¤å®š
    """
    # 1. ã‚«ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯å­¦ç¿’å±¥æ­´ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã€Œæœªå­¦ç¿’ã€
    if not card or not isinstance(card, dict) or not card.get('history'):
        return "æœªå­¦ç¿’"
    
    # --- ã“ã“ã‹ã‚‰å…ˆã¯ã€å­¦ç¿’å±¥æ­´ãŒ1ä»¶ä»¥ä¸Šå­˜åœ¨ã™ã‚‹å ´åˆã®å‡¦ç† ---
    
    n = card.get('n', 0)
    ef = card.get('EF', card.get('ef', 2.5))
    
    # 2. ã€Œç¿’å¾—æ¸ˆã¿ã€ã®åˆ¤å®š (ç°¡å˜ã• x å›æ•°ã®çµ„ã¿åˆã‚ã›)
    if (ef >= 2.8 and n >= 3) or \
       (ef >= 2.5 and n >= 5) or \
       (n >= 8):
        return "ç¿’å¾—æ¸ˆã¿"
    
    # 3. ã€Œãƒ¬ãƒ™ãƒ«1ã€ã‹ã‚‰ã€Œãƒ¬ãƒ™ãƒ«5ã€ã®åˆ¤å®š (æ¼”ç¿’å›æ•°ã«åŸºã¥ã)
    if n >= 7: return "ãƒ¬ãƒ™ãƒ«5"   # æœ€é«˜ãƒ¬ãƒ™ãƒ«
    if n >= 6: return "ãƒ¬ãƒ™ãƒ«4"   # ç¿’å¾—æ¸ˆã¿ç›´å‰
    if n >= 4: return "ãƒ¬ãƒ™ãƒ«3"   # å¾—æ„ãƒ¬ãƒ™ãƒ«
    if n >= 3: return "ãƒ¬ãƒ™ãƒ«2"   # æ™®é€šãƒ¬ãƒ™ãƒ«
    if n >= 2: return "ãƒ¬ãƒ™ãƒ«1"   # åŸºç¤ãƒ¬ãƒ™ãƒ«
    
    # 4. ä¸Šè¨˜ã®ã„ãšã‚Œã§ã‚‚ãªã„ãŒã€å±¥æ­´ã¯å­˜åœ¨ã™ã‚‹ã‚«ãƒ¼ãƒ‰ (n=0ã¾ãŸã¯1) ã¯ã€Œãƒ¬ãƒ™ãƒ«0ã€
    return "ãƒ¬ãƒ™ãƒ«0"

def calculate_progress_metrics(cards: Dict, base_df: pd.DataFrame, uid: str = None, analysis_target: str = "å›½è©¦å•é¡Œ") -> Dict:
    """
    å­¦ç¿’é€²æ—ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨å‰æ—¥æ¯”ãƒ»å‰é€±æ¯”ã‚’è¨ˆç®—ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆUserDataExtractorå¼·åŒ–ç‰ˆï¼‰
    """
    today = datetime.datetime.now().date()
    yesterday = today - datetime.timedelta(days=1)
    seven_days_ago = datetime.datetime.now() - datetime.timedelta(days=7)
    fourteen_days_ago = datetime.datetime.now() - datetime.timedelta(days=14)
    
    # UserDataExtractorã‹ã‚‰è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
    enhanced_data = {}
    if uid and uid != "guest" and UserDataExtractor:
        try:
            extractor = UserDataExtractor()
            
            # analysis_targetã«å¿œã˜ã¦è©¦é¨“ç¨®åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ã‚’è¨­å®š
            exam_type_filter = None
            if analysis_target == "å­¦å£«è©¦é¨“å•é¡Œ":
                exam_type_filter = "å­¦å£«è©¦é¨“"
            elif analysis_target == "å›½è©¦å•é¡Œ":
                exam_type_filter = "æ­¯ç§‘å›½è©¦"
            
            # analysis_targetã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸãƒ­ã‚°ã‚’å–å¾—
            evaluation_logs = extractor.extract_self_evaluation_logs(uid)
            practice_data = extractor.extract_practice_logs(uid)
            
            # evaluation_logsã‚’analysis_targetã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if exam_type_filter and evaluation_logs:
                # å„ãƒ­ã‚°ã®å•é¡ŒIDã‹ã‚‰è©¦é¨“ç¨®åˆ¥ã‚’åˆ¤å®šã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                filtered_logs = []
                for log in evaluation_logs:
                    question_id = log.get('question_id')  # problem_id â†’ question_id ã«ä¿®æ­£
                    if question_id:
                        # å•é¡ŒIDã‹ã‚‰è©¦é¨“ç¨®åˆ¥ã‚’åˆ¤å®š
                        if exam_type_filter == "å­¦å£«è©¦é¨“" and ("G24" in question_id or "G25" in question_id):
                            filtered_logs.append(log)
                        elif exam_type_filter == "æ­¯ç§‘å›½è©¦" and not ("G24" in question_id or "G25" in question_id):
                            filtered_logs.append(log)
                        elif exam_type_filter is None:  # ãƒ•ã‚£ãƒ«ã‚¿ãªã—ã®å ´åˆ
                            filtered_logs.append(log)
                evaluation_logs = filtered_logs
                print(f"[INFO] {analysis_target}ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: {len(filtered_logs)}ä»¶ (å…ƒ: ç·{len(evaluation_logs)}ä»¶)")
            else:
                print(f"[INFO] ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãªã—: {len(evaluation_logs)}ä»¶")
            
            # ã‚ˆã‚Šæ­£ç¢ºãªçµ±è¨ˆã‚’è¨ˆç®—
            if evaluation_logs:
                # 7æ—¥é–“ã®æ­£è§£ç‡ã‚’æ­£ç¢ºã«è¨ˆç®—ï¼ˆanalysis_targetã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ï¼‰
                recent_evaluations = [
                    log for log in evaluation_logs 
                    if log['timestamp'] >= seven_days_ago
                ]
                previous_evaluations = [
                    log for log in evaluation_logs 
                    if fourteen_days_ago <= log['timestamp'] < seven_days_ago
                ]
                
                recent_correct = sum(1 for log in recent_evaluations if log.get('quality', 0) >= 3)
                previous_correct = sum(1 for log in previous_evaluations if log.get('quality', 0) >= 3)
                
                # å¿…ä¿®å•é¡Œã®æ­£è§£ç‡ã‚‚åˆ¥é€”è¨ˆç®—
                recent_hisshu_evaluations = [log for log in recent_evaluations if log.get('is_hisshu', False)]
                previous_hisshu_evaluations = [log for log in previous_evaluations if log.get('is_hisshu', False)]
                
                recent_hisshu_correct = sum(1 for log in recent_hisshu_evaluations if log.get('quality', 0) >= 3)
                previous_hisshu_correct = sum(1 for log in previous_hisshu_evaluations if log.get('quality', 0) >= 3)
                
                enhanced_data['recent_accuracy'] = (recent_correct / len(recent_evaluations) * 100) if recent_evaluations else 0
                enhanced_data['previous_accuracy'] = (previous_correct / len(previous_evaluations) * 100) if previous_evaluations else 0
                enhanced_data['recent_total'] = len(recent_evaluations)
                enhanced_data['previous_total'] = len(previous_evaluations)
                
                # å¿…ä¿®å•é¡Œã®æ­£è§£ç‡çµ±è¨ˆ
                enhanced_data['recent_hisshu_stats'] = {
                    'correct': recent_hisshu_correct,
                    'total': len(recent_hisshu_evaluations)
                }
                enhanced_data['previous_hisshu_stats'] = {
                    'correct': previous_hisshu_correct,
                    'total': len(previous_hisshu_evaluations)
                }
                
                # ä»Šæ—¥ã¨æ˜¨æ—¥ã®å­¦ç¿’æ•°ã‚’æ­£ç¢ºã«è¨ˆç®—
                today_logs = [
                    log for log in evaluation_logs 
                    if log['timestamp'].date() == today
                ]
                yesterday_logs = [
                    log for log in evaluation_logs 
                    if log['timestamp'].date() == yesterday
                ]
                
                enhanced_data['today_study_count'] = len(today_logs)
                enhanced_data['yesterday_study_count'] = len(yesterday_logs)
                
                print(f"[INFO] UserDataExtractorå¼·åŒ–({analysis_target}): ä»Šæ—¥{len(today_logs)}å•, æ˜¨æ—¥{len(yesterday_logs)}å•, ç›´è¿‘7æ—¥{len(recent_evaluations)}å•, å¿…ä¿®{len(recent_hisshu_evaluations)}å•")
        except Exception as e:
            print(f"[WARNING] UserDataExtractorå¼·åŒ–ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ä»Šæ—¥ãƒ»æ˜¨æ—¥ãƒ»æœŸé–“åˆ¥ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆï¼ˆå¾“æ¥ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    today_studied_problems = set()
    yesterday_studied_problems = set()
    today_hisshu_problems = set()
    yesterday_hisshu_problems = set()
    today_study_count = enhanced_data.get('today_study_count', 0)  # å¼·åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆ
    yesterday_study_count = enhanced_data.get('yesterday_study_count', 0)  # å¼·åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆ
    recent_7days_stats = {'correct': 0, 'total': enhanced_data.get('recent_total', 0)}
    previous_7days_stats = {'correct': 0, 'total': enhanced_data.get('previous_total', 0)}
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå¾“æ¥ãƒ­ã‚¸ãƒƒã‚¯ã§è£œå®Œï¼ˆUserDataExtractorãŒåˆ©ç”¨ã§ããªã„å ´åˆï¼‰
    if not enhanced_data:
        for _, row in base_df.iterrows():
            q_id = row['id']
            is_hisshu = row['is_hisshu']
            card = row['card_data']
            history = card.get('history', [])
            
            if isinstance(history, list):
                for entry in history:
                    if isinstance(entry, dict):
                        timestamp = entry.get('timestamp')
                        if timestamp:
                            try:
                                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ãƒ‘ãƒ¼ã‚¹ - DatetimeWithNanosecondså¯¾å¿œ
                                if hasattr(timestamp, 'timestamp') and callable(getattr(timestamp, 'timestamp')):
                                    # DatetimeWithNanoseconds ã®å ´åˆ
                                    entry_date = timestamp.date()
                                    entry_datetime = timestamp
                                elif hasattr(timestamp, 'date') and callable(getattr(timestamp, 'date')):
                                    # datetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                                    entry_date = timestamp.date()
                                    entry_datetime = timestamp
                                else:
                                    # æ–‡å­—åˆ—ã®å ´åˆ - ã‚ˆã‚Šå®‰å…¨ãªãƒ‘ãƒ¼ã‚¹
                                    try:
                                        if 'T' in str(timestamp):
                                            # ISOå½¢å¼
                                            timestamp_str = str(timestamp).split('.')[0] if '.' in str(timestamp) else str(timestamp)
                                            entry_datetime = datetime.datetime.fromisoformat(timestamp_str)
                                        else:
                                            # é€šå¸¸å½¢å¼
                                            entry_datetime = datetime.datetime.fromisoformat(str(timestamp)[:19])
                                        entry_date = entry_datetime.date()
                                    except Exception as e:
                                        print(f"ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ (search_page): {e}")
                                        continue
                                
                                # ä»Šæ—¥ã®å­¦ç¿’å•é¡Œã‚’è¨˜éŒ²
                                if entry_date == today:
                                    today_studied_problems.add(q_id)
                                    if not enhanced_data:  # å¼·åŒ–ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ã¿ã‚«ã‚¦ãƒ³ãƒˆ
                                        today_study_count += 1
                                    if is_hisshu:
                                        today_hisshu_problems.add(q_id)
                                
                                # æ˜¨æ—¥ã®å­¦ç¿’å•é¡Œã‚’è¨˜éŒ²
                                elif entry_date == yesterday:
                                    yesterday_studied_problems.add(q_id)
                                    if not enhanced_data:  # å¼·åŒ–ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ã¿ã‚«ã‚¦ãƒ³ãƒˆ
                                        yesterday_study_count += 1
                                    if is_hisshu:
                                        yesterday_hisshu_problems.add(q_id)
                                
                                # ç›´è¿‘7æ—¥é–“ã®æ­£è§£ç‡çµ±è¨ˆï¼ˆå¼·åŒ–ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ã¿ï¼‰
                                if not enhanced_data and entry_datetime >= seven_days_ago:
                                    recent_7days_stats['total'] += 1
                                    quality = entry.get('quality', 0)
                                    if quality >= 3:
                                        recent_7days_stats['correct'] += 1
                                
                                # å‰ã®7æ—¥é–“ï¼ˆ8-14æ—¥å‰ï¼‰ã®æ­£è§£ç‡çµ±è¨ˆï¼ˆå¼·åŒ–ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ã¿ï¼‰
                                elif not enhanced_data and entry_datetime >= fourteen_days_ago:
                                    previous_7days_stats['total'] += 1
                                    quality = entry.get('quality', 0)
                                    if quality >= 3:
                                        previous_7days_stats['correct'] += 1
                            except Exception:
                                # ã™ã¹ã¦ã®ä¾‹å¤–ã‚’ã‚­ãƒ£ãƒƒãƒã—ã¦ã‚¹ã‚­ãƒƒãƒ—
                                continue
    
    # ç¾åœ¨ã®ç·å­¦ç¿’æ¸ˆã¿å•é¡Œæ•°ã‚’è¨ˆç®—
    current_studied_count = 0
    current_hisshu_studied_count = 0
    
    # analysis_targetã«åŸºã¥ã„ã¦ç·å•é¡Œæ•°ã‚’æ±ºå®šï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–å¾—ã—ãŸæ­£ç¢ºãªå€¤ï¼‰
    if analysis_target == "å­¦å£«è©¦é¨“å•é¡Œ":
        # å­¦å£«è©¦é¨“å•é¡Œã®å ´åˆ: 4,941å•ã€å¿…ä¿®1,100å•
        total_count = 4941
        hisshu_total_count = 1100
    else:
        # å›½è©¦å•é¡Œã®å ´åˆ: 8,576å•ã€å¿…ä¿®1,300å•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        total_count = 8576
        hisshu_total_count = 1300
    
    # UserDataExtractorã‹ã‚‰æ­£ç¢ºãªå­¦ç¿’æ¸ˆã¿æ•°ã‚’å–å¾—ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
    if uid and uid != "guest" and UserDataExtractor:
        try:
            extractor = UserDataExtractor()
            comprehensive_stats = extractor.get_user_comprehensive_stats(uid, analysis_target)
            if comprehensive_stats and 'level_distribution' in comprehensive_stats:
                # UserDataExtractorã‹ã‚‰æ­£ç¢ºãªå­¦ç¿’æ¸ˆã¿æ•°ã‚’è¨ˆç®—
                level_dist = comprehensive_stats['level_distribution']
                total_questions = sum(level_dist.values())
                unstudied_count = level_dist.get('æœªå­¦ç¿’', 0)
                current_studied_count = total_questions - unstudied_count
                
                # å¿…ä¿®å•é¡Œã®å­¦ç¿’æ¸ˆã¿æ•°ã‚‚æ­£ç¢ºã«è¨ˆç®—ï¼ˆanalysis_targetã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸbase_dfã‹ã‚‰ç®—å‡ºï¼‰
                # UserDataExtractorã§ã¯å¿…ä¿®å•é¡Œã®è©³ç´°åˆ¤å®šãŒã§ããªã„ãŸã‚ã€base_dfã‹ã‚‰å†è¨ˆç®—
                for _, row in base_df.iterrows():
                    # analysis_targetã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    row_id = row['id']
                    if analysis_target == "å­¦å£«è©¦é¨“å•é¡Œ" and not ("G24" in row_id or "G25" in row_id):
                        continue
                    elif analysis_target == "å›½è©¦å•é¡Œ" and ("G24" in row_id or "G25" in row_id):
                        continue
                    
                    # å¿…ä¿®å•é¡Œã®åˆ¤å®šï¼ˆå­¦å£«è©¦é¨“å•é¡Œã®å ´åˆã¯å•é¡ŒIDã‹ã‚‰åˆ¤å®šï¼‰
                    is_hisshu = row['is_hisshu']
                    if analysis_target == "å­¦å£«è©¦é¨“å•é¡Œ":
                        # å­¦å£«è©¦é¨“å•é¡Œ: G24-2-A-1ã€œ20, G24-2-B-1ã€œ20ãªã©ãŒå¿…ä¿®
                        import re
                        match = re.search(r'G\d+-\d+-[A-Z]-(\d+)', row_id)
                        if match:
                            question_num = int(match.group(1))
                            is_hisshu = (question_num <= 20)  # 1ã€œ20ç•ªãŒå¿…ä¿®
                    
                    if is_hisshu:
                        card = row['card_data']
                        level = calculate_card_level(card)
                        if level != "æœªå­¦ç¿’":
                            current_hisshu_studied_count += 1
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: analysis_targetã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸbase_dfã‹ã‚‰è¨ˆç®—
                for _, row in base_df.iterrows():
                    # analysis_targetã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    row_id = row['id']
                    if analysis_target == "å­¦å£«è©¦é¨“å•é¡Œ" and not ("G24" in row_id or "G25" in row_id):
                        continue
                    elif analysis_target == "å›½è©¦å•é¡Œ" and ("G24" in row_id or "G25" in row_id):
                        continue
                    
                    # å¿…ä¿®å•é¡Œã®åˆ¤å®šï¼ˆå­¦å£«è©¦é¨“å•é¡Œã®å ´åˆã¯å•é¡ŒIDã‹ã‚‰åˆ¤å®šï¼‰
                    is_hisshu = row['is_hisshu']
                    if analysis_target == "å­¦å£«è©¦é¨“å•é¡Œ":
                        # å­¦å£«è©¦é¨“å•é¡Œ: G24-2-A-1ã€œ20, G24-2-B-1ã€œ20ãªã©ãŒå¿…ä¿®
                        import re
                        match = re.search(r'G\d+-\d+-[A-Z]-(\d+)', row_id)
                        if match:
                            question_num = int(match.group(1))
                            is_hisshu = (question_num <= 20)  # 1ã€œ20ç•ªãŒå¿…ä¿®
                    
                    card = row['card_data']
                    level = calculate_card_level(card)
                    if level != "æœªå­¦ç¿’":
                        current_studied_count += 1
                        if is_hisshu:
                            current_hisshu_studied_count += 1
        except Exception as e:
            print(f"[WARNING] UserDataExtractorå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: analysis_targetã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸbase_dfã‹ã‚‰è¨ˆç®—
            for _, row in base_df.iterrows():
                # analysis_targetã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                row_id = row['id']
                if analysis_target == "å­¦å£«è©¦é¨“å•é¡Œ" and not ("G24" in row_id or "G25" in row_id):
                    continue
                elif analysis_target == "å›½è©¦å•é¡Œ" and ("G24" in row_id or "G25" in row_id):
                    continue
                
                # å¿…ä¿®å•é¡Œã®åˆ¤å®šï¼ˆå­¦å£«è©¦é¨“å•é¡Œã®å ´åˆã¯å•é¡ŒIDã‹ã‚‰åˆ¤å®šï¼‰
                is_hisshu = row['is_hisshu']
                if analysis_target == "å­¦å£«è©¦é¨“å•é¡Œ":
                    # å­¦å£«è©¦é¨“å•é¡Œ: G24-2-A-1ã€œ20, G24-2-B-1ã€œ20ãªã©ãŒå¿…ä¿®
                    import re
                    match = re.search(r'G\d+-\d+-[A-Z]-(\d+)', row_id)
                    if match:
                        question_num = int(match.group(1))
                        is_hisshu = (question_num <= 20)  # 1ã€œ20ç•ªãŒå¿…ä¿®
                
                card = row['card_data']
                level = calculate_card_level(card)
                if level != "æœªå­¦ç¿’":
                    current_studied_count += 1
                    if is_hisshu:
                        current_hisshu_studied_count += 1
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: analysis_targetã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸbase_dfã‹ã‚‰è¨ˆç®—
        for _, row in base_df.iterrows():
            # analysis_targetã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            row_id = row['id']
            if analysis_target == "å­¦å£«è©¦é¨“å•é¡Œ" and not ("G24" in row_id or "G25" in row_id):
                continue
            elif analysis_target == "å›½è©¦å•é¡Œ" and ("G24" in row_id or "G25" in row_id):
                continue
            
            # å¿…ä¿®å•é¡Œã®åˆ¤å®šï¼ˆå­¦å£«è©¦é¨“å•é¡Œã®å ´åˆã¯å•é¡ŒIDã‹ã‚‰åˆ¤å®šï¼‰
            is_hisshu = row['is_hisshu']
            if analysis_target == "å­¦å£«è©¦é¨“å•é¡Œ":
                # å­¦å£«è©¦é¨“å•é¡Œ: G24-2-A-1ã€œ20, G24-2-B-1ã€œ20ãªã©ãŒå¿…ä¿®
                import re
                match = re.search(r'G\d+-\d+-[A-Z]-(\d+)', row_id)
                if match:
                    question_num = int(match.group(1))
                    is_hisshu = (question_num <= 20)  # 1ã€œ20ç•ªãŒå¿…ä¿®
            
            card = row['card_data']
            level = calculate_card_level(card)
            if level != "æœªå­¦ç¿’":
                current_studied_count += 1
                if is_hisshu:
                    current_hisshu_studied_count += 1
    
    # æ˜¨æ—¥æ™‚ç‚¹ã§ã®å­¦ç¿’æ¸ˆã¿å•é¡Œæ•°ã‚’æ¨å®šï¼ˆä»Šæ—¥æ–°è¦å­¦ç¿’ã—ãŸå•é¡Œã‚’é™¤ãï¼‰
    yesterday_studied_count = current_studied_count - len(today_studied_problems)
    yesterday_hisshu_studied_count = current_hisshu_studied_count - len(today_hisshu_problems)
    
    # æ­£è§£ç‡è¨ˆç®—ï¼ˆå¼·åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆä½¿ç”¨ã€analysis_targetã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
    if enhanced_data:
        recent_accuracy = enhanced_data['recent_accuracy']
        previous_accuracy = enhanced_data['previous_accuracy']
        # å¼·åŒ–ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®å¿…ä¿®ã¨å…¨ä½“ã®æ­£è§£ç‡ã‚‚å–å¾—
        recent_hisshu_stats = enhanced_data.get('recent_hisshu_stats', {'correct': 0, 'total': 0})
        previous_hisshu_stats = enhanced_data.get('previous_hisshu_stats', {'correct': 0, 'total': 0})
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šbase_dfã‹ã‚‰è¨ˆç®—ã™ã‚‹ãŒã€analysis_targetã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        recent_7days_stats_filtered = {'correct': 0, 'total': 0}
        previous_7days_stats_filtered = {'correct': 0, 'total': 0}
        recent_hisshu_stats = {'correct': 0, 'total': 0}
        previous_hisshu_stats = {'correct': 0, 'total': 0}
        
        for _, row in base_df.iterrows():
            q_id = row['id']
            is_hisshu = row['is_hisshu']
            card = row['card_data']
            history = card.get('history', [])
            
            if isinstance(history, list):
                for entry in history:
                    if isinstance(entry, dict):
                        timestamp = entry.get('timestamp')
                        if timestamp:
                            try:
                                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ãƒ‘ãƒ¼ã‚¹
                                if hasattr(timestamp, 'timestamp') and callable(getattr(timestamp, 'timestamp')):
                                    entry_datetime = timestamp
                                elif hasattr(timestamp, 'date') and callable(getattr(timestamp, 'date')):
                                    entry_datetime = timestamp
                                else:
                                    try:
                                        if 'T' in str(timestamp):
                                            timestamp_str = str(timestamp).split('.')[0] if '.' in str(timestamp) else str(timestamp)
                                            entry_datetime = datetime.datetime.fromisoformat(timestamp_str)
                                        else:
                                            entry_datetime = datetime.datetime.fromisoformat(str(timestamp)[:19])
                                    except Exception:
                                        continue
                                
                                quality = entry.get('quality', 0)
                                
                                # ç›´è¿‘7æ—¥é–“ã®æ­£è§£ç‡çµ±è¨ˆï¼ˆanalysis_targetã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
                                if entry_datetime >= seven_days_ago:
                                    recent_7days_stats_filtered['total'] += 1
                                    if quality >= 3:
                                        recent_7days_stats_filtered['correct'] += 1
                                    
                                    # å¿…ä¿®å•é¡Œã®å ´åˆ
                                    if is_hisshu:
                                        recent_hisshu_stats['total'] += 1
                                        if quality >= 3:
                                            recent_hisshu_stats['correct'] += 1
                                
                                # å‰ã®7æ—¥é–“ï¼ˆ8-14æ—¥å‰ï¼‰ã®æ­£è§£ç‡çµ±è¨ˆï¼ˆanalysis_targetã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
                                elif entry_datetime >= fourteen_days_ago:
                                    previous_7days_stats_filtered['total'] += 1
                                    if quality >= 3:
                                        previous_7days_stats_filtered['correct'] += 1
                                    
                                    # å¿…ä¿®å•é¡Œã®å ´åˆ
                                    if is_hisshu:
                                        previous_hisshu_stats['total'] += 1
                                        if quality >= 3:
                                            previous_hisshu_stats['correct'] += 1
                            except Exception:
                                continue
        
        recent_accuracy = (recent_7days_stats_filtered['correct'] / recent_7days_stats_filtered['total'] * 100) if recent_7days_stats_filtered['total'] > 0 else 0
        previous_accuracy = (previous_7days_stats_filtered['correct'] / previous_7days_stats_filtered['total'] * 100) if previous_7days_stats_filtered['total'] > 0 else 0
    
    # å¿…ä¿®å•é¡Œã®æ­£è§£ç‡ã‚’è¨ˆç®—
    recent_hisshu_accuracy = (recent_hisshu_stats['correct'] / recent_hisshu_stats['total'] * 100) if recent_hisshu_stats['total'] > 0 else 0
    previous_hisshu_accuracy = (previous_hisshu_stats['correct'] / previous_hisshu_stats['total'] * 100) if previous_hisshu_stats['total'] > 0 else 0
    
    return {
        'current_studied_count': current_studied_count,
        'total_count': total_count,
        'yesterday_studied_count': yesterday_studied_count,
        'progress_delta': current_studied_count - yesterday_studied_count,
        'current_hisshu_studied_count': current_hisshu_studied_count,
        'hisshu_total_count': hisshu_total_count,
        'yesterday_hisshu_studied_count': yesterday_hisshu_studied_count,
        'hisshu_delta': current_hisshu_studied_count - yesterday_hisshu_studied_count,
        'today_study_count': today_study_count,
        'yesterday_study_count': yesterday_study_count,
        'recent_accuracy': recent_accuracy,
        'previous_accuracy': previous_accuracy,
        'accuracy_delta': recent_accuracy - previous_accuracy,
        'recent_hisshu_accuracy': recent_hisshu_accuracy,
        'previous_hisshu_accuracy': previous_hisshu_accuracy,
        'hisshu_accuracy_delta': recent_hisshu_accuracy - previous_hisshu_accuracy,
        'recent_hisshu_stats': recent_hisshu_stats,
        'previous_hisshu_stats': previous_hisshu_stats
    }

def render_search_page():
    """
    ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä»•æ§˜ã«åŸºã¥ãå®Œç’§ãªæ¤œç´¢ãƒ»é€²æ—ãƒšãƒ¼ã‚¸å®Ÿè£…
    
    AI Copilotå‘ã‘ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¦ä»¶ã‚’100%æº€ãŸã™çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ©Ÿèƒ½
    """
    
    # â—† ã‚µã‚¤ãƒ‰ãƒãƒ¼é€£æºï¼šanalysis_target (å›½è©¦/å­¦å£«è©¦é¨“) ã®å–å¾—
    analysis_target = st.session_state.get("analysis_target", "å›½è©¦")
    level_filter = st.session_state.get("level_filter", ["æœªå­¦ç¿’", "ãƒ¬ãƒ™ãƒ«0", "ãƒ¬ãƒ™ãƒ«1", "ãƒ¬ãƒ™ãƒ«2", "ãƒ¬ãƒ™ãƒ«3", "ãƒ¬ãƒ™ãƒ«4", "ç¿’å¾—æ¸ˆã¿"])
    subject_filter = st.session_state.get("subject_filter", [])
    
    # 1. æ¦‚è¦ã¨ç›®çš„ - ãƒšãƒ¼ã‚¸ãƒ˜ãƒƒãƒ€ãƒ¼
    st.subheader(f"ğŸ“ˆ å­¦ç¿’ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ ({analysis_target})")
    
    # 2. åˆæœŸãƒ‡ãƒ¼ã‚¿å–å¾—
    uid = st.session_state.get("uid", "guest")
    cards = st.session_state.get("cards", {})
    
    # uidãŒå­˜åœ¨ã—ã€cardsãŒç©ºã®å ´åˆã€Firestoreã‹ã‚‰èª­ã¿è¾¼ã¿
    if uid != "guest" and not cards:
        try:
            db = get_firestore_manager()
            user_cards = db.get_user_cards(uid)
            if user_cards:
                cards.update(user_cards)
                st.session_state["cards"] = cards
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’å–å¾—ã—ã¦æ¼”ç¿’ãƒ­ã‚°ã‚’ç¢ºèª
                try:
                    user_ref = db.db.collection("users").document(uid)
                    user_doc = user_ref.get()
                    
                    if user_doc.exists:
                        user_data = user_doc.to_dict()
                        result_log = user_data.get('result_log', {})
                        
                        if result_log:
                            # result_logã‚’historyã«å¤‰æ›
                            for q_id, log_entry in result_log.items():
                                if q_id in cards:
                                    if 'history' not in cards[q_id]:
                                        cards[q_id]['history'] = []
                                    
                                    # ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’historyå½¢å¼ã«å¤‰æ›
                                    history_entry = {
                                        'timestamp': log_entry.get('timestamp'),
                                        'quality': log_entry.get('quality', 0),
                                        'is_correct': log_entry.get('quality', 0) >= 3,
                                        'user_answer': log_entry.get('user_answer'),
                                        'time_spent': log_entry.get('time_spent')
                                    }
                                    cards[q_id]['history'].append(history_entry)
                        
                except Exception as e:
                    print(f"[WARNING] result_logå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                    
        except Exception as e:
            st.error(f"[ERROR] Firestoreå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"[WARNING] Firestoreå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®result_logã‚‚ç¢ºèª
    result_log = st.session_state.get("result_log", {})
    if result_log:
        # result_logã‹ã‚‰historyã‚’ä½œæˆ
        for q_id, log_entry in result_log.items():
            if q_id in cards:
                if 'history' not in cards[q_id]:
                    cards[q_id]['history'] = []
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®result_logã‹ã‚‰historyå½¢å¼ã«å¤‰æ›
                history_entry = {
                    'timestamp': log_entry.get('timestamp'),
                    'quality': log_entry.get('quality', 0),
                    'is_correct': log_entry.get('quality', 0) >= 3,
                    'user_answer': log_entry.get('user_answer'),
                    'time_spent': log_entry.get('time_spent')
                }
                cards[q_id]['history'].append(history_entry)
    
    # 3. æ¨©é™ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šã®å–å¾—
    has_gakushi_permission = check_gakushi_permission(uid)
    analysis_target = st.session_state.get("analysis_target", "å›½è©¦")
    level_filter = st.session_state.get("level_filter", LEVEL_ORDER)
    subject_filter = st.session_state.get("subject_filter", [])
    
    # 4. 2. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŒ‡ç¤ºã«åŸºã¥ãä¿®æ­£ï¼šä¸»è¦ãªãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¸€åº¦ã ã‘ä½œæˆ
    all_data = []
    
    for question in ALL_QUESTIONS:
        q_number = question.get('number', '')
        
        # analysis_targetã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¨©é™ã«åŸºã¥ããƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if analysis_target == "å›½è©¦" and q_number.startswith('G'):
            continue
        if analysis_target == "å­¦å£«è©¦é¨“":
            if not q_number.startswith('G') or not has_gakushi_permission:
                continue
        
        # å„å•é¡Œã«å¯¾å¿œã™ã‚‹cardsãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€å­¦ç¿’ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
        card = cards.get(q_number, {})
        level = calculate_card_level(card)
        
        # is_hisshuãƒ•ãƒ©ã‚°ã‚’analysis_targetã«å¿œã˜ã¦åˆ¤å®š
        if analysis_target == "å­¦å£«è©¦é¨“":
            is_hisshu = q_number in GAKUSHI_HISSHU_Q_NUMBERS_SET
        else:
            is_hisshu = q_number in HISSHU_Q_NUMBERS_SET
        
        all_data.append({
            'id': q_number,
            'subject': question.get('subject', ''),
            'year': question.get('year', 0),
            'question_text': question.get('question_text', ''),
            'choices': question.get('choices', []),
            'answer': question.get('answer', ''),
            'level': level,
            'is_hisshu': is_hisshu,
            'card_data': card,
            'history': card.get('history', [])
        })
    
    # åŸºæœ¬DataFrameã‚’ä½œæˆï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰ã®å…¨å¯¾è±¡å•é¡Œï¼‰
    base_df = pd.DataFrame(all_data)
    
    # 5. ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’åŸºæœ¬DataFrameã«é©ç”¨
    filtered_df = base_df.copy()
    
    if not filtered_df.empty:
        # ãƒ¬ãƒ™ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
        if level_filter and set(level_filter) != set(LEVEL_ORDER):
            filtered_df = filtered_df[filtered_df['level'].isin(level_filter)]
        
        # ç§‘ç›®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
        if subject_filter:
            filtered_df = filtered_df[filtered_df['subject'].isin(subject_filter)]
    
    # 6. ã‚µãƒãƒªãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—ã¨è¡¨ç¤ºï¼ˆUserDataExtractorå¼·åŒ–ç‰ˆï¼‰
    if not filtered_df.empty:
        # æ–°ã—ã„actionableãªæŒ‡æ¨™ã®è¨ˆç®—ï¼ˆå‰æ—¥æ¯”ãƒ»å‰é€±æ¯”ã‚’å«ã‚€ï¼‰
        metrics = calculate_progress_metrics(cards, base_df, uid, analysis_target)
        
        # UserDataExtractorã‹ã‚‰ã®è¿½åŠ æƒ…å ±ã‚’å–å¾—
        extractor_insights = {}
        if uid != "guest" and UserDataExtractor:
            try:
                extractor = UserDataExtractor()
                comprehensive_stats = extractor.get_user_comprehensive_stats(uid, analysis_target)
                if comprehensive_stats:
                    extractor_insights = {
                        'weak_categories': comprehensive_stats.get('weak_categories', []),
                        'learning_efficiency': comprehensive_stats.get('learning_efficiency', 0),
                        'total_studied_cards': comprehensive_stats.get('total_studied_cards', 0)
                    }
            except Exception as e:
                print(f"[WARNING] UserDataExtractor insightså–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # st.columns(4)ã‚’ä½¿ç”¨ã—ã¦4ã¤ã®æ–°ã—ã„æŒ‡æ¨™ã‚’st.metricã§è¡¨ç¤º
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            # å­¦ç¿’é€²æ—ç‡ï¼ˆå‰æ—¥æ¯”ä»˜ãï¼‰
            progress_delta_text = f"+{metrics['progress_delta']} å•ï¼ˆå‰æ—¥æ¯”ï¼‰" if metrics['progress_delta'] > 0 else f"{metrics['progress_delta']} å•ï¼ˆå‰æ—¥æ¯”ï¼‰" if metrics['progress_delta'] < 0 else "å¤‰åŒ–ãªã—ï¼ˆå‰æ—¥æ¯”ï¼‰"
            st.metric(
                "å­¦ç¿’é€²æ—ç‡",
                f"{metrics['current_studied_count']} / {metrics['total_count']} å•",
                delta=progress_delta_text
            )
            
            # å¼±ç‚¹åˆ†é‡ã®ãƒ’ãƒ³ãƒˆè¡¨ç¤º
            if extractor_insights.get('weak_categories'):
                weak_hint = ", ".join(extractor_insights['weak_categories'][:2])
                st.caption(f"ğŸ’¡ è¦å¾©ç¿’: {weak_hint}")
        
        with col2:
            # å¿…ä¿®å•é¡Œã®é€²æ—ï¼ˆå‰æ—¥æ¯”ä»˜ãï¼‰
            hisshu_delta_text = f"+{metrics['hisshu_delta']} å•ï¼ˆå‰æ—¥æ¯”ï¼‰" if metrics['hisshu_delta'] > 0 else f"{metrics['hisshu_delta']} å•ï¼ˆå‰æ—¥æ¯”ï¼‰" if metrics['hisshu_delta'] < 0 else "å¤‰åŒ–ãªã—ï¼ˆå‰æ—¥æ¯”ï¼‰"
            st.metric(
                "å¿…ä¿®å•é¡Œã®é€²æ—",
                f"{metrics['current_hisshu_studied_count']} / {metrics['hisshu_total_count']} å•",
                delta=hisshu_delta_text
            )
        
        with col3:
            # ä»Šæ—¥ã®å­¦ç¿’ï¼ˆæ˜¨æ—¥ã®å®Ÿç¸¾æ¯”è¼ƒä»˜ãï¼‰
            today_delta_text = f"æ˜¨æ—¥: {metrics['yesterday_study_count']} å•"
            st.metric(
                "ä»Šæ—¥ã®å­¦ç¿’",
                f"{metrics['today_study_count']} å•",
                delta=today_delta_text
            )
            
            # å­¦ç¿’åŠ¹ç‡ã‚¹ã‚³ã‚¢è¡¨ç¤º
            if extractor_insights.get('learning_efficiency', 0) > 0:
                efficiency = extractor_insights['learning_efficiency']
                st.caption(f"ğŸ“ˆ å­¦ç¿’åŠ¹ç‡: {efficiency:.1%}")
        
        with col4:
            # ç›´è¿‘7æ—¥é–“ã®æ­£è§£ç‡ï¼ˆå‰é€±æ¯”ä»˜ãï¼‰
            accuracy_delta_text = f"{metrics['accuracy_delta']:+.1f}%ï¼ˆå‰é€±æ¯”ï¼‰"
            delta_color = "normal" if metrics['accuracy_delta'] >= 0 else "inverse"
            st.metric(
                "ç›´è¿‘7æ—¥é–“ã®æ­£è§£ç‡",
                f"{metrics['recent_accuracy']:.1f} %",
                delta=accuracy_delta_text,
                delta_color=delta_color
            )
    
    # 7. ã‚¿ãƒ–ã‚³ãƒ³ãƒ†ãƒŠ - 4ã¤ã®ã‚¿ãƒ–ï¼ˆè©³ç´°åˆ†æã‚¿ãƒ–ã‚’å‰Šé™¤ã—ã¦å…ƒã®æ§‹æˆã«æˆ»ã™ï¼‰
    tab1, tab2, tab3, tab4 = st.tabs(["æ¦‚è¦", "ã‚°ãƒ©ãƒ•åˆ†æ", "å•é¡Œãƒªã‚¹ãƒˆ", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢"])
    
    with tab1:
        render_overview_tab_perfect(filtered_df, ALL_QUESTIONS, analysis_target)
    
    with tab2:
        render_graph_analysis_tab_perfect(filtered_df)
    
    with tab3:
        render_question_list_tab_perfect(filtered_df)
    
    with tab4:
        render_keyword_search_tab_perfect(analysis_target)

def render_overview_tab_perfect(filtered_df: pd.DataFrame, ALL_QUESTIONS: list, analysis_target: str):
    """
    æ¦‚è¦ã‚¿ãƒ– - UserDataExtractorå¼·åŒ–ç‰ˆ
    st.columns(2)ã§2åˆ†å‰²ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã€ç¿’ç†Ÿåº¦åˆ†å¸ƒã¨æ­£è§£ç‡è¡¨ç¤º
    """
    if filtered_df.empty:
        st.info("è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # UserDataExtractorã‹ã‚‰ã®è¿½åŠ æ´å¯Ÿã‚’å–å¾—
    uid = st.session_state.get("uid", "guest")
    insights_text = ""
    if uid != "guest" and UserDataExtractor:
        try:
            extractor = UserDataExtractor()
            comprehensive_stats = extractor.get_user_comprehensive_stats(uid)
            if comprehensive_stats:
                weak_areas = comprehensive_stats.get('weak_categories', [])
                efficiency = comprehensive_stats.get('learning_efficiency', 0)
                if weak_areas:
                    insights_text = f"ğŸ’¡ æ¨å¥¨å¾©ç¿’åˆ†é‡: {', '.join(weak_areas[:3])}"
                if efficiency > 0.7:
                    insights_text += " | ğŸš€ å­¦ç¿’åŠ¹ç‡ãŒè‰¯å¥½ã§ã™"
        except Exception as e:
            print(f"[WARNING] æ¦‚è¦ã‚¿ãƒ–æ´å¯Ÿå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    # st.columns(2)ã‚’ä½¿ç”¨ã—ã¦2åˆ†å‰²ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("##### ã‚«ãƒ¼ãƒ‰ç¿’ç†Ÿåº¦åˆ†å¸ƒ")
        
        # UserDataExtractorã‹ã‚‰ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒã‚’å–å¾—ï¼ˆå„ªå…ˆï¼‰
        level_distribution_source = "å¾“æ¥ãƒ­ã‚¸ãƒƒã‚¯"
        level_counts = None
        
        if uid != "guest" and UserDataExtractor:
            try:
                extractor = UserDataExtractor()
                enhanced_stats = extractor.get_user_comprehensive_stats(uid, analysis_target)
                if enhanced_stats and 'level_distribution' in enhanced_stats:
                    level_dist = enhanced_stats['level_distribution']
                    
                    # UserDataExtractorã®çµæœã‚’ä½¿ç”¨
                    level_counts = pd.Series(level_dist)
                    level_counts = level_counts.reindex(LEVEL_ORDER, fill_value=0)
                    level_distribution_source = "UserDataExtractor"
            except Exception as e:
                print(f"[WARNING] UserDataExtractor ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ãƒ­ã‚¸ãƒƒã‚¯
        if level_counts is None:
            updated_levels = []
            for _, row in filtered_df.iterrows():
                card_data = row['card_data']
                updated_level = calculate_card_level(card_data)
                updated_levels.append(updated_level)
            
            level_counts = pd.Series(updated_levels).value_counts()
            level_counts = level_counts.reindex(LEVEL_ORDER, fill_value=0)
        
        # è¡¨å½¢å¼è¡¨ç¤º
        level_df = pd.DataFrame({
            'ãƒ¬ãƒ™ãƒ«': level_counts.index,
            'å•é¡Œæ•°': level_counts.values
        })
        
        st.dataframe(
            level_df,
            use_container_width=True,
            hide_index=True
        )
        
        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        st.caption(f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {level_distribution_source}")
        
        # AIæ´å¯Ÿã‚’è¡¨ç¤º
        if insights_text:
            st.info(insights_text)
    
    with col2:
        st.markdown("##### æ­£è§£ç‡ (True Retention)")
        
        # UserDataExtractorã‹ã‚‰ã‚ˆã‚Šæ­£ç¢ºãªæ­£è§£ç‡ã‚’å–å¾—
        uid = st.session_state.get("uid", "guest")
        enhanced_accuracy = None
        if uid != "guest" and UserDataExtractor:
            try:
                extractor = UserDataExtractor()
                evaluation_logs = extractor.extract_self_evaluation_logs(uid)
                if evaluation_logs:
                    # analysis_targetã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    filtered_logs = []
                    for log in evaluation_logs:
                        q_id = log.get('question_id', '')
                        if analysis_target == "å­¦å£«è©¦é¨“":
                            # å­¦å£«è©¦é¨“å•é¡Œã®ã¿ï¼ˆG24, G25ã§å§‹ã¾ã‚‹ï¼‰
                            if q_id.startswith('G24') or q_id.startswith('G25'):
                                filtered_logs.append(log)
                        else:
                            # å›½è©¦å•é¡Œã®ã¿ï¼ˆG24, G25ã§å§‹ã¾ã‚‰ãªã„ï¼‰
                            if not (q_id.startswith('G24') or q_id.startswith('G25')):
                                filtered_logs.append(log)
                    
                    print(f"[INFO] {analysis_target}ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: {len(filtered_logs)}ä»¶ (å…ƒ: ç·{len(evaluation_logs)}ä»¶)")
                    
                    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ­ã‚°ã§æ­£è§£ç‡è¨ˆç®—
                    if filtered_logs:
                        # å…¨ä½“æ­£è§£ç‡
                        total_correct = sum(1 for log in filtered_logs if log.get('quality', 0) >= 3)
                        total_attempts = len(filtered_logs)
                        overall_rate = (total_correct / total_attempts * 100) if total_attempts > 0 else 0
                        
                        # å¿…ä¿®å•é¡Œæ­£è§£ç‡
                        hisshu_correct = 0
                        hisshu_attempts = 0
                        
                        # å­¦å£«è©¦é¨“å•é¡Œã®å ´åˆã¯å•é¡Œç•ªå·ã§å¿…ä¿®åˆ¤å®šã€å›½è©¦å•é¡Œã®å ´åˆã¯å¾“æ¥é€šã‚Š
                        for log in filtered_logs:
                            q_id = log.get('question_id', '')
                            is_hisshu = False
                            
                            if analysis_target == "å­¦å£«è©¦é¨“":
                                # å­¦å£«è©¦é¨“å•é¡Œ: G24-2-A-1ã€œ20, G24-2-B-1ã€œ20ãªã©ãŒå¿…ä¿®
                                import re
                                match = re.search(r'G\d+-\d+-[A-Z]-(\d+)', q_id)
                                if match:
                                    question_num = int(match.group(1))
                                    is_hisshu = (question_num <= 20)  # 1ã€œ20ç•ªãŒå¿…ä¿®
                            else:
                                # å›½è©¦å•é¡Œ: å¾“æ¥ã®HISSHU_Q_NUMBERS_SETã‚’ä½¿ç”¨
                                is_hisshu = q_id in HISSHU_Q_NUMBERS_SET
                            
                            if is_hisshu:
                                hisshu_attempts += 1
                                if log.get('quality', 0) >= 3:
                                    hisshu_correct += 1
                        
                        hisshu_rate = (hisshu_correct / hisshu_attempts * 100) if hisshu_attempts > 0 else 0
                        
                        enhanced_accuracy = {
                            'overall_rate': overall_rate,
                            'overall_attempts': total_attempts,
                            'overall_correct': total_correct,
                            'hisshu_rate': hisshu_rate,
                            'hisshu_attempts': hisshu_attempts,
                            'hisshu_correct': hisshu_correct
                        }
                        print(f"[INFO] æ¦‚è¦ã‚¿ãƒ–å¼·åŒ–: å…¨ä½“æ­£è§£ç‡{overall_rate:.1f}%, å¿…ä¿®æ­£è§£ç‡{hisshu_rate:.1f}%")
            except Exception as e:
                print(f"[WARNING] æ¦‚è¦ã‚¿ãƒ–æ­£è§£ç‡å¼·åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        
        # å¼·åŒ–ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
        if enhanced_accuracy:
            # UserDataExtractorã‹ã‚‰ã®é«˜ç²¾åº¦ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            st.metric(
                label="é¸æŠç¯„å›²ã®æ­£è§£ç‡",
                value=f"{enhanced_accuracy['overall_rate']:.1f}%",
                delta=f"{enhanced_accuracy['overall_correct']} / {enhanced_accuracy['overall_attempts']} å›"
            )
            st.metric(
                label="ã€å¿…ä¿®å•é¡Œã€‘ã®æ­£è§£ç‡",
                value=f"{enhanced_accuracy['hisshu_rate']:.1f}%",
                delta=f"{enhanced_accuracy['hisshu_correct']} / {enhanced_accuracy['hisshu_attempts']} å›"
            )
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ãƒ­ã‚¸ãƒƒã‚¯
            total_correct = 0
            total_attempts = 0
            hisshu_correct = 0
            hisshu_attempts = 0
            
            for _, row in filtered_df.iterrows():
                history = row.get('history', [])
                is_hisshu = row.get('is_hisshu', False)
                
                if isinstance(history, list):
                    for entry in history:
                        if isinstance(entry, dict):
                            # qualityå€¤ã«ã‚ˆã‚‹æ­£è§£åˆ¤å®šï¼ˆquality >= 3ã§æ­£è§£ï¼‰
                            quality = entry.get('quality', 0)
                            is_correct = quality >= 3
                            
                            total_attempts += 1
                            if is_correct:
                                total_correct += 1
                            
                            if is_hisshu:
                                hisshu_attempts += 1
                                if is_correct:
                                    hisshu_correct += 1
            
            # æ­£è§£ç‡è¨ˆç®—
            overall_rate = (total_correct / total_attempts * 100) if total_attempts > 0 else 0
            hisshu_rate = (hisshu_correct / hisshu_attempts * 100) if hisshu_attempts > 0 else 0
            
            # st.metricã‚’2ã¤ä½¿ç”¨ï¼ˆdeltaå¼•æ•°ã§å†…è¨³ã‚’è¡¨ç¤ºï¼‰
            st.metric(
                label="é¸æŠç¯„å›²ã®æ­£è§£ç‡",
                value=f"{overall_rate:.1f}%",
                delta=f"{total_correct} / {total_attempts} å›"
            )
            st.metric(
                label="ã€å¿…ä¿®å•é¡Œã€‘ã®æ­£è§£ç‡",
                value=f"{hisshu_rate:.1f}%",
                delta=f"{hisshu_correct} / {hisshu_attempts} å›"
            )

def render_graph_analysis_tab_perfect(filtered_df: pd.DataFrame):
    """
    ã‚°ãƒ©ãƒ•åˆ†æã‚¿ãƒ– - UserDataExtractorå¼·åŒ–ç‰ˆ
    ç§‘ç›®åˆ¥é€²æ—ã€å­¦ç¿’è¨˜éŒ²ã€ãƒ¬ãƒ™ãƒ«åˆ¥åˆ†å¸ƒã‚’Plotlyã§è¡¨ç¤º
    """
    if filtered_df.empty:
        st.info("è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    # UserDataExtractorã‹ã‚‰ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    uid = st.session_state.get("uid", "guest")
    enhanced_analytics = {}
    if uid != "guest" and UserDataExtractor:
        try:
            extractor = UserDataExtractor()
            evaluation_logs = extractor.extract_self_evaluation_logs(uid)
            if evaluation_logs:
                enhanced_analytics['evaluation_logs'] = evaluation_logs
                print(f"[INFO] ã‚°ãƒ©ãƒ•åˆ†æå¼·åŒ–: {len(evaluation_logs)}ä»¶ã®è©•ä¾¡ãƒ­ã‚°ã‚’å–å¾—")
        except Exception as e:
            print(f"[WARNING] ã‚°ãƒ©ãƒ•åˆ†æå¼·åŒ–ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ç§‘ç›®åˆ¥é€²æ—
    st.markdown("##### ç§‘ç›®åˆ¥é€²æ—çŠ¶æ³")
    
    # ã‚°ãƒ©ãƒ•è¡¨ç¤ºå‰ã®èª¬æ˜ã‚’è¿½åŠ 
    st.info("ğŸ“Š å„ç§‘ç›®ã®å­¦ç¿’é€²æ—ã‚’æ¨ªæ£’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤ºã—ã¾ã™ã€‚ã‚°ãƒ¬ãƒ¼: æœªå­¦ç¿’ã€é’: å­¦ç¿’ä¸­ã€ç·‘: ç¿’å¾—æ¸ˆã¿")
    
    try:
        # ç§‘ç›®åˆ¥ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒãƒ‡ãƒ¼ã‚¿ã‚’è©³ç´°ã«é›†è¨ˆï¼ˆå®Ÿéš›ã®JSONãƒ‡ãƒ¼ã‚¿ã®ç§‘ç›®åã‚’ä½¿ç”¨ï¼‰
        subject_level_data = []
        
        for subject in filtered_df['subject'].unique():
            # å®Ÿéš›ã®ç§‘ç›®åã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆæ¨™æº–åŒ–ã¯è¡Œã‚ãªã„ï¼‰
            subject_df = filtered_df[filtered_df['subject'] == subject]
            total_count = len(subject_df)
            
            if total_count == 0:
                continue
            
            # å„ãƒ¬ãƒ™ãƒ«ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            level_counts = subject_df['level'].value_counts()
            
            # æœªå­¦ç¿’ä»¥å¤–ã‚’ã€Œå­¦ç¿’æ¸ˆã¿ã€ã¨ã—ã¦é›†è¨ˆ
            learned_count = total_count - level_counts.get('æœªå­¦ç¿’', 0)
            mastered_count = level_counts.get('ç¿’å¾—æ¸ˆã¿', 0)
            
            # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸è¨ˆç®—
            learned_pct = (learned_count / total_count * 100) if total_count > 0 else 0
            mastered_pct = (mastered_count / total_count * 100) if total_count > 0 else 0
            unlearned_pct = 100 - learned_pct
            
            subject_level_data.append({
                'subject': subject,  # å®Ÿéš›ã®ç§‘ç›®åã‚’ãã®ã¾ã¾ä½¿ç”¨
                'total': total_count,
                'learned': learned_count,
                'mastered': mastered_count,
                'learned_pct': learned_pct,
                'mastered_pct': mastered_pct,
                'unlearned_pct': unlearned_pct
            })
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        progress_df = pd.DataFrame(subject_level_data)
        
        if len(progress_df) == 0:
            st.warning("ç§‘ç›®åˆ¥ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # å®Ÿéš›ã®ç§‘ç›®åã‚’ä½¿ç”¨ã™ã‚‹ã®ã§é‡è¤‡çµ±åˆã¯ä¸è¦
        # å•é¡Œæ•°ã§é™é †ã‚½ãƒ¼ãƒˆã—ã¦è¦‹ã‚„ã™ãã™ã‚‹
        if len(progress_df) > 0:
            progress_df = progress_df.sort_values('total', ascending=True)  # å•é¡Œæ•°æ˜‡é †ã§ã‚½ãƒ¼ãƒˆ
        
        # ç©ã¿ä¸Šã’æ¨ªæ£’ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
        fig = go.Figure()
        
        # å¯è¦–æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã€æœ€å°è¡¨ç¤ºå¹…ã‚’è¨­å®š
        min_visible_width = 2.0  # æœ€ä½2%ã¯è¡¨ç¤ºã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
        
        # æœªå­¦ç¿’éƒ¨åˆ†ï¼ˆè–„ã„ã‚°ãƒ¬ãƒ¼ - è¦–èªæ€§å‘ä¸Šï¼‰
        unlearned_values = progress_df['unlearned_pct'].tolist()
        fig.add_trace(go.Bar(
            name='æœªå­¦ç¿’',
            y=progress_df['subject'],
            x=unlearned_values,
            orientation='h',
            marker_color='#BDBDBD',
            text=[f"{pct:.0f}%" if pct >= 10 else "" for pct in unlearned_values],
            textposition='inside',
            hovertemplate='<b>%{y}</b><br>æœªå­¦ç¿’: %{x:.1f}%<extra></extra>'
        ))
        
        # å­¦ç¿’æ¸ˆã¿ï¼ˆæœªç¿’å¾—ï¼‰éƒ¨åˆ†ï¼ˆè¦–èªæ€§ã®é«˜ã„é’è‰²ï¼‰
        learning_pct = progress_df['learned_pct'] - progress_df['mastered_pct']
        # æœ€å°è¡¨ç¤ºå¹…ã‚’é©ç”¨
        learning_values = [max(pct, min_visible_width) if pct > 0 else pct for pct in learning_pct]
        fig.add_trace(go.Bar(
            name='å­¦ç¿’ä¸­',
            y=progress_df['subject'],
            x=learning_values,
            orientation='h',
            marker_color='#42A5F5',
            text=[f"{pct:.0f}%" if pct >= 5 else "" for pct in learning_pct],  # å…ƒã®å€¤ã§ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
            textposition='inside',
            hovertemplate='<b>%{y}</b><br>å­¦ç¿’ä¸­: %{customdata:.1f}%<extra></extra>',
            customdata=learning_pct  # å…ƒã®å€¤ã‚’ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿æŒ
        ))
        
        # ç¿’å¾—æ¸ˆã¿éƒ¨åˆ†ï¼ˆé”æˆæ„Ÿã®ã‚ã‚‹ç·‘è‰²ï¼‰
        mastered_values = [max(pct, min_visible_width) if pct > 0 else pct for pct in progress_df['mastered_pct']]
        fig.add_trace(go.Bar(
            name='ç¿’å¾—æ¸ˆã¿',
            y=progress_df['subject'],
            x=mastered_values,
            orientation='h',
            marker_color='#4CAF50',
            text=[f"{pct:.0f}%" if pct >= 5 else "" for pct in progress_df['mastered_pct']],  # å…ƒã®å€¤ã§ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
            textposition='inside',
            hovertemplate='<b>%{y}</b><br>ç¿’å¾—æ¸ˆã¿: %{customdata:.1f}%<extra></extra>',
            customdata=progress_df['mastered_pct']  # å…ƒã®å€¤ã‚’ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿æŒ
        ))
        
        fig.update_layout(
            title={
                'text': "ç§‘ç›®åˆ¥é€²æ—çŠ¶æ³ï¼ˆå„ç§‘ç›®100%åŸºæº–ï¼‰",
                'x': 0,  # ã‚¿ã‚¤ãƒˆãƒ«ã‚’å·¦å¯„ã›
                'xanchor': 'left'
            },
            xaxis_title="é€²æ—ç‡ (%)",
            yaxis_title="ç§‘ç›®",
            barmode='stack',
            height=max(500, len(progress_df) * 35),  # ç§‘ç›®æ•°ã«å¿œã˜ã¦é«˜ã•èª¿æ•´ï¼ˆæœ€å°500pxï¼‰
            xaxis=dict(range=[0, 105], tickformat='.0f', ticksuffix='%'),
            yaxis=dict(
                automargin=True, 
                tickmode='linear',
                side='left'  # Yè»¸ãƒ©ãƒ™ãƒ«ã‚’å·¦å´ã«é…ç½®
            ),
            legend=dict(
                orientation="h", 
                yanchor="bottom", 
                y=1.02, 
                xanchor="left",  # å‡¡ä¾‹ã‚’å·¦å¯„ã›
                x=0
            ),
            margin=dict(l=200, r=50, t=80, b=50),  # å·¦ãƒãƒ¼ã‚¸ãƒ³ã‚’åºƒãå–ã£ã¦ç§‘ç›®åã‚’è¡¨ç¤º
            showlegend=True,
            plot_bgcolor='white',
            paper_bgcolor='white',
            font=dict(size=12)  # ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
        )
        
        # æ¨ªæ£’ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºï¼ˆå·¦å¯„ã›ã§é«˜ã•ä¸­å¤®é…ç½®ï¼‰
        print(f"[DEBUG] ã‚°ãƒ©ãƒ•åˆ†æã‚¿ãƒ–ã§æ¨ªæ£’ã‚°ãƒ©ãƒ•è¡¨ç¤ºé–‹å§‹")
        print(f"[DEBUG] figã®å‹: {type(fig)}")
        print(f"[DEBUG] progress_dfç§‘ç›®æ•°: {len(progress_df)}")
        print(f"[DEBUG] figã®dataæ•°: {len(fig.data)}")
        print(f"[DEBUG] figã®é«˜ã•: {fig.layout.height}")
        
        # ã‚°ãƒ©ãƒ•ã‚’å·¦å¯„ã›ã§é…ç½®ï¼ˆé«˜ã•ä¸­å¤®ï¼‰
        try:
            st.plotly_chart(fig, use_container_width=True, key="subject_progress_chart")
            print(f"[DEBUG] Plotlyãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºæˆåŠŸ")
        except Exception as chart_error:
            print(f"[ERROR] Plotlyãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {chart_error}")
            st.error(f"ã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {chart_error}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
            st.bar_chart(progress_df.set_index('subject')[['learned_pct', 'mastered_pct']])
        
        print(f"[DEBUG] ã‚°ãƒ©ãƒ•åˆ†æã‚¿ãƒ–ã§æ¨ªæ£’ã‚°ãƒ©ãƒ•è¡¨ç¤ºå®Œäº†")
        
        # è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ã¯éè¡¨ç¤ºï¼ˆUIãŒç…©é›‘ã«ãªã‚‹ãŸã‚ï¼‰
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©³ç´°ã‚’çŸ¥ã‚ŠãŸã„å ´åˆã¯ã‚°ãƒ©ãƒ•ã®ãƒ›ãƒãƒ¼æƒ…å ±ã§ååˆ†
        
    except Exception as e:
        st.error(f"ã‚°ãƒ©ãƒ•ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        st.info("ã‚°ãƒ©ãƒ•ã®è¡¨ç¤ºã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
    
    # å­¦ç¿’è¨˜éŒ² - UserDataExtractorå¼·åŒ–ç‰ˆ
    st.markdown("##### å­¦ç¿’ã®è¨˜éŒ²")
    
    # UserDataExtractorã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
    if enhanced_analytics.get('evaluation_logs'):
        evaluation_logs = enhanced_analytics['evaluation_logs']
        
        # é«˜ç²¾åº¦ãªæ—¥åˆ¥å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        daily_study = defaultdict(lambda: {'count': 0, 'correct': 0, 'avg_quality': 0})
        today = datetime.datetime.now()
        ninety_days_ago = today - datetime.timedelta(days=90)
        
        quality_sum = defaultdict(int)
        
        for log in evaluation_logs:
            try:
                # ã‚ˆã‚Šå®‰å…¨ãªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ‘ãƒ¼ã‚¹
                timestamp = log['timestamp']
                if isinstance(timestamp, str):
                    if 'T' in timestamp:
                        # ISOå½¢å¼
                        timestamp_str = timestamp.split('.')[0] if '.' in timestamp else timestamp
                        log_datetime = datetime.datetime.fromisoformat(timestamp_str)
                    else:
                        # é€šå¸¸å½¢å¼
                        log_datetime = datetime.datetime.fromisoformat(timestamp[:19])
                else:
                    # datetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                    log_datetime = timestamp
                    
                if log_datetime >= ninety_days_ago:
                    date_str = log_datetime.date().isoformat()
                    daily_study[date_str]['count'] += 1
                    quality = log.get('quality', 0)
                    quality_sum[date_str] += quality
                    if quality >= 3:
                        daily_study[date_str]['correct'] += 1
            except:
                continue
        
        # å¹³å‡è©•ä¾¡ã‚’è¨ˆç®—
        for date_str in daily_study:
            if daily_study[date_str]['count'] > 0:
                daily_study[date_str]['avg_quality'] = quality_sum[date_str] / daily_study[date_str]['count']
        
        if daily_study:
            study_df = pd.DataFrame([
                {
                    'æ—¥ä»˜': date_str,
                    'å­¦ç¿’å›æ•°': data['count'],
                    'æ­£è§£æ•°': data['correct'],
                    'æ­£è§£ç‡': (data['correct'] / data['count'] * 100) if data['count'] > 0 else 0,
                    'å¹³å‡è©•ä¾¡': data['avg_quality']
                }
                for date_str, data in daily_study.items()
            ])
            study_df['æ—¥ä»˜'] = pd.to_datetime(study_df['æ—¥ä»˜'])
            study_df = study_df.sort_values('æ—¥ä»˜')
            
            # 2ã¤ã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
            col1, col2 = st.columns(2)
            
            with col1:
                # å­¦ç¿’å›æ•°ã‚°ãƒ©ãƒ•
                fig1 = px.bar(
                    study_df, 
                    x='æ—¥ä»˜', 
                    y='å­¦ç¿’å›æ•°',
                    title='å­¦ç¿’å›æ•°æ¨ç§»ï¼ˆéå»90æ—¥ï¼‰',
                    color='å­¦ç¿’å›æ•°',
                    color_continuous_scale='Blues'
                )
                fig1.update_traces(hovertemplate='<b>%{x|%Y-%m-%d}</b><br>å­¦ç¿’å›æ•°: %{y}å•<extra></extra>')
                fig1.update_layout(coloraxis_showscale=False, height=300)
                st.plotly_chart(fig1, use_container_width=True)
            
            with col2:
                # æ­£è§£ç‡ã‚°ãƒ©ãƒ•
                fig2 = px.line(
                    study_df, 
                    x='æ—¥ä»˜', 
                    y='æ­£è§£ç‡',
                    title='æ­£è§£ç‡æ¨ç§»ï¼ˆéå»90æ—¥ï¼‰',
                    line_shape='spline'
                )
                fig2.update_traces(hovertemplate='<b>%{x|%Y-%m-%d}</b><br>æ­£è§£ç‡: %{y:.1f}%<extra></extra>')
                fig2.update_layout(height=300)
                fig2.update_traces(line_color='#FF6B6B')
                st.plotly_chart(fig2, use_container_width=True)
            
            # å¼·åŒ–ã•ã‚ŒãŸçµ±è¨ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹
            col1, col2, col3, col4 = st.columns(4)
            total_days = len(study_df)
            total_sessions = study_df['å­¦ç¿’å›æ•°'].sum()
            avg_daily = study_df['å­¦ç¿’å›æ•°'].mean()
            avg_accuracy = study_df['æ­£è§£ç‡'].mean()

            with col1:
                st.metric("å­¦ç¿’æ—¥æ•°", f"{total_days}æ—¥", help="éå»90æ—¥é–“ã®å®Ÿç¸¾")
            with col2:
                st.metric("ç·å­¦ç¿’å›æ•°", f"{total_sessions}å›", help="éå»90æ—¥é–“ã®å®Ÿç¸¾")
            with col3:
                st.metric("1æ—¥å¹³å‡", f"{avg_daily:.1f}å›", help="éå»90æ—¥é–“ã®å­¦ç¿’æ—¥å¹³å‡")
            with col4:
                st.metric("å¹³å‡æ­£è§£ç‡", f"{avg_accuracy:.1f}%", help="éå»90æ—¥é–“ã®å¹³å‡")
        else:
            st.info("å­¦ç¿’è¨˜éŒ²ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®ãƒ­ã‚¸ãƒƒã‚¯
        daily_study = defaultdict(int)
        today = datetime.datetime.now()
        ninety_days_ago = today - datetime.timedelta(days=90)

        for _, row in filtered_df.iterrows():
            history = row.get('history', [])
            if isinstance(history, list):
                for entry in history:
                    if isinstance(entry, dict) and 'timestamp' in entry:
                        try:
                            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ãƒ‘ãƒ¼ã‚¹å‡¦ç†
                            timestamp = entry['timestamp']
                            if hasattr(timestamp, 'date'):
                                entry_datetime = timestamp
                            else:
                                # ã‚ˆã‚Šå®‰å…¨ãªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ‘ãƒ¼ã‚¹
                                try:
                                    if 'T' in str(timestamp):
                                        # ISOå½¢å¼
                                        timestamp_str = str(timestamp).split('.')[0] if '.' in str(timestamp) else str(timestamp)
                                        entry_datetime = datetime.datetime.fromisoformat(timestamp_str)
                                    else:
                                        # é€šå¸¸å½¢å¼
                                        entry_datetime = datetime.datetime.fromisoformat(str(timestamp)[:19])
                                except Exception as e:
                                    print(f"ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ (search_page line 939): {e}")
                                    continue
                            
                            # 90æ—¥ä»¥å†…ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿é›†è¨ˆ
                            if entry_datetime >= ninety_days_ago:
                                date_str = entry_datetime.date().isoformat()
                                daily_study[date_str] += 1
                        except:
                            continue

        if daily_study:
            study_df = pd.DataFrame(list(daily_study.items()), columns=['æ—¥ä»˜', 'å­¦ç¿’å›æ•°'])
            study_df['æ—¥ä»˜'] = pd.to_datetime(study_df['æ—¥ä»˜'])
            study_df = study_df.sort_values('æ—¥ä»˜')
            
            # ã‚·ãƒ³ãƒ—ãƒ«ãªæ£’ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
            fig = px.bar(
                study_df, 
                x='æ—¥ä»˜', 
                y='å­¦ç¿’å›æ•°',
                title='éå»90æ—¥é–“ã®å­¦ç¿’è¨˜éŒ²',
                color='å­¦ç¿’å›æ•°',
                color_continuous_scale='OrRd'
            )
            
            fig.update_traces(hovertemplate='<b>%{x|%Y-%m-%d}</b><br>å­¦ç¿’å›æ•°: %{y}å•<extra></extra>')
            fig.update_layout(
                xaxis_title='æ—¥ä»˜',
                yaxis_title='å­¦ç¿’å›æ•°',
                coloraxis_showscale=False,
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # åŸºæœ¬çµ±è¨ˆ
            col1, col2, col3, col4 = st.columns(4)
            total_days = len(study_df)
            total_sessions = study_df['å­¦ç¿’å›æ•°'].sum()
            avg_daily = study_df['å­¦ç¿’å›æ•°'].mean()
            max_daily = study_df['å­¦ç¿’å›æ•°'].max()

            with col1:
                st.metric("å­¦ç¿’æ—¥æ•°", f"{total_days}æ—¥", help="éå»90æ—¥é–“ã®å®Ÿç¸¾")
            with col2:
                st.metric("ç·å­¦ç¿’å›æ•°", f"{total_sessions}å›", help="éå»90æ—¥é–“ã®å®Ÿç¸¾")
            with col3:
                st.metric("1æ—¥å¹³å‡", f"{avg_daily:.1f}å›", help="éå»90æ—¥é–“ã®å­¦ç¿’æ—¥å¹³å‡")
            with col4:
                st.metric("æœ€å¤§å­¦ç¿’å›æ•°", f"{max_daily}å›", help="éå»90æ—¥é–“ã®æœ€å¤§å€¤")
        else:
            st.info("å­¦ç¿’è¨˜éŒ²ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    # ãƒ¬ãƒ™ãƒ«åˆ¥åˆ†å¸ƒ
    st.markdown("##### å­¦ç¿’ãƒ¬ãƒ™ãƒ«åˆ¥åˆ†å¸ƒ")
    
    level_counts = filtered_df['level'].value_counts()
    level_counts = level_counts.reindex(LEVEL_ORDER, fill_value=0)
    
    try:
        # Plotlyè£½ã®æ£’ã‚°ãƒ©ãƒ•
        fig = px.bar(
            x=level_counts.index, 
            y=level_counts.values,
            title="å­¦ç¿’ãƒ¬ãƒ™ãƒ«åˆ¥åˆ†å¸ƒ",
            color=level_counts.index,
            color_discrete_map=LEVEL_COLORS
        )
        fig.update_layout(showlegend=False)
        st.plotly_chart(fig, use_container_width=True)
    except:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        st.bar_chart(level_counts)

def render_question_list_tab_perfect(filtered_df: pd.DataFrame):
    """
    å•é¡Œãƒªã‚¹ãƒˆã‚¿ãƒ– - ç¸¦é•·ãƒªã‚¹ãƒˆå½¢å¼ã§ã®å…¨é¢åˆ·æ–°
    ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«åˆè‡´ã™ã‚‹å…¨ã¦ã®å•é¡Œã‚’ä¸€è¦§è¡¨ç¤º
    """
    st.subheader("å•é¡Œãƒªã‚¹ãƒˆ")
    
    if filtered_df.empty:
        st.info("ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹å•é¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # 4. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŒ‡ç¤ºã«åŸºã¥ãä¿®æ­£ï¼šã‚·ãƒ³ãƒ—ãƒ«ã§å …ç‰¢ãªã‚½ãƒ¼ãƒˆé–¢æ•°ã«ç½®ãæ›ãˆ
    def get_natural_sort_key(q_id):
        """
        ã‚·ãƒ³ãƒ—ãƒ«ã§å …ç‰¢ãªå•é¡Œç•ªå·ã‚½ãƒ¼ãƒˆã‚­ãƒ¼ç”Ÿæˆé–¢æ•°
        å›½è©¦å•é¡Œï¼ˆ118A1ï¼‰ã¨å­¦å£«è©¦é¨“å•é¡Œï¼ˆG24-1-1-A-1ï¼‰ã®ä¸¡æ–¹ã«å¯¾å¿œ
        """
        import re
        q_id = str(q_id)
        
        # å­¦å£«è©¦é¨“å•é¡Œï¼ˆGå§‹ã¾ã‚Šï¼‰ã®å ´åˆ
        if q_id.startswith('G'):
            # ãƒ‘ã‚¿ãƒ¼ãƒ³1: G22-1-1-A-1 å½¢å¼
            match1 = re.match(r'G(\d+)-(\d+)-(\d+)-([A-Z])-(\d+)', q_id)
            if match1:
                year, term, session, section, number = match1.groups()
                return (1, int(year), int(term), int(session), 0, section, int(number))
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³2: G23-2-A-67 å½¢å¼
            match2 = re.match(r'G(\d+)-(\d+)-([A-Z])-(\d+)', q_id)
            if match2:
                year, term, section, number = match2.groups()
                return (1, int(year), int(term), 999, 0, section, int(number))
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³3: G22-1å†-C-75 å½¢å¼ï¼ˆå†è©¦é¨“ï¼‰
            match3 = re.match(r'G(\d+)-(\d+)å†-([A-Z])-(\d+)', q_id)
            if match3:
                year, term, section, number = match3.groups()
                return (1, int(year), int(term), 1000, 0, section, int(number))
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³4: æ—§å½¢å¼ G97A1
            match4 = re.match(r'G(\d+)([A-Z])(\d+)', q_id)
            if match4:
                year, section, number = match4.groups()
                return (1, int(year), 0, 0, 0, section, int(number))
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return (1, 0, 0, 9999, 0, 'Z', 9999)
        else:
            # å›½è©¦å•é¡Œã®å ´åˆï¼š118A1, 95C40 ãªã©
            match = re.match(r'(\d+)([A-Z]?)(\d+)', q_id)
            if match:
                year, section, number = match.groups()
                section = section if section else 'A'
                return (0, int(year), 0, 0, 0, section, int(number))
            else:
                # æ•°å€¤ã®ã¿ã®å ´åˆ
                num_match = re.search(r'(\d+)', q_id)
                if num_match:
                    return (0, 0, 0, 0, 0, 'A', int(num_match.group(1)))
                else:
                    return (0, 0, 0, 9999, 0, 'Z', 9999)
    
    # 4. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŒ‡ç¤ºã«åŸºã¥ãä¿®æ­£ï¼štry-exceptã§ã‚½ãƒ¼ãƒˆå‡¦ç†ã‚’å›²ã‚€
    try:
        sorted_df = filtered_df.copy()
        sorted_df['sort_key'] = sorted_df['id'].apply(get_natural_sort_key)
        sorted_df = sorted_df.sort_values('sort_key').drop('sort_key', axis=1)
    except Exception as e:
        # 4. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŒ‡ç¤ºã«åŸºã¥ãä¿®æ­£ï¼šãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼ˆæ–‡å­—åˆ—ã‚½ãƒ¼ãƒˆï¼‰
        print(f"[WARNING] ã‚½ãƒ¼ãƒˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã€æ–‡å­—åˆ—ã‚½ãƒ¼ãƒˆã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {e}")
        sorted_df = filtered_df.sort_values('id')
    
    # --- â–¼ ã“ã“ã‹ã‚‰ãŒä¿®æ­£éƒ¨åˆ†ï¼šãƒªã‚¹ãƒˆå½¢å¼è¡¨ç¤º ---
    
    # 1. è¡¨ç¤ºåˆ¶é™ã‚’æ’¤å»ƒã—ã€å…¨ä»¶ã‚’è¡¨ç¤ºå¯¾è±¡ã¨ã™ã‚‹
    display_df = sorted_df
    total_count = len(display_df)
    st.write(f"è¡¨ç¤ºå¯¾è±¡: {total_count}å•")

    # 2. ãƒ«ãƒ¼ãƒ—å‡¦ç†ã§ãƒªã‚¹ãƒˆé …ç›®ã‚’ç”Ÿæˆ
    for _, row in display_df.iterrows():
        level = row['level']
        color = LEVEL_COLORS.get(level, "#757575")
        q_id = row['id']
        # å®Ÿéš›ã®ç§‘ç›®åã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆæ¨™æº–åŒ–ã¯è¡Œã‚ãªã„ï¼‰
        actual_subject = row['subject']
        
        # 3. HTMLã¨CSSã§ãƒªã‚¹ãƒˆé …ç›®ã‚’ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°
        list_item_html = f"""
        <div style="
            border-left: 5px solid {color}; 
            padding: 5px 10px; 
            margin: 3px 0; 
            border-radius: 3px;
            display: flex;
            align-items: center;
        ">
            <span style="
                color: {color}; 
                font-weight: bold; 
                width: 80px; 
                flex-shrink: 0;
            ">{level}</span>
            <span style="font-weight: 500;">{q_id}</span>
            <span style="color: #666; margin-left: 15px; font-size: 0.9em;">{actual_subject}</span>
        </div>
        """
        st.markdown(list_item_html, unsafe_allow_html=True)

def render_keyword_search_tab_perfect(analysis_target: str):
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚¿ãƒ– - å®Œå…¨å†ç¾ç‰ˆ
    æ¤œç´¢æ©Ÿèƒ½ã€çµ±è¨ˆè¡¨ç¤ºã€çµæœãƒªã‚¹ãƒˆè¡¨ç¤ºã€PDFç”Ÿæˆæ©Ÿèƒ½ã‚’å«ã‚€
    """
    st.subheader("ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢")

    # 1. æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ 
    col1, col2 = st.columns([4, 1])
    with col1:
        keyword = st.text_input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", key="search_keyword", 
                               placeholder="ä¾‹ï¼šæ ¹ç®¡æ²»ç™‚ã€ã‚¤ãƒ³ãƒ—ãƒ©ãƒ³ãƒˆã€å’¬åˆ")
    with col2:
        shuffle_results = st.checkbox("æ¤œç´¢çµæœã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«", key="shuffle_search")

    if st.button("ğŸ” æ¤œç´¢å®Ÿè¡Œ", key="execute_search", type="primary", use_container_width=True):
        if keyword:
            # 2. æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯ (è¤‡æ•°ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å¯¾è±¡)
            search_results = []
            
            for question in ALL_QUESTIONS:
                q_number = question.get('number', '')
                
                # analysis_targetãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
                if analysis_target == "å›½è©¦" and q_number.startswith('G'):
                    continue
                if analysis_target == "å­¦å£«è©¦é¨“" and not q_number.startswith('G'):
                    continue
                
                # è¤‡æ•°ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
                searchable_text = [
                    question.get('question', ''),  # æ­£ã—ã„ã‚­ãƒ¼
                    question.get('subject', ''),
                    q_number,
                    str(question.get('choices', [])),
                    question.get('answer', ''),
                    question.get('explanation', '')  # è§£èª¬ã‚‚æ¤œç´¢å¯¾è±¡ã«è¿½åŠ 
                ]
                
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                combined_text = ' '.join(searchable_text).lower()
                if keyword.lower() in combined_text:
                    search_results.append(question)
            
            # ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³é©ç”¨
            if shuffle_results:
                random.shuffle(search_results)
            
            # æ¤œç´¢çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state["search_results"] = search_results
            st.session_state["search_query"] = keyword
            st.session_state["search_analysis_target"] = analysis_target
            st.session_state["search_shuffled"] = shuffle_results
        else:
            st.warning("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    # 3. æ¤œç´¢çµæœè¡¨ç¤º
    if "search_results" in st.session_state:
        results = st.session_state["search_results"]
        query = st.session_state.get("search_query", "")
        search_type = st.session_state.get("search_analysis_target", "å…¨ä½“")
        is_shuffled = st.session_state.get("search_shuffled", False)

        if results:
            # ã‚µãƒãƒªãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            shuffle_info = "ï¼ˆã‚·ãƒ£ãƒƒãƒ•ãƒ«æ¸ˆã¿ï¼‰" if is_shuffled else "ï¼ˆé †ç•ªé€šã‚Šï¼‰"
            st.success(f"ã€Œ{query}ã€ã§{len(results)}å•è¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼ˆ{search_type}ï¼‰{shuffle_info}")

            # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
            subjects = set(q.get('subject', '') for q in results)
            
            # å¹´åº¦ç¯„å›²ã®è¨ˆç®—ï¼ˆextract_year_from_question_numberä½¿ç”¨ï¼‰
            years = [extract_year_from_question_number(q.get("number", "")) for q in results]
            valid_years = [y for y in years if y is not None]
            year_range = f"{min(valid_years)}-{max(valid_years)}" if valid_years else "ä¸æ˜"
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ãƒ’ãƒƒãƒˆæ•°", len(results))
            with col2:
                st.metric("é–¢é€£ç§‘ç›®æ•°", len(subjects))
            with col3:
                st.metric("å¹´åº¦ç¯„å›²", year_range)

            # æ¤œç´¢çµæœãƒªã‚¹ãƒˆ
            st.subheader("æ¤œç´¢çµæœ")
            for i, q in enumerate(results[:20]):  # 20ä»¶ã«åˆ¶é™
                q_number = q.get('number', 'N/A')
                subject = q.get('subject', 'æœªåˆ†é¡')
                
                # å­¦ç¿’ãƒ¬ãƒ™ãƒ«ã¨å±¥æ­´ã‚’å–å¾—
                cards = st.session_state.get('cards', {})
                card = cards.get(q_number, {})
                level = calculate_card_level(card)
                
                # st.expanderã‚¿ã‚¤ãƒˆãƒ«
                with st.expander(f"â— {q_number} - {subject}"):
                    # å­¦ç¿’ãƒ¬ãƒ™ãƒ«ï¼ˆæœ€ä¸Šéƒ¨ï¼‰
                    st.markdown(f"**å­¦ç¿’ãƒ¬ãƒ™ãƒ«:** {level}")
                    
                    # å•é¡Œæ–‡ï¼ˆçœç•¥è¡¨ç¤ºï¼‰
                    question_text = q.get('question', '')
                    if len(question_text) > 100:
                        st.markdown(f"**å•é¡Œ:** {question_text[:100]}...")
                    else:
                        st.markdown(f"**å•é¡Œ:** {question_text}")
                    
                    # é¸æŠè‚¢ï¼ˆçœç•¥è¡¨ç¤ºï¼‰
                    choices = q.get('choices', [])
                    if choices:
                        st.markdown("**é¸æŠè‚¢:**")
                        for j, choice in enumerate(choices):
                            if isinstance(choice, dict):
                                choice_text = choice.get('text', str(choice))
                            else:
                                choice_text = str(choice)
                            
                            if len(choice_text) > 50:
                                st.markdown(f"  {chr(65 + j)}. {choice_text[:50]}...")
                            else:
                                st.markdown(f"  {chr(65 + j)}. {choice_text}")
                    
                    # æ­£è§£
                    answer = q.get('answer', '')
                    if answer:
                        st.markdown(f"**æ­£è§£:** {answer}")
                    
                    # å­¦ç¿’å±¥æ­´
                    history = card.get('history', [])
                    n = card.get('n', 0)
                    if not history:
                        st.markdown("**å­¦ç¿’å±¥æ­´:** ãªã—")
                    else:
                        st.markdown(f"**å­¦ç¿’å±¥æ­´:** {len(history)}å›")
                        st.markdown(f"**æ¼”ç¿’å›æ•°:** {n}å›")
                        # æœ€æ–°ã®å­¦ç¿’è¨˜éŒ²ã‚’è¡¨ç¤º
                        if len(history) > 0:
                            latest = history[-1]
                            timestamp = latest.get('timestamp', '')
                            quality = latest.get('quality', 0)
                            if timestamp:
                                try:
                                    if hasattr(timestamp, 'strftime'):
                                        time_str = timestamp.strftime('%Y-%m-%d %H:%M')
                                    else:
                                        # ã‚ˆã‚Šå®‰å…¨ãªæ–‡å­—åˆ—å‡¦ç†
                                        try:
                                            if 'T' in str(timestamp):
                                                # ISOå½¢å¼
                                                timestamp_str = str(timestamp).split('.')[0] if '.' in str(timestamp) else str(timestamp)
                                                parsed_time = datetime.datetime.fromisoformat(timestamp_str)
                                                time_str = parsed_time.strftime('%Y-%m-%d %H:%M')
                                            else:
                                                time_str = str(timestamp)[:16]
                                        except:
                                            time_str = "ä¸æ˜"
                                    st.markdown(f"ã€€æœ€æ–°: {time_str} (è©•ä¾¡: {quality})")
                                except:
                                    st.markdown(f"ã€€æœ€æ–°: (è©•ä¾¡: {quality})")

            # 4. PDFç”Ÿæˆãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
            st.markdown("#### ğŸ“„ PDFç”Ÿæˆ")
            colA, colB = st.columns(2)
            
            with colA:
                if st.button("ğŸ“„ PDFã‚’ç”Ÿæˆ", key="pdf_generate_button"):
                    with st.spinner("PDFã‚’ç”Ÿæˆä¸­... é«˜å“è³ªãªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®ãŸã‚æ•°åˆ†ã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚"):
                        # å‚ç…§å…ƒapp.pyã®PDFç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Œå…¨ã«ç§»æ¤
                        assets, per_q_files = _gather_images_for_questions(results)
                        latex_source = export_questions_to_latex_tcb_jsarticle(results, right_label_fn=lambda q: q.get('subject', ''))
                        
                        # ç”»åƒãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ç½®æ›
                        for i, files in enumerate(per_q_files, start=1):
                            block = _image_block_latex(files)
                            latex_source = latex_source.replace(rf"%__IMAGES_SLOT__{i}__", block)

                        pdf_bytes, log = compile_latex_to_pdf(latex_source, assets=assets)

                        if pdf_bytes:
                            ts = datetime.datetime.now().strftime("%Y%m%d_%H%M")
                            st.session_state["pdf_bytes_for_download"] = pdf_bytes
                            st.session_state["pdf_filename_for_download"] = f"search_results_{ts}.pdf"
                            st.success("âœ… PDFç”Ÿæˆå®Œäº†ï¼å³ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                        else:
                            st.error("âŒ PDFç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                            # å¤±æ•—ã—ãŸå ´åˆã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
                            if "pdf_bytes_for_download" in st.session_state:
                                del st.session_state["pdf_bytes_for_download"]
                            with st.expander("ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°"):
                                st.code(log or "ãƒ­ã‚°ã¯ã‚ã‚Šã¾ã›ã‚“", language="text")
            
            with colB:
                # st.session_stateã«PDFãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’æ´»æ€§åŒ–
                if "pdf_bytes_for_download" in st.session_state and st.session_state["pdf_bytes_for_download"]:
                    file_size_kb = len(st.session_state["pdf_bytes_for_download"]) / 1024
                    st.download_button(
                        label="ğŸ“¥ PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=st.session_state["pdf_bytes_for_download"],
                        file_name=st.session_state["pdf_filename_for_download"],
                        mime="application/pdf",
                        use_container_width=True,
                        type="primary",  # ç›®ç«‹ã¤ãƒ—ãƒ©ã‚¤ãƒãƒªãƒ¼ã‚¹ã‚¿ã‚¤ãƒ«ã‚’é©ç”¨
                        help=f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_kb:.1f} KB"
                    )
                else:
                    # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ãƒœã‚¿ãƒ³ã‚’éæ´»æ€§çŠ¶æ…‹ã§è¡¨ç¤º
                    st.button("ğŸ“¥ PDFã‚’DL", disabled=True, use_container_width=True)
        else:
            if query:
                st.warning(f"ã€Œ{query}ã€ã«è©²å½“ã™ã‚‹å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            else:
                st.info("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦æ¤œç´¢ã—ã¦ãã ã•ã„")

# ãƒ¡ã‚¤ãƒ³é–¢æ•°ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å…¬é–‹é–¢æ•°ã¨ã—ã¦è¨­å®š
def main():
    """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    render_search_page()

if __name__ == "__main__":
    main()
