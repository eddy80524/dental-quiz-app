import pandas as pd
from sentence_transformers import SentenceTransformer, InputExample, losses
from torch.utils.data import DataLoader
import os

print("--- AIãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™ ---")

# --- ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATASET_PATH = os.path.join(BASE_DIR, '..', 'my_llm_app', 'data', 'finetune_dataset.csv')
BASE_MODEL = 'cl-tohoku/bert-base-japanese-whole-word-masking'
OUTPUT_MODEL_PATH = os.path.join(BASE_DIR, '..', 'models', 'dental-bert-v1') # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å…ˆ

# å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
EPOCHS = 1
BATCH_SIZE = 16

# --- ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨æº–å‚™ ---
print(f"--- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{DATASET_PATH}' ã‚’èª­ã¿è¾¼ã¿ä¸­ ---")
df = pd.read_csv(DATASET_PATH)
train_examples = []
for index, row in df.iterrows():
    train_examples.append(InputExample(texts=[row['anchor'], row['positive']]))

# --- ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã¨å­¦ç¿’è¨­å®š ---
print(f"--- ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ« '{BASE_MODEL}' ã‚’èª­ã¿è¾¼ã¿ä¸­ ---")
model = SentenceTransformer(BASE_MODEL)
train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=BATCH_SIZE)
train_loss = losses.MultipleNegativesRankingLoss(model=model)

# --- å­¦ç¿’ã®å®Ÿè¡Œ ---
print(f"--- {EPOCHS}ã‚¨ãƒãƒƒã‚¯ã®å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆæ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰ ---")
model.fit(train_objectives=[(train_dataloader, train_loss)],
          epochs=EPOCHS,
          warmup_steps=100,
          output_path=OUTPUT_MODEL_PATH,
          show_progress_bar=True)

print(f"ğŸ‰ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å®Œäº†ï¼ è³¢ããªã£ãŸãƒ¢ãƒ‡ãƒ«ã‚’'{OUTPUT_MODEL_PATH}'ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")